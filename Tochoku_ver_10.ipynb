{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgSl06wDKDjOHnMiN8wx6y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomitayus/-/blob/claude%2Fduty-roster-setup-8yW1T/Tochoku_ver_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 当直くん\n",
        "from google.colab import files\n",
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "# =========================\n",
        "# ユーザー設定\n",
        "# =========================\n",
        "HOLIDAYS = set()  # 祝日を入れるならここ（例: {pd.Timestamp(\"2026-01-01\"), ...}）\n",
        "BG_DAY_COLS = set()    # 列名で「昼」固定したい大学枠があれば追加\n",
        "BG_NIGHT_COLS = set()  # 列名で「夜」固定したい大学枠があれば追加\n",
        "\n",
        "WED_FORBIDDEN_DOCTORS = {'金城', '山田', '野寺'}  # 水曜の H〜U を禁止したい医師\n",
        "\n",
        "NUM_PATTERNS = 10000  # 100/1000/10000 など\n",
        "\n",
        "# sheet1 の「枠」扱いする入力値（1以外の記号も許容したい場合）\n",
        "SLOT_MARKERS = {1, 1.0, \"1\", \"〇\", \"○\", \"◯\", \"◎\"}\n",
        "\n",
        "# --- ローカル探索（入替）設定 ---\n",
        "LOCAL_SEARCH_ENABLED = True\n",
        "TOP_KEEP = 15                 # greedyで残す候補数（この中に最良が残る確率↑）\n",
        "REFINE_TOP = 15               # ローカル探索をかける候補数（<= TOP_KEEP）\n",
        "LOCAL_MAX_ITERS = 3000        # 1候補あたりの入替試行回数\n",
        "LOCAL_PATIENCE = 1200         # 改善が出ない試行がこの回数続いたら打ち切り\n",
        "LOCAL_REFRESH_EVERY = 200     # 問題医師（gap/重複）を再抽出する間隔\n",
        "\n",
        "# スコア重み（必要なら調整）\n",
        "W_FAIR_TOTAL = 10          # 全合計（active内 max-min-1）\n",
        "W_GAP = 3                  # gap(4日未満)\n",
        "W_HOSP_DUP = 1             # 同一病院複数回\n",
        "W_UNASSIGNED = 100         # 未割当\n",
        "W_CAP = 50                 # cap超え\n",
        "W_BG_SPREAD = 3            # 大学合計（累計）ばらつき\n",
        "W_HT_SPREAD = 3            # 外病院合計（累計）ばらつき\n",
        "W_WD_SPREAD = 2            # 平日（累計）ばらつき\n",
        "W_WE_SPREAD = 3            # 休日合計（累計）ばらつき\n",
        "\n",
        "# =========================\n",
        "# ユーティリティ\n",
        "# =========================\n",
        "def strip_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df.columns = [c.strip() if isinstance(c, str) else c for c in df.columns]\n",
        "    return df\n",
        "\n",
        "def make_unique(names):\n",
        "    \"\"\"重複列名を _2, _3 ... でユニーク化\"\"\"\n",
        "    seen = {}\n",
        "    out = []\n",
        "    for n in names:\n",
        "        n = \"\" if pd.isna(n) else n\n",
        "        if n not in seen:\n",
        "            seen[n] = 1\n",
        "            out.append(n)\n",
        "        else:\n",
        "            seen[n] += 1\n",
        "            out.append(f\"{n}_{seen[n]}\")\n",
        "    return out\n",
        "\n",
        "def safe_str(x):\n",
        "    if pd.isna(x):\n",
        "        return \"\"\n",
        "    return str(x).strip()\n",
        "\n",
        "def find_sheet_name(xls: pd.ExcelFile, target: str):\n",
        "    \"\"\"sheet名の大小・表記ゆれに耐える\"\"\"\n",
        "    if target in xls.sheet_names:\n",
        "        return target\n",
        "    low_map = {s.lower(): s for s in xls.sheet_names}\n",
        "    if target.lower() in low_map:\n",
        "        return low_map[target.lower()]\n",
        "    for s in xls.sheet_names:\n",
        "        if s.strip().lower() == target.strip().lower():\n",
        "            return s\n",
        "    return None\n",
        "\n",
        "def is_slot_value(v) -> bool:\n",
        "    if isinstance(v, str):\n",
        "        return v.strip() in SLOT_MARKERS\n",
        "    if isinstance(v, (int, float, np.integer, np.floating)):\n",
        "        return float(v) == 1.0\n",
        "    return False\n",
        "\n",
        "# =========================\n",
        "# sheet4 読み込み（ヘッダ行自動検出＋重複耐性）\n",
        "# =========================\n",
        "def parse_sheet4_from_grid(grid: pd.DataFrame) -> pd.DataFrame:\n",
        "    g = grid.copy()\n",
        "    g = g.dropna(how=\"all\").reset_index(drop=True)\n",
        "\n",
        "    if len(g) == 0:\n",
        "        raise ValueError(\"sheet4 が空です\")\n",
        "\n",
        "    # ヘッダ行を探す（'氏名' がある行）\n",
        "    header_row_idx = None\n",
        "    for i in range(min(30, len(g))):\n",
        "        row = g.iloc[i].astype(str).str.strip()\n",
        "        if (row == \"氏名\").any():\n",
        "            header_row_idx = i\n",
        "            break\n",
        "    if header_row_idx is None:\n",
        "        header_row_idx = 0\n",
        "\n",
        "    headers = [safe_str(x) for x in g.iloc[header_row_idx].tolist()]\n",
        "    headers = [h if (h != \"\" and h.lower() != \"nan\") else f\"Unnamed_{j}\" for j, h in enumerate(headers)]\n",
        "    headers = make_unique(headers)\n",
        "\n",
        "    data = g.iloc[header_row_idx + 1:].reset_index(drop=True)\n",
        "    data.columns = headers\n",
        "\n",
        "    if \"氏名\" not in data.columns:\n",
        "        raise ValueError(\"sheet4 のヘッダ行に '氏名' 列が見つかりません（sheet4の形式を確認してください）\")\n",
        "\n",
        "    # 氏名の空行削除\n",
        "    data[\"氏名\"] = data[\"氏名\"].astype(str).str.strip()\n",
        "    data = data[(data[\"氏名\"].notna()) & (data[\"氏名\"] != \"\") & (data[\"氏名\"].str.lower() != \"nan\")].reset_index(drop=True)\n",
        "\n",
        "    # 数値化（氏名以外）\n",
        "    for col in data.columns:\n",
        "        if col == \"氏名\":\n",
        "            continue\n",
        "        data[col] = pd.to_numeric(data[col], errors=\"coerce\").fillna(0)\n",
        "\n",
        "    return data\n",
        "\n",
        "# =========================\n",
        "# 入力ファイルのアップロード\n",
        "# =========================\n",
        "print(\"sheet1〜sheet4（またはSheet4）が入った当直Excelファイルを選択してください\")\n",
        "uploaded = files.upload()\n",
        "uploaded_filename = list(uploaded.keys())[0]\n",
        "\n",
        "xls = pd.ExcelFile(io.BytesIO(uploaded[uploaded_filename]))\n",
        "\n",
        "sheet1_name = find_sheet_name(xls, \"sheet1\")\n",
        "sheet2_name = find_sheet_name(xls, \"sheet2\")\n",
        "sheet3_name = find_sheet_name(xls, \"sheet3\")\n",
        "sheet4_name = find_sheet_name(xls, \"sheet4\") or find_sheet_name(xls, \"Sheet4\")\n",
        "\n",
        "missing = [k for k, v in [(\"sheet1\", sheet1_name), (\"sheet2\", sheet2_name), (\"sheet3\", sheet3_name), (\"sheet4\", sheet4_name)] if v is None]\n",
        "if missing:\n",
        "    raise ValueError(f\"必要なシートが見つかりません: {missing} / 実際のシート名: {xls.sheet_names}\")\n",
        "\n",
        "# --------- Excel 読み込み ---------\n",
        "shift_df = strip_cols(pd.read_excel(xls, sheet_name=sheet1_name))\n",
        "availability_raw = strip_cols(pd.read_excel(xls, sheet_name=sheet2_name))\n",
        "schedule_raw = strip_cols(pd.read_excel(xls, sheet_name=sheet3_name))\n",
        "\n",
        "shift_df.columns = make_unique(list(shift_df.columns))\n",
        "availability_raw.columns = make_unique(list(availability_raw.columns))\n",
        "schedule_raw.columns = make_unique(list(schedule_raw.columns))\n",
        "\n",
        "# sheet4 は「出力用」と「解析用（header=None）」を分ける\n",
        "sheet4_raw_out = strip_cols(pd.read_excel(xls, sheet_name=sheet4_name))\n",
        "sheet4_raw_out.columns = make_unique(list(sheet4_raw_out.columns))\n",
        "\n",
        "sheet4_grid = pd.read_excel(xls, sheet_name=sheet4_name, header=None)\n",
        "sheet4_data = parse_sheet4_from_grid(sheet4_grid)\n",
        "\n",
        "# =========================\n",
        "# 日付列の整形\n",
        "# =========================\n",
        "date_col_shift = shift_df.columns[0]\n",
        "shift_df[date_col_shift] = pd.to_datetime(shift_df[date_col_shift], errors=\"coerce\").dt.normalize()\n",
        "if shift_df[date_col_shift].isna().all():\n",
        "    raise ValueError(\"sheet1 の先頭列が日付として解釈できません（列の形式を確認してください）\")\n",
        "\n",
        "date_col_avail = availability_raw.columns[0]\n",
        "availability_raw[date_col_avail] = pd.to_datetime(availability_raw[date_col_avail], errors=\"coerce\").dt.normalize()\n",
        "availability_df = availability_raw.set_index(date_col_avail)\n",
        "\n",
        "date_col_sched = schedule_raw.columns[0]\n",
        "schedule_raw[date_col_sched] = pd.to_datetime(schedule_raw[date_col_sched], errors=\"coerce\").dt.normalize()\n",
        "schedule_df = schedule_raw.set_index(date_col_sched)\n",
        "\n",
        "HOLIDAYS = {pd.to_datetime(d).normalize() for d in HOLIDAYS}\n",
        "\n",
        "def is_holiday(date):\n",
        "    return pd.to_datetime(date).normalize() in HOLIDAYS\n",
        "\n",
        "# =========================\n",
        "# 基本情報\n",
        "# =========================\n",
        "doctor_names = [safe_str(x) for x in list(availability_raw.columns[1:])]\n",
        "doctor_col_index = {doc: idx for idx, doc in enumerate(doctor_names)}\n",
        "\n",
        "hospital_cols = list(shift_df.columns[1:])\n",
        "n_cols = len(shift_df.columns)\n",
        "\n",
        "# 列インデックス（テンプレ依存：B〜U を想定）\n",
        "B_COL_INDEX = 1\n",
        "C_COL_INDEX = 2\n",
        "D_COL_INDEX = min(3, n_cols - 1)\n",
        "E_COL_INDEX = min(4, n_cols - 1)\n",
        "F_COL_INDEX = min(5, n_cols - 1)\n",
        "G_COL_INDEX = min(6, n_cols - 1)\n",
        "H_COL_INDEX = min(7, n_cols - 1)\n",
        "M_COL_INDEX = min(12, n_cols - 1)\n",
        "U_COL_INDEX = min(20, n_cols - 1)\n",
        "\n",
        "# =========================\n",
        "# sheet2 可否コード\n",
        "# =========================\n",
        "fallback_avail_codes = {}\n",
        "for doc in doctor_names:\n",
        "    col_vals = availability_raw[doc]\n",
        "    first_val = None\n",
        "    for v in col_vals:\n",
        "        if pd.notna(v):\n",
        "            first_val = v\n",
        "            break\n",
        "    if first_val is None:\n",
        "        fallback_avail_codes[doc] = 1\n",
        "    else:\n",
        "        try:\n",
        "            c = int(first_val)\n",
        "        except Exception:\n",
        "            c = 1\n",
        "        if c not in (0, 1, 2, 3):\n",
        "            c = 1\n",
        "        fallback_avail_codes[doc] = c\n",
        "\n",
        "def get_avail_code(date, doctor):\n",
        "    code = None\n",
        "    if isinstance(availability_df.index, pd.DatetimeIndex):\n",
        "        try:\n",
        "            value = availability_df.at[pd.to_datetime(date).normalize(), doctor]\n",
        "            if isinstance(value, pd.Series):\n",
        "                value = value.iloc[0]\n",
        "            if pd.notna(value):\n",
        "                code = int(value)\n",
        "        except Exception:\n",
        "            pass\n",
        "    if code is None:\n",
        "        code = fallback_avail_codes.get(doctor, 1)\n",
        "    if code not in (0, 1, 2, 3):\n",
        "        code = 1\n",
        "    return code\n",
        "\n",
        "def get_sched_code(date, doctor):\n",
        "    if doctor not in schedule_df.columns:\n",
        "        return None\n",
        "    try:\n",
        "        value = schedule_df.at[pd.to_datetime(date).normalize(), doctor]\n",
        "        if isinstance(value, pd.Series):\n",
        "            value = value.iloc[0]\n",
        "    except Exception:\n",
        "        return None\n",
        "    if pd.isna(value):\n",
        "        return None\n",
        "    return str(value).strip()\n",
        "\n",
        "# sheet2 と sheet3 の医師列がズレていないか（ズレてても動くが、制約が弱くなる）\n",
        "sched_doctors = [safe_str(x) for x in list(schedule_raw.columns[1:])]\n",
        "if doctor_names != sched_doctors:\n",
        "    print(\"WARNING: sheet2(可否) と sheet3(カテ表) の医師列が一致していません。\")\n",
        "    only2 = [d for d in doctor_names if d not in sched_doctors]\n",
        "    only3 = [d for d in sched_doctors if d not in doctor_names]\n",
        "    print(\"  sheet2 only (先頭10):\", only2[:10])\n",
        "    print(\"  sheet3 only (先頭10):\", only3[:10])\n",
        "    print(\"  ※H〜U の『カテ表あり不可』制約が一部の医師で効かない可能性があります。\")\n",
        "\n",
        "# =========================\n",
        "# sheet4 前月まで累積\n",
        "# =========================\n",
        "name_to_row = {row[\"氏名\"]: row for _, row in sheet4_data.iterrows()}\n",
        "prev_names = list(sheet4_data[\"氏名\"])\n",
        "\n",
        "def match_prev_name(doc):\n",
        "    if doc in name_to_row:\n",
        "        return doc\n",
        "    ms = [p for p in prev_names if str(p).startswith(doc) or doc.startswith(str(p))]\n",
        "    return ms[0] if len(ms) == 1 else None\n",
        "\n",
        "name_match = {doc: match_prev_name(doc) for doc in doctor_names}\n",
        "unmatched = [d for d in doctor_names if name_match.get(d) is None]\n",
        "if unmatched:\n",
        "    print(\"WARNING: sheet4(累積)で名前が一致しない医師がいます（累積が0扱いになります）:\", unmatched)\n",
        "\n",
        "def prev_get(doc, colname):\n",
        "    pname = name_match.get(doc)\n",
        "    if pname and pname in name_to_row:\n",
        "        row = name_to_row[pname]\n",
        "        v = row.get(colname, 0)\n",
        "        try:\n",
        "            return float(v or 0)\n",
        "        except Exception:\n",
        "            return 0.0\n",
        "    return 0.0\n",
        "\n",
        "prev_total   = {d: prev_get(d, \"全合計\")   for d in doctor_names}\n",
        "prev_bg      = {d: prev_get(d, \"大学合計\") for d in doctor_names}\n",
        "prev_ht      = {d: prev_get(d, \"外病院合計\") for d in doctor_names}\n",
        "prev_weekday = {d: prev_get(d, \"平日\")     for d in doctor_names}\n",
        "prev_weekend = {d: prev_get(d, \"休日合計\") for d in doctor_names}\n",
        "\n",
        "# =========================\n",
        "# 全枠数カウント + slots_by_date 前計算\n",
        "# =========================\n",
        "slots_by_date = defaultdict(lambda: {\"preassigned\": [], \"free\": []})\n",
        "preassigned_count = {d: 0 for d in doctor_names}\n",
        "total_slots = 0\n",
        "\n",
        "for ridx in shift_df.index:\n",
        "    date = shift_df.at[ridx, date_col_shift]\n",
        "    if pd.isna(date):\n",
        "        continue\n",
        "    date = pd.to_datetime(date).normalize()\n",
        "\n",
        "    for hosp in hospital_cols:\n",
        "        val = shift_df.at[ridx, hosp]\n",
        "\n",
        "        # 固定割当（セルに医師名が入っている）\n",
        "        if isinstance(val, str) and val.strip() in doctor_names:\n",
        "            doc = val.strip()\n",
        "            slots_by_date[date][\"preassigned\"].append((ridx, hosp, doc))\n",
        "            preassigned_count[doc] += 1\n",
        "            total_slots += 1\n",
        "            continue\n",
        "\n",
        "        # 自動枠（1/〇など）\n",
        "        if is_slot_value(val):\n",
        "            slots_by_date[date][\"free\"].append((ridx, hosp))\n",
        "            total_slots += 1\n",
        "\n",
        "if len(doctor_names) == 0:\n",
        "    raise ValueError(\"sheet2 に医師名がありません\")\n",
        "\n",
        "all_dates = sorted(slots_by_date.keys())\n",
        "all_shift_dates = sorted(pd.to_datetime(shift_df[date_col_shift].dropna()).dt.normalize().unique())\n",
        "\n",
        "# =========================\n",
        "# cap設計：3回ベース＋余りは右側から4回目\n",
        "# =========================\n",
        "def is_always_unavailable(doc):\n",
        "    if preassigned_count.get(doc, 0) > 0:\n",
        "        return False\n",
        "    return all(get_avail_code(d, doc) == 0 for d in all_shift_dates)\n",
        "\n",
        "inactive_doctors = [d for d in doctor_names if is_always_unavailable(d)]\n",
        "active_doctors = [d for d in doctor_names if d not in inactive_doctors]\n",
        "if len(active_doctors) == 0:\n",
        "    raise ValueError(\"当月に割り当て可能な医師がいません\")\n",
        "\n",
        "BASE_TARGET = total_slots // len(active_doctors)\n",
        "EXTRA_SLOTS = total_slots - BASE_TARGET * len(active_doctors)\n",
        "\n",
        "active_sorted_right = sorted(active_doctors, key=lambda d: doctor_col_index[d], reverse=True)\n",
        "EXTRA_ALLOWED = set(active_sorted_right[:EXTRA_SLOTS])\n",
        "\n",
        "TARGET_CAP = {d: 0 for d in doctor_names}\n",
        "for d in active_doctors:\n",
        "    TARGET_CAP[d] = BASE_TARGET + (1 if d in EXTRA_ALLOWED else 0)\n",
        "for d in doctor_names:\n",
        "    if preassigned_count.get(d, 0) > TARGET_CAP.get(d, 0):\n",
        "        TARGET_CAP[d] = preassigned_count[d]\n",
        "\n",
        "floor_shifts = BASE_TARGET\n",
        "\n",
        "print(\"=== Target summary ===\")\n",
        "print(\"total_slots:\", total_slots)\n",
        "print(\"active:\", len(active_doctors), \"inactive:\", len(inactive_doctors), \"inactive_doctors:\", inactive_doctors)\n",
        "print(\"BASE_TARGET:\", BASE_TARGET, \"EXTRA_SLOTS:\", EXTRA_SLOTS)\n",
        "\n",
        "# =========================\n",
        "# 大学(B〜G)の昼夜判定 & 7分類\n",
        "# =========================\n",
        "def is_bg_day_shift(hosp_name, col_idx):\n",
        "    if hosp_name in BG_DAY_COLS:\n",
        "        return True\n",
        "    if hosp_name in BG_NIGHT_COLS:\n",
        "        return False\n",
        "    # デフォルト：B,C,E,F=昼 / D,G=夜\n",
        "    if col_idx in (B_COL_INDEX, C_COL_INDEX, E_COL_INDEX, F_COL_INDEX):\n",
        "        return True\n",
        "    if col_idx in (D_COL_INDEX, G_COL_INDEX):\n",
        "        return False\n",
        "    mid = (B_COL_INDEX + G_COL_INDEX) // 2\n",
        "    return col_idx <= mid\n",
        "\n",
        "def classify_bg_category(date, hosp_name):\n",
        "    idx = shift_df.columns.get_loc(hosp_name)\n",
        "    is_day = is_bg_day_shift(hosp_name, idx)\n",
        "    dow = pd.to_datetime(date).weekday()\n",
        "    holi = is_holiday(date)\n",
        "\n",
        "    weekday = dow < 5\n",
        "    # 平日かつ C,D,F,G は祝日扱い\n",
        "    if weekday and idx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX):\n",
        "        holi = True\n",
        "\n",
        "    if holi and weekday:\n",
        "        base = \"祝日\"\n",
        "    elif dow == 5:\n",
        "        base = \"土曜\"\n",
        "    elif dow == 6:\n",
        "        base = \"日曜\"\n",
        "    else:\n",
        "        return \"平日\"\n",
        "\n",
        "    return base + (\"昼\" if is_day else \"夜\")\n",
        "\n",
        "# =========================\n",
        "# 1枠の医師選択（greedy）\n",
        "# =========================\n",
        "def choose_doctor_for_slot(\n",
        "    date,\n",
        "    hospital_name,\n",
        "    assigned_count,\n",
        "    assigned_dates,\n",
        "    assigned_bg,\n",
        "    assigned_ht,\n",
        "    assigned_weekday,\n",
        "    assigned_weekend,\n",
        "    assigned_be,\n",
        "    assigned_fg,\n",
        "    assigned_hosp_count,\n",
        "):\n",
        "    idx = shift_df.columns.get_loc(hospital_name)\n",
        "    is_BE = B_COL_INDEX <= idx <= E_COL_INDEX\n",
        "    is_BG = B_COL_INDEX <= idx <= G_COL_INDEX\n",
        "    is_HU = H_COL_INDEX <= idx <= U_COL_INDEX\n",
        "    dow = pd.to_datetime(date).weekday()\n",
        "    weekday = dow < 5\n",
        "\n",
        "    # ハード制約候補\n",
        "    base_candidates = []\n",
        "    for doc in doctor_names:\n",
        "        if date in assigned_dates[doc]:\n",
        "            continue\n",
        "\n",
        "        code = get_avail_code(date, doc)\n",
        "        if code == 0:\n",
        "            continue\n",
        "        # 2 -> B〜M列以外ダメ\n",
        "        if code == 2 and not (B_COL_INDEX <= idx <= M_COL_INDEX):\n",
        "            continue\n",
        "        # 3 -> H〜U列以外ダメ\n",
        "        if code == 3 and not (H_COL_INDEX <= idx <= U_COL_INDEX):\n",
        "            continue\n",
        "\n",
        "        # H〜U でカテ表ありは不可\n",
        "        if H_COL_INDEX <= idx <= U_COL_INDEX:\n",
        "            if get_sched_code(date, doc):\n",
        "                continue\n",
        "\n",
        "        # 水曜 H〜U 禁止\n",
        "        if dow == 2 and H_COL_INDEX <= idx <= U_COL_INDEX:\n",
        "            if doc in WED_FORBIDDEN_DOCTORS:\n",
        "                continue\n",
        "\n",
        "        base_candidates.append(doc)\n",
        "\n",
        "    if not base_candidates:\n",
        "        return None\n",
        "\n",
        "    # cap未満だけ優先（埋まらない時だけcap破り）\n",
        "    cap_ok = [d for d in base_candidates if assigned_count[d] < TARGET_CAP.get(d, 0)]\n",
        "    candidates = cap_ok if cap_ok else base_candidates\n",
        "\n",
        "    # gap\n",
        "    gaps = {}\n",
        "    for d in candidates:\n",
        "        if not assigned_dates[d]:\n",
        "            gaps[d] = 999\n",
        "        else:\n",
        "            gaps[d] = min(abs((pd.to_datetime(date) - x).days) for x in assigned_dates[d])\n",
        "\n",
        "    # 優先順位: 7,4,5,2,3,6,8,1(>=4),10\n",
        "\n",
        "    # 7 全体（前月+今月）\n",
        "    metric_total = {d: prev_total[d] + assigned_count[d] for d in candidates}\n",
        "    min_total = min(metric_total.values())\n",
        "    candidates = [d for d in candidates if metric_total[d] == min_total]\n",
        "\n",
        "    # 4 大学/外病院偏り（前月+今月）\n",
        "    if is_BG:\n",
        "        metric_bg = {d: prev_bg[d] + assigned_bg[d] for d in candidates}\n",
        "        mb = min(metric_bg.values())\n",
        "        candidates = [d for d in candidates if metric_bg[d] == mb]\n",
        "    elif is_HU:\n",
        "        metric_ht = {d: prev_ht[d] + assigned_ht[d] for d in candidates}\n",
        "        mh = min(metric_ht.values())\n",
        "        candidates = [d for d in candidates if metric_ht[d] == mh]\n",
        "\n",
        "    # 5 B〜E / F〜G\n",
        "    if is_BG:\n",
        "        if is_BE:\n",
        "            mbe = min(assigned_be[d] for d in candidates)\n",
        "            candidates = [d for d in candidates if assigned_be[d] == mbe]\n",
        "        else:\n",
        "            mfg = min(assigned_fg[d] for d in candidates)\n",
        "            candidates = [d for d in candidates if assigned_fg[d] == mfg]\n",
        "\n",
        "    # 2 同一病院0回優先\n",
        "    no_dup = [d for d in candidates if assigned_hosp_count[d].get(hospital_name, 0) == 0]\n",
        "    if no_dup:\n",
        "        candidates = no_dup\n",
        "\n",
        "    # 3 B〜G はカテ表あり優先（ソフト優先）\n",
        "    if is_BG:\n",
        "        with_sched = [d for d in candidates if get_sched_code(date, d)]\n",
        "        if with_sched:\n",
        "            candidates = with_sched\n",
        "\n",
        "    # 6 平日/休日偏り（前月+今月）\n",
        "    holi_flag = (\n",
        "        is_holiday(date)\n",
        "        or dow >= 5\n",
        "        or (weekday and idx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX))\n",
        "    )\n",
        "    if holi_flag:\n",
        "        metric_we = {d: prev_weekend[d] + assigned_weekend[d] for d in candidates}\n",
        "        mwe = min(metric_we.values())\n",
        "        candidates = [d for d in candidates if metric_we[d] == mwe]\n",
        "    else:\n",
        "        metric_wd = {d: prev_weekday[d] + assigned_weekday[d] for d in candidates}\n",
        "        mwd = min(metric_wd.values())\n",
        "        candidates = [d for d in candidates if metric_wd[d] == mwd]\n",
        "\n",
        "    # 8 floor未満優先\n",
        "    under_floor = [d for d in candidates if assigned_count[d] < floor_shifts]\n",
        "    if under_floor:\n",
        "        candidates = under_floor\n",
        "\n",
        "    # 1 gap>=4\n",
        "    gap_ok = [d for d in candidates if gaps[d] >= 4]\n",
        "    if gap_ok:\n",
        "        candidates = gap_ok\n",
        "\n",
        "    # 10 同点なら右側\n",
        "    return max(candidates, key=lambda d: doctor_col_index[d])\n",
        "\n",
        "# =========================\n",
        "# 1ヶ月分生成（greedy）\n",
        "# =========================\n",
        "def build_schedule_pattern(seed=0):\n",
        "    random.seed(seed)\n",
        "\n",
        "    df = shift_df.copy()\n",
        "    for col in hospital_cols:\n",
        "        df[col] = df[col].astype(object)\n",
        "\n",
        "    assigned_count = {d: 0 for d in doctor_names}\n",
        "    assigned_dates = {d: set() for d in doctor_names}\n",
        "\n",
        "    assigned_bg = {d: 0 for d in doctor_names}\n",
        "    assigned_ht = {d: 0 for d in doctor_names}\n",
        "    assigned_weekday = {d: 0 for d in doctor_names}\n",
        "    assigned_weekend = {d: 0 for d in doctor_names}\n",
        "    assigned_be = {d: 0 for d in doctor_names}\n",
        "    assigned_fg = {d: 0 for d in doctor_names}\n",
        "    assigned_hosp_count = {d: defaultdict(int) for d in doctor_names}\n",
        "    bg_cat = {d: defaultdict(int) for d in doctor_names}\n",
        "\n",
        "    # 固定当直\n",
        "    for date in all_dates:\n",
        "        for ridx, hosp, doc in slots_by_date[date][\"preassigned\"]:\n",
        "            df.at[ridx, hosp] = doc\n",
        "            assigned_count[doc] += 1\n",
        "            assigned_dates[doc].add(date)\n",
        "            assigned_hosp_count[doc][hosp] += 1\n",
        "\n",
        "            hidx = shift_df.columns.get_loc(hosp)\n",
        "            if B_COL_INDEX <= hidx <= G_COL_INDEX:\n",
        "                assigned_bg[doc] += 1\n",
        "                if B_COL_INDEX <= hidx <= E_COL_INDEX:\n",
        "                    assigned_be[doc] += 1\n",
        "                elif F_COL_INDEX <= hidx <= G_COL_INDEX:\n",
        "                    assigned_fg[doc] += 1\n",
        "                bg_cat[doc][classify_bg_category(date, hosp)] += 1\n",
        "            elif H_COL_INDEX <= hidx <= U_COL_INDEX:\n",
        "                assigned_ht[doc] += 1\n",
        "\n",
        "            dow = date.weekday()\n",
        "            weekday = dow < 5\n",
        "            holi_flag = (\n",
        "                is_holiday(date)\n",
        "                or dow >= 5\n",
        "                or (weekday and hidx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX))\n",
        "            )\n",
        "            if holi_flag:\n",
        "                assigned_weekend[doc] += 1\n",
        "            else:\n",
        "                assigned_weekday[doc] += 1\n",
        "\n",
        "    # 自動割当\n",
        "    for date in all_dates:\n",
        "        free_slots = slots_by_date[date][\"free\"].copy()\n",
        "        random.shuffle(free_slots)\n",
        "\n",
        "        for ridx, hosp in free_slots:\n",
        "            chosen = choose_doctor_for_slot(\n",
        "                date=date,\n",
        "                hospital_name=hosp,\n",
        "                assigned_count=assigned_count,\n",
        "                assigned_dates=assigned_dates,\n",
        "                assigned_bg=assigned_bg,\n",
        "                assigned_ht=assigned_ht,\n",
        "                assigned_weekday=assigned_weekday,\n",
        "                assigned_weekend=assigned_weekend,\n",
        "                assigned_be=assigned_be,\n",
        "                assigned_fg=assigned_fg,\n",
        "                assigned_hosp_count=assigned_hosp_count,\n",
        "            )\n",
        "            if chosen is None:\n",
        "                df.at[ridx, hosp] = \"UNASSIGNED\"\n",
        "            else:\n",
        "                df.at[ridx, hosp] = chosen\n",
        "                assigned_count[chosen] += 1\n",
        "                assigned_dates[chosen].add(date)\n",
        "                assigned_hosp_count[chosen][hosp] += 1\n",
        "\n",
        "                hidx = shift_df.columns.get_loc(hosp)\n",
        "                if B_COL_INDEX <= hidx <= G_COL_INDEX:\n",
        "                    assigned_bg[chosen] += 1\n",
        "                    if B_COL_INDEX <= hidx <= E_COL_INDEX:\n",
        "                        assigned_be[chosen] += 1\n",
        "                    elif F_COL_INDEX <= hidx <= G_COL_INDEX:\n",
        "                        assigned_fg[chosen] += 1\n",
        "                    bg_cat[chosen][classify_bg_category(date, hosp)] += 1\n",
        "                elif H_COL_INDEX <= hidx <= U_COL_INDEX:\n",
        "                    assigned_ht[chosen] += 1\n",
        "\n",
        "                dow = date.weekday()\n",
        "                weekday = dow < 5\n",
        "                holi_flag = (\n",
        "                    is_holiday(date)\n",
        "                    or dow >= 5\n",
        "                    or (weekday and hidx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX))\n",
        "                )\n",
        "                if holi_flag:\n",
        "                    assigned_weekend[chosen] += 1\n",
        "                else:\n",
        "                    assigned_weekday[chosen] += 1\n",
        "\n",
        "    return df, assigned_count, assigned_bg, assigned_ht, assigned_weekday, assigned_weekend, bg_cat\n",
        "\n",
        "# =========================\n",
        "# slot_meta / movable_positions（ローカル探索用）\n",
        "# =========================\n",
        "slot_meta = {}  # (ridx,hosp) -> (date, fixed)\n",
        "movable_positions = []  # (ridx,hosp,date)\n",
        "\n",
        "for date in all_dates:\n",
        "    for ridx, hosp, doc in slots_by_date[date][\"preassigned\"]:\n",
        "        slot_meta[(ridx, hosp)] = (date, True)\n",
        "    for ridx, hosp in slots_by_date[date][\"free\"]:\n",
        "        slot_meta[(ridx, hosp)] = (date, False)\n",
        "        movable_positions.append((ridx, hosp, date))\n",
        "\n",
        "# =========================\n",
        "# パターン統計再計算（pattern_df から）\n",
        "# =========================\n",
        "def recompute_stats(pattern_df):\n",
        "    counts = {d: 0 for d in doctor_names}\n",
        "    bg_counts = {d: 0 for d in doctor_names}\n",
        "    ht_counts = {d: 0 for d in doctor_names}\n",
        "    wd_counts = {d: 0 for d in doctor_names}\n",
        "    we_counts = {d: 0 for d in doctor_names}\n",
        "    bg_cat = {d: defaultdict(int) for d in doctor_names}\n",
        "    assigned_hosp_count = {d: defaultdict(int) for d in doctor_names}\n",
        "    doc_assignments = {d: [] for d in doctor_names}  # (date,hosp)\n",
        "    unassigned = []  # (date,hosp,ridx)\n",
        "\n",
        "    for (ridx, hosp), (date, fixed) in slot_meta.items():\n",
        "        val = pattern_df.at[ridx, hosp]\n",
        "        if not isinstance(val, str):\n",
        "            continue\n",
        "        v = val.strip()\n",
        "\n",
        "        if v == \"UNASSIGNED\":\n",
        "            unassigned.append((date, hosp, ridx))\n",
        "            continue\n",
        "        if v not in doctor_names:\n",
        "            continue\n",
        "\n",
        "        doc = v\n",
        "        counts[doc] += 1\n",
        "        assigned_hosp_count[doc][hosp] += 1\n",
        "        doc_assignments[doc].append((date, hosp))\n",
        "\n",
        "        hidx = shift_df.columns.get_loc(hosp)\n",
        "        if B_COL_INDEX <= hidx <= G_COL_INDEX:\n",
        "            bg_counts[doc] += 1\n",
        "            bg_cat[doc][classify_bg_category(date, hosp)] += 1\n",
        "        elif H_COL_INDEX <= hidx <= U_COL_INDEX:\n",
        "            ht_counts[doc] += 1\n",
        "\n",
        "        dow = date.weekday()\n",
        "        weekday = dow < 5\n",
        "        holi_flag = (\n",
        "            is_holiday(date)\n",
        "            or dow >= 5\n",
        "            or (weekday and hidx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX))\n",
        "        )\n",
        "        if holi_flag:\n",
        "            we_counts[doc] += 1\n",
        "        else:\n",
        "            wd_counts[doc] += 1\n",
        "\n",
        "    return counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned\n",
        "\n",
        "# =========================\n",
        "# スコア評価（raw_scoreも保持して 0 で潰れないように）\n",
        "# =========================\n",
        "def evaluate_schedule_with_raw(pattern_df, assigned_count, assigned_bg, assigned_ht, assigned_weekday, assigned_weekend):\n",
        "    # UNASSIGNED\n",
        "    unassigned_slots = 0\n",
        "    for ridx in pattern_df.index:\n",
        "        for hosp in hospital_cols:\n",
        "            v = pattern_df.at[ridx, hosp]\n",
        "            if isinstance(v, str) and v.strip() == \"UNASSIGNED\":\n",
        "                unassigned_slots += 1\n",
        "\n",
        "    # cap違反\n",
        "    cap_violations = 0\n",
        "    for doc in doctor_names:\n",
        "        cap = TARGET_CAP.get(doc, 0)\n",
        "        if assigned_count.get(doc, 0) > cap:\n",
        "            cap_violations += (assigned_count[doc] - cap)\n",
        "\n",
        "    # 全合計公平性（activeのみ）\n",
        "    active_counts = [assigned_count.get(d, 0) for d in active_doctors]\n",
        "    max_c = max(active_counts) if active_counts else 0\n",
        "    min_c = min(active_counts) if active_counts else 0\n",
        "    diff_total = max_c - min_c\n",
        "    fairness_penalty = max(0, diff_total - 1)\n",
        "\n",
        "    # gap(4日未満) と 同一病院重複\n",
        "    dates_by_doc = defaultdict(list)\n",
        "    hosp_counts_by_doc = {doc: defaultdict(int) for doc in doctor_names}\n",
        "\n",
        "    for ridx in pattern_df.index:\n",
        "        date = pattern_df.at[ridx, date_col_shift]\n",
        "        if pd.isna(date):\n",
        "            continue\n",
        "        date = pd.to_datetime(date).normalize()\n",
        "        for hosp in hospital_cols:\n",
        "            val = pattern_df.at[ridx, hosp]\n",
        "            if isinstance(val, str) and val in doctor_names:\n",
        "                dates_by_doc[val].append(date)\n",
        "                hosp_counts_by_doc[val][hosp] += 1\n",
        "\n",
        "    gap_violations = 0\n",
        "    for doc, dlist in dates_by_doc.items():\n",
        "        dlist = sorted(dlist)\n",
        "        for i in range(1, len(dlist)):\n",
        "            if (dlist[i] - dlist[i - 1]).days < 4:\n",
        "                gap_violations += 1\n",
        "\n",
        "    hosp_dup_violations = 0\n",
        "    for doc, hdict in hosp_counts_by_doc.items():\n",
        "        for _, c in hdict.items():\n",
        "            if c > 1:\n",
        "                hosp_dup_violations += (c - 1)\n",
        "\n",
        "    # 偏り（累計：前月+今月）の spread\n",
        "    bg_vals = [prev_bg[d] + assigned_bg.get(d, 0) for d in active_doctors]\n",
        "    ht_vals = [prev_ht[d] + assigned_ht.get(d, 0) for d in active_doctors]\n",
        "    wd_vals = [prev_weekday[d] + assigned_weekday.get(d, 0) for d in active_doctors]\n",
        "    we_vals = [prev_weekend[d] + assigned_weekend.get(d, 0) for d in active_doctors]\n",
        "\n",
        "    bg_spread = (max(bg_vals) - min(bg_vals)) if bg_vals else 0\n",
        "    ht_spread = (max(ht_vals) - min(ht_vals)) if ht_vals else 0\n",
        "    wd_spread = (max(wd_vals) - min(wd_vals)) if wd_vals else 0\n",
        "    we_spread = (max(we_vals) - min(we_vals)) if we_vals else 0\n",
        "\n",
        "    penalty = 0\n",
        "    penalty += fairness_penalty * W_FAIR_TOTAL\n",
        "    penalty += gap_violations * W_GAP\n",
        "    penalty += hosp_dup_violations * W_HOSP_DUP\n",
        "    penalty += unassigned_slots * W_UNASSIGNED\n",
        "    penalty += cap_violations * W_CAP\n",
        "\n",
        "    penalty += max(0, bg_spread - 1) * W_BG_SPREAD\n",
        "    penalty += max(0, ht_spread - 1) * W_HT_SPREAD\n",
        "    penalty += max(0, wd_spread - 1) * W_WD_SPREAD\n",
        "    penalty += max(0, we_spread - 1) * W_WE_SPREAD\n",
        "\n",
        "    raw_score = 100 - penalty\n",
        "    score = max(raw_score, 0)\n",
        "\n",
        "    metrics = {\n",
        "        \"raw_score\": float(raw_score),\n",
        "        \"penalty_total\": float(penalty),\n",
        "        \"max_minus_min_total_active\": int(diff_total),\n",
        "        \"gap_violations\": int(gap_violations),\n",
        "        \"hospital_dup_violations\": int(hosp_dup_violations),\n",
        "        \"unassigned_slots\": int(unassigned_slots),\n",
        "        \"cap_violations\": int(cap_violations),\n",
        "        \"bg_spread_cum\": float(bg_spread),\n",
        "        \"ht_spread_cum\": float(ht_spread),\n",
        "        \"weekday_spread_cum\": float(wd_spread),\n",
        "        \"weekend_spread_cum\": float(we_spread),\n",
        "    }\n",
        "    return score, raw_score, metrics\n",
        "\n",
        "# =========================\n",
        "# ローカル探索（入替 swap）\n",
        "# =========================\n",
        "def can_assign_doc_to_slot(doc, date, hosp):\n",
        "    \"\"\"ハード制約のみ（同日重複は別チェック）\"\"\"\n",
        "    idx = shift_df.columns.get_loc(hosp)\n",
        "    dow = pd.to_datetime(date).weekday()\n",
        "\n",
        "    code = get_avail_code(date, doc)\n",
        "    if code == 0:\n",
        "        return False\n",
        "    if code == 2 and not (B_COL_INDEX <= idx <= M_COL_INDEX):\n",
        "        return False\n",
        "    if code == 3 and not (H_COL_INDEX <= idx <= U_COL_INDEX):\n",
        "        return False\n",
        "    if H_COL_INDEX <= idx <= U_COL_INDEX:\n",
        "        if get_sched_code(date, doc):\n",
        "            return False\n",
        "    if dow == 2 and H_COL_INDEX <= idx <= U_COL_INDEX and doc in WED_FORBIDDEN_DOCTORS:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def build_date_doc_count(pattern_df):\n",
        "    \"\"\"date -> doc -> count（同日複数割当検出も兼ねる）\"\"\"\n",
        "    date_doc_count = defaultdict(lambda: defaultdict(int))\n",
        "    for (ridx, hosp), (date, fixed) in slot_meta.items():\n",
        "        val = pattern_df.at[ridx, hosp]\n",
        "        if isinstance(val, str):\n",
        "            v = val.strip()\n",
        "            if v in doctor_names:\n",
        "                date_doc_count[date][v] += 1\n",
        "    return date_doc_count\n",
        "\n",
        "def collect_violation_docs_from_assignments(doc_assignments, assigned_hosp_count):\n",
        "    bad = set()\n",
        "    # gap\n",
        "    for doc, assigns in doc_assignments.items():\n",
        "        dlist = sorted([d for d, _ in assigns])\n",
        "        for i in range(1, len(dlist)):\n",
        "            if (dlist[i] - dlist[i - 1]).days < 4:\n",
        "                bad.add(doc)\n",
        "                break\n",
        "    # hospital dup\n",
        "    for doc, hdict in assigned_hosp_count.items():\n",
        "        if any(c > 1 for c in hdict.values()):\n",
        "            bad.add(doc)\n",
        "    return bad\n",
        "\n",
        "def is_better_raw(new_raw, new_metrics, cur_raw, cur_metrics):\n",
        "    if new_raw > cur_raw:\n",
        "        return True\n",
        "    if new_raw < cur_raw:\n",
        "        return False\n",
        "    # tie-break（重要度順）\n",
        "    keys = [\n",
        "        \"unassigned_slots\",\n",
        "        \"cap_violations\",\n",
        "        \"gap_violations\",\n",
        "        \"hospital_dup_violations\",\n",
        "        \"max_minus_min_total_active\",\n",
        "        \"bg_spread_cum\",\n",
        "        \"ht_spread_cum\",\n",
        "        \"weekday_spread_cum\",\n",
        "        \"weekend_spread_cum\",\n",
        "    ]\n",
        "    return tuple(new_metrics.get(k, 0) for k in keys) < tuple(cur_metrics.get(k, 0) for k in keys)\n",
        "\n",
        "def local_search_swap(pattern_df, max_iters=2000, patience=800, refresh_every=200, seed=0):\n",
        "    \"\"\"入替（swap）局所探索：preassignedは動かさず、free枠のみを対象に改善する\"\"\"\n",
        "    if not movable_positions:\n",
        "        # 動かせる枠が無い（全部固定など）\n",
        "        counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat, *_ = recompute_stats(pattern_df)\n",
        "        score, raw_score, metrics = evaluate_schedule_with_raw(pattern_df, counts, bg_counts, ht_counts, wd_counts, we_counts)\n",
        "        return pattern_df.copy(), score, raw_score, metrics\n",
        "\n",
        "    rng = random.Random(seed)\n",
        "    df = pattern_df.copy()\n",
        "\n",
        "    counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned = recompute_stats(df)\n",
        "    cur_score, cur_raw, cur_metrics = evaluate_schedule_with_raw(df, counts, bg_counts, ht_counts, wd_counts, we_counts)\n",
        "    date_doc_count = build_date_doc_count(df)\n",
        "\n",
        "    no_improve = 0\n",
        "    bad_positions = None\n",
        "\n",
        "    for it in range(1, max_iters + 1):\n",
        "        if no_improve >= patience:\n",
        "            break\n",
        "\n",
        "        if it == 1 or it % refresh_every == 0:\n",
        "            bad_docs = collect_violation_docs_from_assignments(doc_assignments, assigned_hosp_count)\n",
        "            if bad_docs:\n",
        "                tmp = []\n",
        "                for (ridx, hosp, date) in movable_positions:\n",
        "                    v = df.at[ridx, hosp]\n",
        "                    if isinstance(v, str) and v.strip() in bad_docs:\n",
        "                        tmp.append((ridx, hosp, date))\n",
        "                bad_positions = tmp if tmp else None\n",
        "            else:\n",
        "                bad_positions = None\n",
        "\n",
        "        p1 = rng.choice(bad_positions if bad_positions is not None else movable_positions)\n",
        "        p2 = rng.choice(movable_positions)\n",
        "        if p1 == p2:\n",
        "            no_improve += 1\n",
        "            continue\n",
        "\n",
        "        r1, h1, d1 = p1\n",
        "        r2, h2, d2 = p2\n",
        "\n",
        "        v1 = df.at[r1, h1]\n",
        "        v2 = df.at[r2, h2]\n",
        "        if not (isinstance(v1, str) and isinstance(v2, str)):\n",
        "            no_improve += 1\n",
        "            continue\n",
        "\n",
        "        doc1 = v1.strip()\n",
        "        doc2 = v2.strip()\n",
        "        if doc1 not in doctor_names or doc2 not in doctor_names:\n",
        "            no_improve += 1\n",
        "            continue\n",
        "        if doc1 == doc2:\n",
        "            no_improve += 1\n",
        "            continue\n",
        "\n",
        "        # 同日重複を作らない\n",
        "        if d1 != d2:\n",
        "            if date_doc_count[d2].get(doc1, 0) > 0:\n",
        "                no_improve += 1\n",
        "                continue\n",
        "            if date_doc_count[d1].get(doc2, 0) > 0:\n",
        "                no_improve += 1\n",
        "                continue\n",
        "\n",
        "        # ハード制約\n",
        "        if not can_assign_doc_to_slot(doc1, d2, h2):\n",
        "            no_improve += 1\n",
        "            continue\n",
        "        if not can_assign_doc_to_slot(doc2, d1, h1):\n",
        "            no_improve += 1\n",
        "            continue\n",
        "\n",
        "        # swap（in-place）\n",
        "        df.at[r1, h1], df.at[r2, h2] = doc2, doc1\n",
        "\n",
        "        # date_doc_count 更新\n",
        "        if d1 != d2:\n",
        "            date_doc_count[d1][doc1] -= 1\n",
        "            if date_doc_count[d1][doc1] <= 0:\n",
        "                del date_doc_count[d1][doc1]\n",
        "            date_doc_count[d2][doc2] -= 1\n",
        "            if date_doc_count[d2][doc2] <= 0:\n",
        "                del date_doc_count[d2][doc2]\n",
        "            date_doc_count[d1][doc2] += 1\n",
        "            date_doc_count[d2][doc1] += 1\n",
        "\n",
        "        # 再評価（全再計算）\n",
        "        counts2, bg2, ht2, wd2, we2, bg_cat2, assigned_hosp_count2, doc_assignments2, unassigned2 = recompute_stats(df)\n",
        "        new_score, new_raw, new_metrics = evaluate_schedule_with_raw(df, counts2, bg2, ht2, wd2, we2)\n",
        "\n",
        "        if is_better_raw(new_raw, new_metrics, cur_raw, cur_metrics):\n",
        "            cur_score, cur_raw, cur_metrics = new_score, new_raw, new_metrics\n",
        "            counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat = counts2, bg2, ht2, wd2, we2, bg_cat2\n",
        "            assigned_hosp_count, doc_assignments = assigned_hosp_count2, doc_assignments2\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            # revert\n",
        "            df.at[r1, h1], df.at[r2, h2] = doc1, doc2\n",
        "            if d1 != d2:\n",
        "                date_doc_count[d1][doc2] -= 1\n",
        "                if date_doc_count[d1][doc2] <= 0:\n",
        "                    del date_doc_count[d1][doc2]\n",
        "                date_doc_count[d2][doc1] -= 1\n",
        "                if date_doc_count[d2][doc1] <= 0:\n",
        "                    del date_doc_count[d2][doc1]\n",
        "                date_doc_count[d1][doc1] += 1\n",
        "                date_doc_count[d2][doc2] += 1\n",
        "            no_improve += 1\n",
        "\n",
        "    return df, cur_score, cur_raw, cur_metrics\n",
        "\n",
        "# =========================\n",
        "# サマリー列（Sheet4 の列を基準に自動生成）\n",
        "# =========================\n",
        "META_COLS_SHEET4 = {\"カテ当番\", \"出張日\", \"出張先\"}\n",
        "BASE_SUMMARY_COLS = {\"全合計\", \"大学合計\", \"外病院合計\", \"平日\", \"休日合計\"}\n",
        "\n",
        "UNIV7_SET = {\"大学平日\", \"大学土曜昼\", \"大学土曜夜\", \"大学日曜昼\", \"大学日曜夜\", \"大学祝日昼\", \"大学祝日夜\"}\n",
        "UNIV7_ORDER = [c for c in sheet4_raw_out.columns if c in UNIV7_SET]\n",
        "if not UNIV7_ORDER:\n",
        "    UNIV7_ORDER = [\"大学土曜昼\", \"大学土曜夜\", \"大学日曜昼\", \"大学日曜夜\", \"大学祝日昼\", \"大学祝日夜\", \"大学平日\"]\n",
        "\n",
        "DETAIL_COLS = [\n",
        "    c for c in sheet4_raw_out.columns\n",
        "    if c not in META_COLS_SHEET4 and c not in [\"氏名\"] and c not in BASE_SUMMARY_COLS and c not in UNIV7_SET\n",
        "]\n",
        "\n",
        "SUMMARY_DETAIL_COLS = UNIV7_ORDER + DETAIL_COLS\n",
        "SUMMARY_COLS = [\"氏名\", \"全合計\", \"大学合計\", \"外病院合計\", \"平日\", \"休日合計\"] + SUMMARY_DETAIL_COLS\n",
        "\n",
        "def count_doc_in_column(df, colname, doc):\n",
        "    if colname not in df.columns:\n",
        "        return 0\n",
        "    s = df[colname]\n",
        "    cnt = 0\n",
        "    for v in s:\n",
        "        if isinstance(v, str) and v.strip() == doc:\n",
        "            cnt += 1\n",
        "    return cnt\n",
        "\n",
        "def build_summaries(pattern_df, counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat_local):\n",
        "    rows_month = []\n",
        "    rows_total = []\n",
        "\n",
        "    uni_map = {\n",
        "        \"大学平日\": \"平日\",\n",
        "        \"大学土曜昼\": \"土曜昼\",\n",
        "        \"大学土曜夜\": \"土曜夜\",\n",
        "        \"大学日曜昼\": \"日曜昼\",\n",
        "        \"大学日曜夜\": \"日曜夜\",\n",
        "        \"大学祝日昼\": \"祝日昼\",\n",
        "        \"大学祝日夜\": \"祝日夜\",\n",
        "    }\n",
        "\n",
        "    for doc in doctor_names:\n",
        "        pname = name_match.get(doc)\n",
        "        base_row = name_to_row.get(pname) if pname and pname in name_to_row else None\n",
        "\n",
        "        def prev_val(colname):\n",
        "            if base_row is None:\n",
        "                return 0.0\n",
        "            v = base_row.get(colname, 0)\n",
        "            try:\n",
        "                return float(v or 0)\n",
        "            except Exception:\n",
        "                return 0.0\n",
        "\n",
        "        # 今月\n",
        "        row_m = {c: 0.0 for c in SUMMARY_COLS}\n",
        "        row_m[\"氏名\"] = doc\n",
        "        row_m[\"全合計\"] = float(counts.get(doc, 0))\n",
        "        row_m[\"大学合計\"] = float(bg_counts.get(doc, 0))\n",
        "        row_m[\"外病院合計\"] = float(ht_counts.get(doc, 0))\n",
        "        row_m[\"平日\"] = float(wd_counts.get(doc, 0))\n",
        "        row_m[\"休日合計\"] = float(we_counts.get(doc, 0))\n",
        "\n",
        "        # 大学7分類\n",
        "        for col in UNIV7_ORDER:\n",
        "            cat = uni_map.get(col)\n",
        "            if cat:\n",
        "                row_m[col] = float(bg_cat_local[doc].get(cat, 0))\n",
        "\n",
        "        # 病院列（Sheet4準拠）をそのまま数える\n",
        "        for col in DETAIL_COLS:\n",
        "            row_m[col] = float(count_doc_in_column(pattern_df, col, doc))\n",
        "\n",
        "        # 累計（前月＋今月）\n",
        "        row_t = {c: 0.0 for c in SUMMARY_COLS}\n",
        "        row_t[\"氏名\"] = doc\n",
        "        for c in SUMMARY_COLS:\n",
        "            if c == \"氏名\":\n",
        "                continue\n",
        "            row_t[c] = prev_val(c) + float(row_m.get(c, 0))\n",
        "\n",
        "        rows_month.append(row_m)\n",
        "        rows_total.append(row_t)\n",
        "\n",
        "    return pd.DataFrame(rows_month)[SUMMARY_COLS], pd.DataFrame(rows_total)[SUMMARY_COLS]\n",
        "\n",
        "# =========================\n",
        "# 診断シート生成（偏り & gap違反一覧）\n",
        "# =========================\n",
        "def build_gap_details(doc_assignments):\n",
        "    rows = []\n",
        "    for doc, assigns in doc_assignments.items():\n",
        "        assigns_sorted = sorted(assigns, key=lambda x: (x[0], x[1]))\n",
        "        for i in range(1, len(assigns_sorted)):\n",
        "            d_prev, h_prev = assigns_sorted[i - 1]\n",
        "            d_cur, h_cur = assigns_sorted[i]\n",
        "            gap = (d_cur - d_prev).days\n",
        "            if gap < 4:\n",
        "                rows.append({\n",
        "                    \"氏名\": doc,\n",
        "                    \"前回日付\": d_prev,\n",
        "                    \"前回病院\": h_prev,\n",
        "                    \"今回日付\": d_cur,\n",
        "                    \"今回病院\": h_cur,\n",
        "                    \"間隔(日)\": gap,\n",
        "                })\n",
        "    cols = [\"氏名\", \"前回日付\", \"前回病院\", \"今回日付\", \"今回病院\", \"間隔(日)\"]\n",
        "    if not rows:\n",
        "        return pd.DataFrame(columns=cols)\n",
        "    return pd.DataFrame(rows)[cols].sort_values([\"氏名\", \"今回日付\"]).reset_index(drop=True)\n",
        "\n",
        "def build_same_day_duplicates(doc_assignments):\n",
        "    rows = []\n",
        "    for doc, assigns in doc_assignments.items():\n",
        "        by_date = defaultdict(list)\n",
        "        for d, h in assigns:\n",
        "            by_date[d].append(h)\n",
        "        for d, hs in by_date.items():\n",
        "            if len(hs) > 1:\n",
        "                rows.append({\"氏名\": doc, \"日付\": d, \"件数\": len(hs), \"病院\": \", \".join(sorted(hs))})\n",
        "    cols = [\"氏名\", \"日付\", \"件数\", \"病院\"]\n",
        "    if not rows:\n",
        "        return pd.DataFrame(columns=cols)\n",
        "    return pd.DataFrame(rows)[cols].sort_values([\"日付\", \"氏名\"]).reset_index(drop=True)\n",
        "\n",
        "def build_hosp_dup_details(assigned_hosp_count):\n",
        "    rows = []\n",
        "    for doc, hdict in assigned_hosp_count.items():\n",
        "        for hosp, c in hdict.items():\n",
        "            if c > 1:\n",
        "                rows.append({\"氏名\": doc, \"病院\": hosp, \"回数\": c, \"超過\": c - 1})\n",
        "    cols = [\"氏名\", \"病院\", \"回数\", \"超過\"]\n",
        "    if not rows:\n",
        "        return pd.DataFrame(columns=cols)\n",
        "    return pd.DataFrame(rows)[cols].sort_values([\"超過\", \"氏名\"], ascending=[False, True]).reset_index(drop=True)\n",
        "\n",
        "def build_unassigned_details(unassigned):\n",
        "    rows = [{\"日付\": d, \"病院\": hosp, \"row_index\": ridx} for d, hosp, ridx in unassigned]\n",
        "    cols = [\"日付\", \"病院\", \"row_index\"]\n",
        "    if not rows:\n",
        "        return pd.DataFrame(columns=cols)\n",
        "    return pd.DataFrame(rows)[cols].sort_values([\"日付\", \"病院\"]).reset_index(drop=True)\n",
        "\n",
        "def build_doctor_diag(counts, bg_counts, ht_counts, wd_counts, we_counts, doc_assignments, assigned_hosp_count):\n",
        "    rows = []\n",
        "    active_set = set(active_doctors)\n",
        "\n",
        "    for doc in doctor_names:\n",
        "        assigns = sorted(doc_assignments.get(doc, []), key=lambda x: x[0])\n",
        "        gaps = [(assigns[i][0] - assigns[i - 1][0]).days for i in range(1, len(assigns))]\n",
        "        gap_viol = sum(1 for g in gaps if g < 4)\n",
        "        min_gap = min(gaps) if gaps else None\n",
        "        hosp_excess = sum(max(0, c - 1) for c in assigned_hosp_count.get(doc, {}).values())\n",
        "\n",
        "        row = {\n",
        "            \"氏名\": doc,\n",
        "            \"active\": 1 if doc in active_set else 0,\n",
        "            \"cap\": TARGET_CAP.get(doc, 0),\n",
        "            \"preassigned\": preassigned_count.get(doc, 0),\n",
        "\n",
        "            \"今月_全合計\": counts.get(doc, 0),\n",
        "            \"累計_全合計\": prev_total.get(doc, 0) + counts.get(doc, 0),\n",
        "\n",
        "            \"今月_大学合計\": bg_counts.get(doc, 0),\n",
        "            \"累計_大学合計\": prev_bg.get(doc, 0) + bg_counts.get(doc, 0),\n",
        "\n",
        "            \"今月_外病院合計\": ht_counts.get(doc, 0),\n",
        "            \"累計_外病院合計\": prev_ht.get(doc, 0) + ht_counts.get(doc, 0),\n",
        "\n",
        "            \"今月_平日\": wd_counts.get(doc, 0),\n",
        "            \"累計_平日\": prev_weekday.get(doc, 0) + wd_counts.get(doc, 0),\n",
        "\n",
        "            \"今月_休日合計\": we_counts.get(doc, 0),\n",
        "            \"累計_休日合計\": prev_weekend.get(doc, 0) + we_counts.get(doc, 0),\n",
        "\n",
        "            \"gap違反回数\": gap_viol,\n",
        "            \"最小間隔(日)\": min_gap if min_gap is not None else \"\",\n",
        "            \"同一病院重複超過\": hosp_excess,\n",
        "        }\n",
        "        rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # 偏り（active平均との差）も出しておく\n",
        "    active_rows = df[df[\"active\"] == 1]\n",
        "    for col in [\"累計_全合計\", \"累計_大学合計\", \"累計_外病院合計\", \"累計_平日\", \"累計_休日合計\"]:\n",
        "        if len(active_rows) > 0:\n",
        "            mean_val = float(active_rows[col].mean())\n",
        "            df[col + \"_平均との差\"] = df[col] - mean_val\n",
        "        else:\n",
        "            df[col + \"_平均との差\"] = 0.0\n",
        "\n",
        "    return df.sort_values([\"active\", \"累計_全合計\"], ascending=[False, False]).reset_index(drop=True)\n",
        "\n",
        "def build_metrics_df(score_clamped, raw_score, metrics):\n",
        "    row = {\"score\": float(score_clamped), \"raw_score\": float(raw_score), **metrics}\n",
        "    return pd.DataFrame([row])\n",
        "\n",
        "def build_diagnostics(pattern_df):\n",
        "    counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned = recompute_stats(pattern_df)\n",
        "    score, raw, metrics = evaluate_schedule_with_raw(pattern_df, counts, bg_counts, ht_counts, wd_counts, we_counts)\n",
        "\n",
        "    df_doctors = build_doctor_diag(counts, bg_counts, ht_counts, wd_counts, we_counts, doc_assignments, assigned_hosp_count)\n",
        "    df_gap = build_gap_details(doc_assignments)\n",
        "    df_same = build_same_day_duplicates(doc_assignments)\n",
        "    df_hdup = build_hosp_dup_details(assigned_hosp_count)\n",
        "    df_unass = build_unassigned_details(unassigned)\n",
        "    df_metrics = build_metrics_df(score, raw, metrics)\n",
        "\n",
        "    return df_doctors, df_gap, df_same, df_hdup, df_unass, df_metrics\n",
        "\n",
        "# =========================\n",
        "# パターン探索（greedy → top候補に局所探索 → top3）\n",
        "# =========================\n",
        "score_rows = []\n",
        "candidates = []  # TOP_KEEPだけ保持\n",
        "\n",
        "for i in range(1, NUM_PATTERNS + 1):\n",
        "    pattern_df, counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat = build_schedule_pattern(seed=i)\n",
        "    score, raw_score, metrics = evaluate_schedule_with_raw(pattern_df, counts, bg_counts, ht_counts, wd_counts, we_counts)\n",
        "\n",
        "    score_rows.append({\"seed\": i, \"score\": score, \"raw_score\": raw_score, **metrics})\n",
        "\n",
        "    candidates.append({\n",
        "        \"seed\": i,\n",
        "        \"score\": score,\n",
        "        \"raw_score\": raw_score,\n",
        "        \"metrics\": metrics,\n",
        "        \"pattern_df\": pattern_df,\n",
        "    })\n",
        "    candidates = sorted(candidates, key=lambda e: e[\"raw_score\"], reverse=True)[:TOP_KEEP]\n",
        "\n",
        "# ローカル探索で候補を改善\n",
        "refined = []\n",
        "for cand in candidates[:REFINE_TOP]:\n",
        "    if LOCAL_SEARCH_ENABLED:\n",
        "        improved_df, sc2, raw2, met2 = local_search_swap(\n",
        "            cand[\"pattern_df\"],\n",
        "            max_iters=LOCAL_MAX_ITERS,\n",
        "            patience=LOCAL_PATIENCE,\n",
        "            refresh_every=LOCAL_REFRESH_EVERY,\n",
        "            seed=1000 + cand[\"seed\"],\n",
        "        )\n",
        "    else:\n",
        "        improved_df = cand[\"pattern_df\"]\n",
        "        sc2 = cand[\"score\"]\n",
        "        raw2 = cand[\"raw_score\"]\n",
        "        met2 = cand[\"metrics\"]\n",
        "\n",
        "    refined.append({\n",
        "        \"seed\": cand[\"seed\"],\n",
        "        \"score_before\": cand[\"score\"],\n",
        "        \"raw_before\": cand[\"raw_score\"],\n",
        "        \"score_after\": sc2,\n",
        "        \"raw_after\": raw2,\n",
        "        \"metrics_after\": met2,\n",
        "        \"pattern_df\": improved_df,\n",
        "    })\n",
        "\n",
        "refined_sorted = sorted(refined, key=lambda e: e[\"raw_after\"], reverse=True)\n",
        "top_patterns = refined_sorted[:3]\n",
        "\n",
        "scores_df = pd.DataFrame(score_rows).sort_values([\"raw_score\", \"seed\"], ascending=[False, True]).reset_index(drop=True)\n",
        "\n",
        "refined_df = pd.DataFrame([\n",
        "    {\n",
        "        \"seed\": e[\"seed\"],\n",
        "        \"score_before\": e[\"score_before\"],\n",
        "        \"raw_before\": e[\"raw_before\"],\n",
        "        \"score_after\": e[\"score_after\"],\n",
        "        \"raw_after\": e[\"raw_after\"],\n",
        "        **{f\"after_{k}\": v for k, v in e[\"metrics_after\"].items() if k not in (\"raw_score\", \"penalty_total\")},\n",
        "    }\n",
        "    for e in refined_sorted\n",
        "]).sort_values([\"raw_after\", \"seed\"], ascending=[False, True]).reset_index(drop=True)\n",
        "\n",
        "print(\"=== top refined (raw) ===\")\n",
        "print(refined_df.head(10))\n",
        "\n",
        "# =========================\n",
        "# 出力（pattern + summary + diagnostics）\n",
        "# =========================\n",
        "base_name = uploaded_filename.rsplit(\".\", 1)[0]\n",
        "output_filename = f\"{base_name}_auto_schedules_with_localsearch_diagnostics.xlsx\"\n",
        "output_path = output_filename\n",
        "\n",
        "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
        "    # 元シート\n",
        "    shift_df.to_excel(writer, sheet_name=\"sheet1\", index=False)\n",
        "    availability_raw.to_excel(writer, sheet_name=\"sheet2\", index=False)\n",
        "    schedule_raw.to_excel(writer, sheet_name=\"sheet3\", index=False)\n",
        "    sheet4_raw_out.to_excel(writer, sheet_name=\"sheet4\", index=False)\n",
        "\n",
        "    # スコア一覧\n",
        "    scores_df.to_excel(writer, sheet_name=\"scores\", index=False)\n",
        "\n",
        "    # ローカル探索の改善一覧\n",
        "    refined_df.to_excel(writer, sheet_name=\"refined_candidates\", index=False)\n",
        "\n",
        "    # TOP3出力\n",
        "    for rank, entry in enumerate(top_patterns, start=1):\n",
        "        sheet_label = f\"pattern_{rank:02d}\"\n",
        "        entry[\"pattern_df\"].to_excel(writer, sheet_name=sheet_label, index=False)\n",
        "\n",
        "        # summary（今月/累計）\n",
        "        counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat, *_ = recompute_stats(entry[\"pattern_df\"])\n",
        "        df_month, df_total = build_summaries(entry[\"pattern_df\"], counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat)\n",
        "        df_month.to_excel(writer, sheet_name=f\"{sheet_label}_今月\", index=False)\n",
        "        df_total.to_excel(writer, sheet_name=f\"{sheet_label}_累計\", index=False)\n",
        "\n",
        "        # diagnostics\n",
        "        df_doctors, df_gap, df_same, df_hdup, df_unass, df_metrics = build_diagnostics(entry[\"pattern_df\"])\n",
        "        df_doctors.to_excel(writer, sheet_name=f\"{sheet_label}_diag_doctors\", index=False)\n",
        "        df_gap.to_excel(writer, sheet_name=f\"{sheet_label}_diag_gap\", index=False)\n",
        "        df_same.to_excel(writer, sheet_name=f\"{sheet_label}_diag_sameday\", index=False)\n",
        "        df_hdup.to_excel(writer, sheet_name=f\"{sheet_label}_diag_hospdup\", index=False)\n",
        "        df_unass.to_excel(writer, sheet_name=f\"{sheet_label}_diag_unassigned\", index=False)\n",
        "        df_metrics.to_excel(writer, sheet_name=f\"{sheet_label}_diag_metrics\", index=False)\n",
        "\n",
        "print(\"完了。出力ファイル:\", output_path)\n",
        "files.download(output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lXKPFtUArc3J",
        "outputId": "a50e5aa4-a3dd-4fd4-b44f-eb7e7cae8d04",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sheet1〜sheet4（またはSheet4）が入った当直Excelファイルを選択してください\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6f24bb69-1731-43cf-baae-03ec0cbb4378\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6f24bb69-1731-43cf-baae-03ec0cbb4378\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tochoku.ver9_2026.01.xlsx to Tochoku.ver9_2026.01.xlsx\n",
            "=== Target summary ===\n",
            "total_slots: 112\n",
            "active: 31 inactive: 1 inactive_doctors: ['大和田']\n",
            "BASE_TARGET: 3 EXTRA_SLOTS: 19\n",
            "=== top refined (raw) ===\n",
            "   seed  score_before  raw_before  score_after  raw_after  \\\n",
            "0  1087          41.0        41.0         72.0       72.0   \n",
            "1  2894          42.0        42.0         72.0       72.0   \n",
            "2  4820          38.0        38.0         71.0       71.0   \n",
            "3  4683          41.0        41.0         68.0       68.0   \n",
            "4  3798          38.0        38.0         66.0       66.0   \n",
            "5  6847          39.0        39.0         66.0       66.0   \n",
            "6  5770          38.0        38.0         65.0       65.0   \n",
            "7   174          39.0        39.0         64.0       64.0   \n",
            "8  1642          43.0        43.0         64.0       64.0   \n",
            "9  4556          41.0        41.0         64.0       64.0   \n",
            "\n",
            "   after_max_minus_min_total_active  after_gap_violations  \\\n",
            "0                                 1                     0   \n",
            "1                                 1                     0   \n",
            "2                                 1                     0   \n",
            "3                                 1                     0   \n",
            "4                                 1                     0   \n",
            "5                                 1                     0   \n",
            "6                                 1                     0   \n",
            "7                                 1                     0   \n",
            "8                                 1                     0   \n",
            "9                                 1                     1   \n",
            "\n",
            "   after_hospital_dup_violations  after_unassigned_slots  \\\n",
            "0                              0                       0   \n",
            "1                              0                       0   \n",
            "2                              1                       0   \n",
            "3                              1                       0   \n",
            "4                              0                       0   \n",
            "5                              0                       0   \n",
            "6                              1                       0   \n",
            "7                              0                       0   \n",
            "8                              1                       0   \n",
            "9                              0                       0   \n",
            "\n",
            "   after_cap_violations  after_bg_spread_cum  after_ht_spread_cum  \\\n",
            "0                     0                  3.0                  5.0   \n",
            "1                     0                  3.0                  5.0   \n",
            "2                     0                  4.0                  5.0   \n",
            "3                     0                  4.0                  5.0   \n",
            "4                     0                  4.0                  6.0   \n",
            "5                     0                  4.0                  6.0   \n",
            "6                     0                  4.0                  5.0   \n",
            "7                     0                  4.0                  6.0   \n",
            "8                     0                  4.0                  5.0   \n",
            "9                     0                  3.0                  5.0   \n",
            "\n",
            "   after_weekday_spread_cum  after_weekend_spread_cum  \n",
            "0                       3.0                       3.0  \n",
            "1                       3.0                       3.0  \n",
            "2                       3.0                       2.0  \n",
            "3                       3.0                       3.0  \n",
            "4                       3.0                       3.0  \n",
            "5                       3.0                       3.0  \n",
            "6                       3.0                       4.0  \n",
            "7                       4.0                       3.0  \n",
            "8                       5.0                       3.0  \n",
            "9                       4.0                       4.0  \n",
            "完了。出力ファイル: Tochoku.ver9_2026.01_auto_schedules_with_localsearch_diagnostics.xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7089a3b0-46a2-4a4d-8acd-9078ee06780d\", \"Tochoku.ver9_2026.01_auto_schedules_with_localsearch_diagnostics.xlsx\", 515072)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}