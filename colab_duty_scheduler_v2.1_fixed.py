# @title å½“ç›´ãã‚“ v2.1 (ãƒã‚°ä¿®æ­£ç‰ˆ)
# ä¿®æ­£å†…å®¹:
# - ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å•é¡Œã®ä¿®æ­£
# - åŒ»å¸«åã®æ­£è¦åŒ–ï¼ˆç©ºç™½é™¤å»ï¼‰
# - sheet4ãƒ˜ãƒƒãƒ€æ¤œå‡ºç¯„å›²ã®æ‹¡å¤§ï¼ˆ30â†’50è¡Œï¼‰
# - date_doc_countã®KeyErrorå¯¾ç­–ï¼ˆdefaultdictåŒ–ï¼‰
# - åŒæ—¥é‡è¤‡ãƒã‚§ãƒƒã‚¯ã®å¼·åŒ–
# - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ”¹å–„

import io
import pandas as pd
import numpy as np
from collections import defaultdict
import random
import importlib.util
import os

COLAB_AVAILABLE = (
    importlib.util.find_spec("google") is not None
    and importlib.util.find_spec("google.colab") is not None
)
if COLAB_AVAILABLE:
    from google.colab import files

# =========================
# ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š
# =========================
HOLIDAYS = set()  # ç¥æ—¥ã‚’å…¥ã‚Œã‚‹ãªã‚‰ã“ã“ï¼ˆä¾‹: {pd.Timestamp("2026-01-01"), ...}ï¼‰
BG_DAY_COLS = set()    # åˆ—åã§ã€Œæ˜¼ã€å›ºå®šã—ãŸã„å¤§å­¦æ ãŒã‚ã‚Œã°è¿½åŠ 
BG_NIGHT_COLS = set()  # åˆ—åã§ã€Œå¤œã€å›ºå®šã—ãŸã„å¤§å­¦æ ãŒã‚ã‚Œã°è¿½åŠ 

WED_FORBIDDEN_DOCTORS = {'é‡‘åŸ', 'å±±ç”°', 'é‡å¯º'}  # æ°´æ›œã® Hã€œU ã‚’ç¦æ­¢ã—ãŸã„åŒ»å¸«

NUM_PATTERNS = int(os.getenv("NUM_PATTERNS", "10000"))  # 100/1000/10000 ãªã©

# sheet1 ã®ã€Œæ ã€æ‰±ã„ã™ã‚‹å…¥åŠ›å€¤ï¼ˆ1ä»¥å¤–ã®è¨˜å·ã‚‚è¨±å®¹ã—ãŸã„å ´åˆï¼‰
SLOT_MARKERS = {1, 1.0, "1", "ã€‡", "â—‹", "â—¯", "â—"}

# --- ãƒ­ãƒ¼ã‚«ãƒ«æ¢ç´¢ï¼ˆå…¥æ›¿ï¼‰è¨­å®š ---
LOCAL_SEARCH_ENABLED = True
TOP_KEEP = 15                 # greedyã§æ®‹ã™å€™è£œæ•°ï¼ˆã“ã®ä¸­ã«æœ€è‰¯ãŒæ®‹ã‚‹ç¢ºç‡â†‘ï¼‰
REFINE_TOP = 15               # ãƒ­ãƒ¼ã‚«ãƒ«æ¢ç´¢ã‚’ã‹ã‘ã‚‹å€™è£œæ•°ï¼ˆ<= TOP_KEEPï¼‰
LOCAL_MAX_ITERS = 3000        # 1å€™è£œã‚ãŸã‚Šã®å…¥æ›¿è©¦è¡Œå›æ•°
LOCAL_PATIENCE = 1200         # æ”¹å–„ãŒå‡ºãªã„è©¦è¡ŒãŒã“ã®å›æ•°ç¶šã„ãŸã‚‰æ‰“ã¡åˆ‡ã‚Š
LOCAL_REFRESH_EVERY = 200     # å•é¡ŒåŒ»å¸«ï¼ˆgap/é‡è¤‡ï¼‰ã‚’å†æŠ½å‡ºã™ã‚‹é–“éš”

# ã‚¹ã‚³ã‚¢é‡ã¿ï¼ˆå¿…è¦ãªã‚‰èª¿æ•´ï¼‰
W_FAIR_TOTAL = 10          # å…¨åˆè¨ˆï¼ˆactiveå†… max-min-1ï¼‰
W_GAP = 3                  # gap(4æ—¥æœªæº€)
W_HOSP_DUP = 1             # åŒä¸€ç—…é™¢è¤‡æ•°å›
W_UNASSIGNED = 100         # æœªå‰²å½“
W_CAP = 50                 # capè¶…ãˆ
W_BG_SPREAD = 3            # å¤§å­¦åˆè¨ˆï¼ˆç´¯è¨ˆï¼‰ã°ã‚‰ã¤ã
W_HT_SPREAD = 3            # å¤–ç—…é™¢åˆè¨ˆï¼ˆç´¯è¨ˆï¼‰ã°ã‚‰ã¤ã
W_WD_SPREAD = 2            # å¹³æ—¥ï¼ˆç´¯è¨ˆï¼‰ã°ã‚‰ã¤ã
W_WE_SPREAD = 3            # ä¼‘æ—¥åˆè¨ˆï¼ˆç´¯è¨ˆï¼‰ã°ã‚‰ã¤ã
W_BK_LY_BALANCE = 2        # B-K/L-Y ã®æ¯”ç‡ãƒãƒ©ãƒ³ã‚¹ï¼ˆãªã‚‹ã¹ã1:1ï¼‰

# =========================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================
def strip_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [c.strip() if isinstance(c, str) else c for c in df.columns]
    return df

def make_unique(names):
    """é‡è¤‡åˆ—åã‚’ _2, _3 ... ã§ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–"""
    seen = {}
    out = []
    for n in names:
        n = "" if pd.isna(n) else n
        if n not in seen:
            seen[n] = 1
            out.append(n)
        else:
            seen[n] += 1
            out.append(f"{n}_{seen[n]}")
    return out

def safe_str(x):
    if pd.isna(x):
        return ""
    return str(x).strip()

# ğŸ”§ FIX: åŒ»å¸«åã®æ­£è¦åŒ–é–¢æ•°ã‚’è¿½åŠ 
def normalize_name(name):
    """åŒ»å¸«åã‚’æ­£è¦åŒ–ï¼ˆå…¨è§’/åŠè§’ã‚¹ãƒšãƒ¼ã‚¹é™¤å»ï¼‰"""
    if pd.isna(name):
        return ""
    return str(name).strip().replace(" ", "").replace("ã€€", "")

def find_sheet_name(xls: pd.ExcelFile, target: str):
    """sheetåã®å¤§å°ãƒ»è¡¨è¨˜ã‚†ã‚Œã«è€ãˆã‚‹"""
    if target in xls.sheet_names:
        return target
    low_map = {s.lower(): s for s in xls.sheet_names}
    if target.lower() in low_map:
        return low_map[target.lower()]
    for s in xls.sheet_names:
        if s.strip().lower() == target.strip().lower():
            return s
    return None

def is_slot_value(v) -> bool:
    if isinstance(v, str):
        return v.strip() in SLOT_MARKERS
    if isinstance(v, (int, float, np.integer, np.floating)):
        return float(v) == 1.0
    return False

# =========================
# sheet4 èª­ã¿è¾¼ã¿ï¼ˆãƒ˜ãƒƒãƒ€è¡Œè‡ªå‹•æ¤œå‡ºï¼‹é‡è¤‡è€æ€§ï¼‰
# ğŸ”§ FIX: æ¤œç´¢ç¯„å›²ã‚’30â†’50è¡Œã«æ‹¡å¤§
# =========================
def parse_sheet4_from_grid(grid: pd.DataFrame) -> pd.DataFrame:
    g = grid.copy()
    g = g.dropna(how="all").reset_index(drop=True)

    if len(g) == 0:
        raise ValueError("sheet4 ãŒç©ºã§ã™")

    # ãƒ˜ãƒƒãƒ€è¡Œã‚’æ¢ã™ï¼ˆ'æ°å' ãŒã‚ã‚‹è¡Œï¼‰
    header_row_idx = None
    search_limit = min(50, len(g))  # ğŸ”§ FIX: 30â†’50ã«æ‹¡å¤§
    for i in range(search_limit):
        row = g.iloc[i].astype(str).str.strip()
        if (row == "æ°å").any():
            header_row_idx = i
            break
    if header_row_idx is None:
        raise ValueError(f"sheet4 ã®ãƒ˜ãƒƒãƒ€è¡Œã« 'æ°å' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆå…ˆé ­{search_limit}è¡Œã‚’æ¤œç´¢ï¼‰")

    headers = [safe_str(x) for x in g.iloc[header_row_idx].tolist()]
    headers = [h if (h != "" and h.lower() != "nan") else f"Unnamed_{j}" for j, h in enumerate(headers)]
    headers = make_unique(headers)

    data = g.iloc[header_row_idx + 1:].reset_index(drop=True)
    data.columns = headers

    if "æ°å" not in data.columns:
        raise ValueError("sheet4 ã®ãƒ˜ãƒƒãƒ€è¡Œã« 'æ°å' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆsheet4ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰")

    # æ°åã®ç©ºè¡Œå‰Šé™¤
    data["æ°å"] = data["æ°å"].astype(str).str.strip()
    data = data[(data["æ°å"].notna()) & (data["æ°å"] != "") & (data["æ°å"].str.lower() != "nan")].reset_index(drop=True)

    # æ•°å€¤åŒ–ï¼ˆæ°åä»¥å¤–ï¼‰
    for col in data.columns:
        if col == "æ°å":
            continue
        data[col] = pd.to_numeric(data[col], errors="coerce").fillna(0)

    return data

# =========================
# å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# =========================
print("="*60)
print("   å½“ç›´ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è‡ªå‹•ç”Ÿæˆãƒ„ãƒ¼ãƒ« v2.1 (ãƒã‚°ä¿®æ­£ç‰ˆ)")
print("="*60)
print("\nã€ä¸»ãªä¿®æ­£å†…å®¹ã€‘")
print("âœ… ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å•é¡Œã®ä¿®æ­£")
print("âœ… åŒ»å¸«åã®æ­£è¦åŒ–ï¼ˆç©ºç™½ã«ã‚ˆã‚‹åˆ¶ç´„ãƒŸã‚¹ã‚’é˜²æ­¢ï¼‰")
print("âœ… sheet4ãƒ˜ãƒƒãƒ€æ¤œå‡ºç¯„å›²ã®æ‹¡å¤§ï¼ˆ30â†’50è¡Œï¼‰")
print("âœ… date_doc_countã®KeyErrorå¯¾ç­–")
print("âœ… åŒæ—¥é‡è¤‡ãƒã‚§ãƒƒã‚¯ã®å¼·åŒ–")
print("="*60)
print("\nã€ä½¿ã„æ–¹ã€‘")
print("1. ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã§Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ")
print("2. å‡¦ç†ãŒè‡ªå‹•ã§é–‹å§‹ã•ã‚Œã¾ã™ï¼ˆ5-10åˆ†ã‹ã‹ã‚Šã¾ã™ï¼‰")
print("3. å®Œäº†ã—ãŸã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
print("="*60)
print("\nsheet1ã€œsheet4ï¼ˆã¾ãŸã¯Sheet4ï¼‰ãŒå…¥ã£ãŸå½“ç›´Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")

if COLAB_AVAILABLE:
    uploaded = files.upload()
    uploaded_filename = list(uploaded.keys())[0]

    try:
        xls = pd.ExcelFile(io.BytesIO(uploaded[uploaded_filename]))
    except Exception as e:
        raise ValueError(f"âŒ Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    sheet1_name = find_sheet_name(xls, "sheet1")
    sheet2_name = find_sheet_name(xls, "sheet2")
    sheet3_name = find_sheet_name(xls, "sheet3")
    sheet4_name = find_sheet_name(xls, "sheet4") or find_sheet_name(xls, "Sheet4")

    missing = [k for k, v in [("sheet1", sheet1_name), ("sheet2", sheet2_name), ("sheet3", sheet3_name), ("sheet4", sheet4_name)] if v is None]
    if missing:
        raise ValueError(f"âŒ å¿…è¦ãªã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing}\nå®Ÿéš›ã®ã‚·ãƒ¼ãƒˆå: {xls.sheet_names}")

    # --------- Excel èª­ã¿è¾¼ã¿ ---------
    shift_df = strip_cols(pd.read_excel(xls, sheet_name=sheet1_name))
    availability_raw = strip_cols(pd.read_excel(xls, sheet_name=sheet2_name))
    schedule_raw = strip_cols(pd.read_excel(xls, sheet_name=sheet3_name))

    shift_df.columns = make_unique(list(shift_df.columns))
    availability_raw.columns = make_unique(list(availability_raw.columns))
    schedule_raw.columns = make_unique(list(schedule_raw.columns))

    # sheet4 ã¯ã€Œå‡ºåŠ›ç”¨ã€ã¨ã€Œè§£æç”¨ï¼ˆheader=Noneï¼‰ã€ã‚’åˆ†ã‘ã‚‹
    sheet4_raw_out = strip_cols(pd.read_excel(xls, sheet_name=sheet4_name))
    sheet4_raw_out.columns = make_unique(list(sheet4_raw_out.columns))

    sheet4_grid = pd.read_excel(xls, sheet_name=sheet4_name, header=None)
    sheet4_data = parse_sheet4_from_grid(sheet4_grid)
else:
    from tochoku_data_complete import DATA as LOCAL_DATA

    uploaded_filename = "Tochoku.local.xlsx"
    shift_df = strip_cols(pd.DataFrame(LOCAL_DATA["sheet1"]))
    availability_raw = strip_cols(pd.DataFrame(LOCAL_DATA["sheet2"]))
    schedule_raw = strip_cols(pd.DataFrame(LOCAL_DATA["sheet3"]))

    shift_df.columns = make_unique(list(shift_df.columns))
    availability_raw.columns = make_unique(list(availability_raw.columns))
    schedule_raw.columns = make_unique(list(schedule_raw.columns))

    sheet4_raw_out = strip_cols(pd.DataFrame(LOCAL_DATA["Sheet4"]))
    sheet4_raw_out.columns = make_unique(list(sheet4_raw_out.columns))

    sheet4_data = sheet4_raw_out.copy()
    if "æ°å" not in sheet4_data.columns:
        raise ValueError("âŒ Sheet4 ã® 'æ°å' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰")
    sheet4_data["æ°å"] = sheet4_data["æ°å"].astype(str).str.strip()
    for col in sheet4_data.columns:
        if col == "æ°å":
            continue
        sheet4_data[col] = pd.to_numeric(sheet4_data[col], errors="coerce").fillna(0)

# =========================
# æ—¥ä»˜åˆ—ã®æ•´å½¢
# ğŸ”§ FIX: ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å•é¡Œã®ä¿®æ­£
# =========================
date_col_shift = shift_df.columns[0]
shift_df[date_col_shift] = pd.to_datetime(shift_df[date_col_shift], errors="coerce").dt.normalize().dt.tz_localize(None)  # ğŸ”§ FIX
if shift_df[date_col_shift].isna().all():
    raise ValueError("âŒ sheet1 ã®å…ˆé ­åˆ—ãŒæ—¥ä»˜ã¨ã—ã¦è§£é‡ˆã§ãã¾ã›ã‚“ï¼ˆåˆ—ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰")

date_col_avail = availability_raw.columns[0]
availability_raw[date_col_avail] = pd.to_datetime(availability_raw[date_col_avail], errors="coerce").dt.normalize().dt.tz_localize(None)  # ğŸ”§ FIX
availability_df = availability_raw.set_index(date_col_avail)

date_col_sched = schedule_raw.columns[0]
schedule_raw[date_col_sched] = pd.to_datetime(schedule_raw[date_col_sched], errors="coerce").dt.normalize().dt.tz_localize(None)  # ğŸ”§ FIX
schedule_df = schedule_raw.set_index(date_col_sched)

# ğŸ”§ FIX: ç¥æ—¥ã‚‚ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æ­£è¦åŒ–
HOLIDAYS = {pd.to_datetime(d).normalize().tz_localize(None) for d in HOLIDAYS}

def is_holiday(date):
    return pd.to_datetime(date).normalize().tz_localize(None) in HOLIDAYS

# =========================
# åŸºæœ¬æƒ…å ±
# ğŸ”§ FIX: åŒ»å¸«åã‚’æ­£è¦åŒ–
# =========================
doctor_names = [normalize_name(x) for x in list(availability_raw.columns[1:])]  # ğŸ”§ FIX
doctor_col_index = {doc: idx for idx, doc in enumerate(doctor_names)}

# ğŸ”§ FIX: ç¦æ­¢åŒ»å¸«åã‚‚æ­£è¦åŒ–
WED_FORBIDDEN_DOCTORS = {normalize_name(d) for d in WED_FORBIDDEN_DOCTORS}  # ğŸ”§ FIX

hospital_cols = list(shift_df.columns[1:])
n_cols = len(shift_df.columns)

# åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ä¾å­˜ï¼šBã€œU ã‚’æƒ³å®šï¼‰
B_COL_INDEX = 1
C_COL_INDEX = 2
D_COL_INDEX = min(3, n_cols - 1)
E_COL_INDEX = min(4, n_cols - 1)
F_COL_INDEX = min(5, n_cols - 1)
G_COL_INDEX = min(6, n_cols - 1)
H_COL_INDEX = min(7, n_cols - 1)
M_COL_INDEX = min(12, n_cols - 1)
U_COL_INDEX = min(20, n_cols - 1)

B_K_START_INDEX = B_COL_INDEX
B_K_END_INDEX = min(10, n_cols - 1)
L_Y_START_INDEX = min(11, n_cols - 1)
L_Y_END_INDEX = n_cols - 1

print(f"âœ… Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
print(f"   åŒ»å¸«æ•°: {len(doctor_names)}äºº")
print(f"   ç—…é™¢åˆ—æ•°: {len(hospital_cols)}åˆ—")
print(f"   å¯¾è±¡æ—¥æ•°: {len(shift_df)}æ—¥")

# =========================
# sheet2 å¯å¦ã‚³ãƒ¼ãƒ‰
# =========================
fallback_avail_codes = {}
for doc in doctor_names:
    col_vals = availability_raw[doc]
    first_val = None
    for v in col_vals:
        if pd.notna(v):
            first_val = v
            break
    if first_val is None:
        fallback_avail_codes[doc] = 1
    else:
        try:
            c = int(first_val)
        except Exception:
            c = 1
        if c not in (0, 1, 2, 3):
            c = 1
        fallback_avail_codes[doc] = c

def get_avail_code(date, doctor):
    code = None
    if isinstance(availability_df.index, pd.DatetimeIndex):
        try:
            value = availability_df.at[pd.to_datetime(date).normalize().tz_localize(None), doctor]  # ğŸ”§ FIX
            if isinstance(value, pd.Series):
                value = value.iloc[0]
            if pd.notna(value):
                code = int(value)
        except Exception:
            pass
    if code is None:
        code = fallback_avail_codes.get(doctor, 1)
    if code not in (0, 1, 2, 3):
        code = 1
    return code

def get_sched_code(date, doctor):
    if doctor not in schedule_df.columns:
        return None
    try:
        value = schedule_df.at[pd.to_datetime(date).normalize().tz_localize(None), doctor]  # ğŸ”§ FIX
        if isinstance(value, pd.Series):
            value = value.iloc[0]
    except Exception:
        return None
    if pd.isna(value):
        return None
    return str(value).strip()

# sheet2 ã¨ sheet3 ã®åŒ»å¸«åˆ—ãŒã‚ºãƒ¬ã¦ã„ãªã„ã‹ï¼ˆã‚ºãƒ¬ã¦ã¦ã‚‚å‹•ããŒã€åˆ¶ç´„ãŒå¼±ããªã‚‹ï¼‰
sched_doctors = [normalize_name(x) for x in list(schedule_raw.columns[1:])]  # ğŸ”§ FIX
if doctor_names != sched_doctors:
    print("âš ï¸ WARNING: sheet2(å¯å¦) ã¨ sheet3(ã‚«ãƒ†è¡¨) ã®åŒ»å¸«åˆ—ãŒä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ã€‚")
    only2 = [d for d in doctor_names if d not in sched_doctors]
    only3 = [d for d in sched_doctors if d not in doctor_names]
    if only2:
        print(f"   sheet2 only (å…ˆé ­10): {only2[:10]}")
    if only3:
        print(f"   sheet3 only (å…ˆé ­10): {only3[:10]}")
    print("   â€»Hã€œU ã®ã€ã‚«ãƒ†è¡¨ã‚ã‚Šä¸å¯ã€åˆ¶ç´„ãŒä¸€éƒ¨ã®åŒ»å¸«ã§åŠ¹ã‹ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

# =========================
# sheet4 å‰æœˆã¾ã§ç´¯ç©
# =========================
name_to_row = {row["æ°å"]: row for _, row in sheet4_data.iterrows()}
prev_names = list(sheet4_data["æ°å"])

def match_prev_name(doc):
    if doc in name_to_row:
        return doc
    ms = [p for p in prev_names if str(p).startswith(doc) or doc.startswith(str(p))]
    return ms[0] if len(ms) == 1 else None

name_match = {doc: match_prev_name(doc) for doc in doctor_names}
unmatched = [d for d in doctor_names if name_match.get(d) is None]
if unmatched:
    print(f"âš ï¸ WARNING: sheet4(ç´¯ç©)ã§åå‰ãŒä¸€è‡´ã—ãªã„åŒ»å¸«ãŒã„ã¾ã™ï¼ˆç´¯ç©ãŒ0æ‰±ã„ã«ãªã‚Šã¾ã™ï¼‰: {unmatched}")

def prev_get(doc, colname):
    pname = name_match.get(doc)
    if pname and pname in name_to_row:
        row = name_to_row[pname]
        v = row.get(colname, 0)
        try:
            return float(v or 0)
        except Exception:
            return 0.0
    return 0.0

prev_total   = {d: prev_get(d, "å…¨åˆè¨ˆ")   for d in doctor_names}
prev_bg      = {d: prev_get(d, "å¤§å­¦åˆè¨ˆ") for d in doctor_names}
prev_ht      = {d: prev_get(d, "å¤–ç—…é™¢åˆè¨ˆ") for d in doctor_names}
prev_weekday = {d: prev_get(d, "å¹³æ—¥")     for d in doctor_names}
prev_weekend = {d: prev_get(d, "ä¼‘æ—¥åˆè¨ˆ") for d in doctor_names}

# =========================
# å…¨æ æ•°ã‚«ã‚¦ãƒ³ãƒˆ + slots_by_date å‰è¨ˆç®—
# =========================
slots_by_date = defaultdict(lambda: {"preassigned": [], "free": []})
preassigned_count = {d: 0 for d in doctor_names}
total_slots = 0

for ridx in shift_df.index:
    date = shift_df.at[ridx, date_col_shift]
    if pd.isna(date):
        continue
    date = pd.to_datetime(date).normalize().tz_localize(None)  # ğŸ”§ FIX

    for hosp in hospital_cols:
        val = shift_df.at[ridx, hosp]

        # å›ºå®šå‰²å½“ï¼ˆã‚»ãƒ«ã«åŒ»å¸«åãŒå…¥ã£ã¦ã„ã‚‹ï¼‰
        val_str = normalize_name(val) if isinstance(val, str) else ""  # ğŸ”§ FIX
        if val_str in doctor_names:
            doc = val_str
            slots_by_date[date]["preassigned"].append((ridx, hosp, doc))
            preassigned_count[doc] += 1
            total_slots += 1
            continue

        # è‡ªå‹•æ ï¼ˆ1/ã€‡ãªã©ï¼‰
        if is_slot_value(val):
            slots_by_date[date]["free"].append((ridx, hosp))
            total_slots += 1

if len(doctor_names) == 0:
    raise ValueError("âŒ sheet2 ã«åŒ»å¸«åãŒã‚ã‚Šã¾ã›ã‚“")

all_dates = sorted(slots_by_date.keys())
all_shift_dates = sorted(pd.to_datetime(shift_df[date_col_shift].dropna()).dt.normalize().dt.tz_localize(None).unique())  # ğŸ”§ FIX

# =========================
# capè¨­è¨ˆï¼šnå›ãƒ™ãƒ¼ã‚¹ï¼‹ä½™ã‚Šã¯ã€Œä¸‹ã®æ–¹ï¼ˆå¾Œã‚ï¼‰ã€ã®åŒ»å¸«ã«+1
# =========================
def is_always_unavailable(doc):
    if preassigned_count.get(doc, 0) > 0:
        return False
    return all(get_avail_code(d, doc) == 0 for d in all_shift_dates)

inactive_doctors = [d for d in doctor_names if is_always_unavailable(d)]
active_doctors = [d for d in doctor_names if d not in inactive_doctors]
if len(active_doctors) == 0:
    raise ValueError("âŒ å½“æœˆã«å‰²ã‚Šå½“ã¦å¯èƒ½ãªåŒ»å¸«ãŒã„ã¾ã›ã‚“")

BASE_TARGET = total_slots // len(active_doctors)
EXTRA_SLOTS = total_slots - BASE_TARGET * len(active_doctors)

active_sorted_bottom = sorted(active_doctors, key=lambda d: doctor_col_index[d])
EXTRA_ALLOWED = set(active_sorted_bottom[-EXTRA_SLOTS:]) if EXTRA_SLOTS > 0 else set()

TARGET_CAP = {d: 0 for d in doctor_names}
for d in active_doctors:
    TARGET_CAP[d] = BASE_TARGET + (1 if d in EXTRA_ALLOWED else 0)
for d in doctor_names:
    if preassigned_count.get(d, 0) > TARGET_CAP.get(d, 0):
        TARGET_CAP[d] = preassigned_count[d]

floor_shifts = BASE_TARGET

print(f"\nâœ… å‰²å½“è¨­è¨ˆå®Œäº†")
print(f"   å…¨æ æ•°: {total_slots}")
print(f"   activeåŒ»å¸«: {len(active_doctors)}äºº")
print(f"   inactiveåŒ»å¸«: {len(inactive_doctors)}äºº")
print(f"   åŸºæœ¬å‰²å½“æ•°: {BASE_TARGET}å›")
print(f"   ä½™ã‚Šæ : {EXTRA_SLOTS}æ ï¼ˆä¸‹ã®æ–¹ã®åŒ»å¸«ã«+1å›ï¼‰")

# =========================
# B-K / L-Y æ¯”ç‡ãƒãƒ©ãƒ³ã‚¹ï¼ˆsheet3ã§ã€Œ3ã€è¨˜è¼‰ã®åŒ»å¸«ã¯é™¤å¤–ï¼‰
# =========================
def has_sheet3_code_3(doc):
    if doc not in schedule_df.columns:
        return False
    values = schedule_df[doc].dropna()
    return any(str(v).strip() == "3" for v in values)

RATIO_EXEMPT_DOCTORS = {doc for doc in doctor_names if has_sheet3_code_3(doc)}
if RATIO_EXEMPT_DOCTORS:
    print(f"   æ¯”ç‡ãƒãƒ©ãƒ³ã‚¹é™¤å¤–ï¼ˆsheet3ã«3ã‚ã‚Šï¼‰: {sorted(RATIO_EXEMPT_DOCTORS)}")

# =========================
# å¤§å­¦(Bã€œG)ã®æ˜¼å¤œåˆ¤å®š & 7åˆ†é¡
# =========================
def is_bg_day_shift(hosp_name, col_idx):
    if hosp_name in BG_DAY_COLS:
        return True
    if hosp_name in BG_NIGHT_COLS:
        return False
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šB,C,E,F=æ˜¼ / D,G=å¤œ
    if col_idx in (B_COL_INDEX, C_COL_INDEX, E_COL_INDEX, F_COL_INDEX):
        return True
    if col_idx in (D_COL_INDEX, G_COL_INDEX):
        return False
    mid = (B_COL_INDEX + G_COL_INDEX) // 2
    return col_idx <= mid

def is_bk_slot(col_idx):
    return B_K_START_INDEX <= col_idx <= B_K_END_INDEX

def is_ly_slot(col_idx):
    return L_Y_START_INDEX <= col_idx <= L_Y_END_INDEX

def classify_bg_category(date, hosp_name):
    idx = shift_df.columns.get_loc(hosp_name)
    is_day = is_bg_day_shift(hosp_name, idx)
    dow = pd.to_datetime(date).weekday()
    holi = is_holiday(date)

    weekday = dow < 5
    # å¹³æ—¥ã‹ã¤ C,D,F,G ã¯ç¥æ—¥æ‰±ã„
    if weekday and idx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX):
        holi = True

    if holi and weekday:
        base = "ç¥æ—¥"
    elif dow == 5:
        base = "åœŸæ›œ"
    elif dow == 6:
        base = "æ—¥æ›œ"
    else:
        return "å¹³æ—¥"

    return base + ("æ˜¼" if is_day else "å¤œ")

# =========================
# 1æ ã®åŒ»å¸«é¸æŠï¼ˆgreedyï¼‰
# =========================
def choose_doctor_for_slot(
    date,
    hospital_name,
    assigned_count,
    assigned_dates,
    assigned_bg,
    assigned_ht,
    assigned_weekday,
    assigned_weekend,
    assigned_be,
    assigned_fg,
    assigned_bk,
    assigned_ly,
    assigned_hosp_count,
):
    idx = shift_df.columns.get_loc(hospital_name)
    is_BE = B_COL_INDEX <= idx <= E_COL_INDEX
    is_BG = B_COL_INDEX <= idx <= G_COL_INDEX
    is_HU = H_COL_INDEX <= idx <= U_COL_INDEX
    is_BK = is_bk_slot(idx)
    is_LY = is_ly_slot(idx)
    dow = pd.to_datetime(date).weekday()
    weekday = dow < 5

    def collect_candidates(
        allow_same_day=False,
        relax_availability=False,
        relax_schedule=False,
        relax_wed=False,
    ):
        candidates = []
        for doc in doctor_names:
            if not allow_same_day and date in assigned_dates[doc]:
                continue

            if not relax_availability:
                code = get_avail_code(date, doc)
                if code == 0:
                    continue
                # 2 -> Bã€œMåˆ—ä»¥å¤–ãƒ€ãƒ¡
                if code == 2 and not (B_COL_INDEX <= idx <= M_COL_INDEX):
                    continue
                # 3 -> Hã€œUåˆ—ä»¥å¤–ãƒ€ãƒ¡
                if code == 3 and not (H_COL_INDEX <= idx <= U_COL_INDEX):
                    continue

            if not relax_schedule and H_COL_INDEX <= idx <= U_COL_INDEX:
                if get_sched_code(date, doc):
                    continue

            if not relax_wed and dow == 2 and H_COL_INDEX <= idx <= U_COL_INDEX:
                if doc in WED_FORBIDDEN_DOCTORS:
                    continue

            if assigned_count[doc] >= TARGET_CAP.get(doc, 0):
                continue

            candidates.append(doc)
        return candidates

    candidates = collect_candidates()
    if not candidates:
        candidates = collect_candidates(allow_same_day=True)
    if not candidates:
        candidates = collect_candidates(allow_same_day=True, relax_availability=True)
    if not candidates:
        candidates = collect_candidates(
            allow_same_day=True,
            relax_availability=True,
            relax_schedule=True,
            relax_wed=True,
        )

    if not candidates:
        return None

    any_under_floor = any(assigned_count[d] < floor_shifts for d in active_doctors)
    if any_under_floor:
        under_floor = [d for d in candidates if assigned_count[d] < floor_shifts]
        if under_floor:
            candidates = under_floor

    # gap
    gaps = {}
    for d in candidates:
        if not assigned_dates[d]:
            gaps[d] = 999
        else:
            gaps[d] = min(abs((pd.to_datetime(date) - x).days) for x in assigned_dates[d])

    # å„ªå…ˆé †ä½: 7,4,5,æ¯”ç‡(B-K/L-Y),2,3,6,8,1(>=4),10

    # 7 å…¨ä½“ï¼ˆå‰æœˆ+ä»Šæœˆï¼‰
    metric_total = {d: prev_total[d] + assigned_count[d] for d in candidates}
    min_total = min(metric_total.values())
    candidates = [d for d in candidates if metric_total[d] == min_total]

    # 4 å¤§å­¦/å¤–ç—…é™¢åã‚Šï¼ˆå‰æœˆ+ä»Šæœˆï¼‰
    if is_BG:
        metric_bg = {d: prev_bg[d] + assigned_bg[d] for d in candidates}
        mb = min(metric_bg.values())
        candidates = [d for d in candidates if metric_bg[d] == mb]
    elif is_HU:
        metric_ht = {d: prev_ht[d] + assigned_ht[d] for d in candidates}
        mh = min(metric_ht.values())
        candidates = [d for d in candidates if metric_ht[d] == mh]

    # 5 Bã€œE / Fã€œG
    if is_BG:
        if is_BE:
            mbe = min(assigned_be[d] for d in candidates)
            candidates = [d for d in candidates if assigned_be[d] == mbe]
        else:
            mfg = min(assigned_fg[d] for d in candidates)
            candidates = [d for d in candidates if assigned_fg[d] == mfg]

    # B-K / L-Y ã®æ¯”ç‡ãƒãƒ©ãƒ³ã‚¹ï¼ˆé™¤å¤–åŒ»å¸«ä»¥å¤–ï¼‰
    if (is_BK or is_LY) and candidates:
        def imbalance_score(doc):
            if doc in RATIO_EXEMPT_DOCTORS:
                return 0
            bk = assigned_bk[doc] + (1 if is_BK else 0)
            ly = assigned_ly[doc] + (1 if is_LY else 0)
            return abs(bk - ly)

        min_imbalance = min(imbalance_score(d) for d in candidates)
        candidates = [d for d in candidates if imbalance_score(d) == min_imbalance]

    # 2 åŒä¸€ç—…é™¢0å›å„ªå…ˆ
    no_dup = [d for d in candidates if assigned_hosp_count[d].get(hospital_name, 0) == 0]
    if no_dup:
        candidates = no_dup

    # 3 Bã€œG ã¯ã‚«ãƒ†è¡¨ã‚ã‚Šå„ªå…ˆï¼ˆã‚½ãƒ•ãƒˆå„ªå…ˆï¼‰
    if is_BG:
        with_sched = [d for d in candidates if get_sched_code(date, d)]
        if with_sched:
            candidates = with_sched

    # 6 å¹³æ—¥/ä¼‘æ—¥åã‚Šï¼ˆå‰æœˆ+ä»Šæœˆï¼‰
    holi_flag = (
        is_holiday(date)
        or dow >= 5
        or (weekday and idx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX))
    )
    if holi_flag:
        metric_we = {d: prev_weekend[d] + assigned_weekend[d] for d in candidates}
        mwe = min(metric_we.values())
        candidates = [d for d in candidates if metric_we[d] == mwe]
    else:
        metric_wd = {d: prev_weekday[d] + assigned_weekday[d] for d in candidates}
        mwd = min(metric_wd.values())
        candidates = [d for d in candidates if metric_wd[d] == mwd]

    # 8 flooræœªæº€å„ªå…ˆ
    under_floor = [d for d in candidates if assigned_count[d] < floor_shifts]
    if under_floor:
        candidates = under_floor

    # 1 gap>=4
    gap_ok = [d for d in candidates if gaps[d] >= 4]
    if gap_ok:
        candidates = gap_ok

    # 10 åŒç‚¹ãªã‚‰å³å´
    return max(candidates, key=lambda d: doctor_col_index[d])

# =========================
# 1ãƒ¶æœˆåˆ†ç”Ÿæˆï¼ˆgreedyï¼‰
# =========================
def build_schedule_pattern(seed=0):
    random.seed(seed)

    df = shift_df.copy()
    for col in hospital_cols:
        df[col] = df[col].astype(object)

    assigned_count = {d: 0 for d in doctor_names}
    assigned_dates = {d: set() for d in doctor_names}

    assigned_bg = {d: 0 for d in doctor_names}
    assigned_ht = {d: 0 for d in doctor_names}
    assigned_weekday = {d: 0 for d in doctor_names}
    assigned_weekend = {d: 0 for d in doctor_names}
    assigned_be = {d: 0 for d in doctor_names}
    assigned_fg = {d: 0 for d in doctor_names}
    assigned_bk = {d: 0 for d in doctor_names}
    assigned_ly = {d: 0 for d in doctor_names}
    assigned_hosp_count = {d: defaultdict(int) for d in doctor_names}
    bg_cat = {d: defaultdict(int) for d in doctor_names}

    # å›ºå®šå½“ç›´
    for date in all_dates:
        for ridx, hosp, doc in slots_by_date[date]["preassigned"]:
            df.at[ridx, hosp] = doc
            assigned_count[doc] += 1
            assigned_dates[doc].add(date)
            assigned_hosp_count[doc][hosp] += 1

            hidx = shift_df.columns.get_loc(hosp)
            if B_COL_INDEX <= hidx <= G_COL_INDEX:
                assigned_bg[doc] += 1
                if B_COL_INDEX <= hidx <= E_COL_INDEX:
                    assigned_be[doc] += 1
                elif F_COL_INDEX <= hidx <= G_COL_INDEX:
                    assigned_fg[doc] += 1
                bg_cat[doc][classify_bg_category(date, hosp)] += 1
            elif H_COL_INDEX <= hidx <= U_COL_INDEX:
                assigned_ht[doc] += 1

            dow = date.weekday()
            weekday = dow < 5
            holi_flag = (
                is_holiday(date)
                or dow >= 5
                or (weekday and hidx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX))
            )
            if holi_flag:
                assigned_weekend[doc] += 1
            else:
                assigned_weekday[doc] += 1

            if is_bk_slot(hidx):
                assigned_bk[doc] += 1
            elif is_ly_slot(hidx):
                assigned_ly[doc] += 1

    # è‡ªå‹•å‰²å½“
    for date in all_dates:
        free_slots = slots_by_date[date]["free"].copy()
        random.shuffle(free_slots)

        for ridx, hosp in free_slots:
            chosen = choose_doctor_for_slot(
                date=date,
                hospital_name=hosp,
                assigned_count=assigned_count,
                assigned_dates=assigned_dates,
                assigned_bg=assigned_bg,
                assigned_ht=assigned_ht,
                assigned_weekday=assigned_weekday,
                assigned_weekend=assigned_weekend,
                assigned_be=assigned_be,
                assigned_fg=assigned_fg,
                assigned_bk=assigned_bk,
                assigned_ly=assigned_ly,
                assigned_hosp_count=assigned_hosp_count,
            )
            if chosen is None:
                remaining = [d for d in doctor_names if assigned_count[d] < TARGET_CAP.get(d, 0)]
                if remaining:
                    fallback_doc = min(remaining, key=lambda d: (assigned_count[d], doctor_col_index[d]))
                else:
                    fallback_doc = min(doctor_names, key=lambda d: (assigned_count[d], doctor_col_index[d]))
                df.at[ridx, hosp] = fallback_doc
                chosen = fallback_doc
            else:
                df.at[ridx, hosp] = chosen

            assigned_count[chosen] += 1
            assigned_dates[chosen].add(date)
            assigned_hosp_count[chosen][hosp] += 1

            hidx = shift_df.columns.get_loc(hosp)
            if B_COL_INDEX <= hidx <= G_COL_INDEX:
                assigned_bg[chosen] += 1
                if B_COL_INDEX <= hidx <= E_COL_INDEX:
                    assigned_be[chosen] += 1
                elif F_COL_INDEX <= hidx <= G_COL_INDEX:
                    assigned_fg[chosen] += 1
                bg_cat[chosen][classify_bg_category(date, hosp)] += 1
            elif H_COL_INDEX <= hidx <= U_COL_INDEX:
                assigned_ht[chosen] += 1

            dow = date.weekday()
            weekday = dow < 5
            holi_flag = (
                is_holiday(date)
                or dow >= 5
                or (weekday and hidx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX))
            )
            if holi_flag:
                assigned_weekend[chosen] += 1
            else:
                assigned_weekday[chosen] += 1

            if is_bk_slot(hidx):
                assigned_bk[chosen] += 1
            elif is_ly_slot(hidx):
                assigned_ly[chosen] += 1

    return (
        df,
        assigned_count,
        assigned_bg,
        assigned_ht,
        assigned_weekday,
        assigned_weekend,
        assigned_bk,
        assigned_ly,
        bg_cat,
    )

# =========================
# slot_meta / movable_positionsï¼ˆãƒ­ãƒ¼ã‚«ãƒ«æ¢ç´¢ç”¨ï¼‰
# =========================
slot_meta = {}  # (ridx,hosp) -> (date, fixed)
movable_positions = []  # (ridx,hosp,date)

for date in all_dates:
    for ridx, hosp, doc in slots_by_date[date]["preassigned"]:
        slot_meta[(ridx, hosp)] = (date, True)
    for ridx, hosp in slots_by_date[date]["free"]:
        slot_meta[(ridx, hosp)] = (date, False)
        movable_positions.append((ridx, hosp, date))

# =========================
# ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆå†è¨ˆç®—ï¼ˆpattern_df ã‹ã‚‰ï¼‰
# =========================
def recompute_stats(pattern_df):
    counts = {d: 0 for d in doctor_names}
    bg_counts = {d: 0 for d in doctor_names}
    ht_counts = {d: 0 for d in doctor_names}
    wd_counts = {d: 0 for d in doctor_names}
    we_counts = {d: 0 for d in doctor_names}
    bk_counts = {d: 0 for d in doctor_names}
    ly_counts = {d: 0 for d in doctor_names}
    bg_cat = {d: defaultdict(int) for d in doctor_names}
    assigned_hosp_count = {d: defaultdict(int) for d in doctor_names}
    doc_assignments = {d: [] for d in doctor_names}  # (date,hosp)
    unassigned = []  # (date,hosp,ridx)

    for (ridx, hosp), (date, fixed) in slot_meta.items():
        val = pattern_df.at[ridx, hosp]
        if not isinstance(val, str):
            continue
        v = normalize_name(val)  # ğŸ”§ FIX

        if v == "UNASSIGNED":
            unassigned.append((date, hosp, ridx))
            continue
        if v not in doctor_names:
            continue

        doc = v
        counts[doc] += 1
        assigned_hosp_count[doc][hosp] += 1
        doc_assignments[doc].append((date, hosp))

        hidx = shift_df.columns.get_loc(hosp)
        if B_COL_INDEX <= hidx <= G_COL_INDEX:
            bg_counts[doc] += 1
            bg_cat[doc][classify_bg_category(date, hosp)] += 1
        elif H_COL_INDEX <= hidx <= U_COL_INDEX:
            ht_counts[doc] += 1

        dow = date.weekday()
        weekday = dow < 5
        holi_flag = (
            is_holiday(date)
            or dow >= 5
            or (weekday and hidx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX))
        )
        if holi_flag:
            we_counts[doc] += 1
        else:
            wd_counts[doc] += 1

        if is_bk_slot(hidx):
            bk_counts[doc] += 1
        elif is_ly_slot(hidx):
            ly_counts[doc] += 1

    return (
        counts,
        bg_counts,
        ht_counts,
        wd_counts,
        we_counts,
        bk_counts,
        ly_counts,
        bg_cat,
        assigned_hosp_count,
        doc_assignments,
        unassigned,
    )

# =========================
# ã‚¹ã‚³ã‚¢è©•ä¾¡ï¼ˆraw_scoreã‚‚ä¿æŒã—ã¦ 0 ã§æ½°ã‚Œãªã„ã‚ˆã†ã«ï¼‰
# =========================
def evaluate_schedule_with_raw(
    pattern_df,
    assigned_count,
    assigned_bg,
    assigned_ht,
    assigned_weekday,
    assigned_weekend,
    assigned_bk,
    assigned_ly,
):
    # UNASSIGNED
    unassigned_slots = 0
    for ridx in pattern_df.index:
        for hosp in hospital_cols:
            v = pattern_df.at[ridx, hosp]
            if isinstance(v, str) and normalize_name(v) == "UNASSIGNED":  # ğŸ”§ FIX
                unassigned_slots += 1

    # capé•å
    cap_violations = 0
    for doc in doctor_names:
        cap = TARGET_CAP.get(doc, 0)
        if assigned_count.get(doc, 0) > cap:
            cap_violations += (assigned_count[doc] - cap)

    # å…¨åˆè¨ˆå…¬å¹³æ€§ï¼ˆactiveã®ã¿ï¼‰
    active_counts = [assigned_count.get(d, 0) for d in active_doctors]
    max_c = max(active_counts) if active_counts else 0
    min_c = min(active_counts) if active_counts else 0
    diff_total = max_c - min_c
    fairness_penalty = max(0, diff_total - 1)

    # gap(4æ—¥æœªæº€) ã¨ åŒä¸€ç—…é™¢é‡è¤‡
    dates_by_doc = defaultdict(list)
    hosp_counts_by_doc = {doc: defaultdict(int) for doc in doctor_names}

    for ridx in pattern_df.index:
        date = pattern_df.at[ridx, date_col_shift]
        if pd.isna(date):
            continue
        date = pd.to_datetime(date).normalize().tz_localize(None)  # ğŸ”§ FIX
        for hosp in hospital_cols:
            val = pattern_df.at[ridx, hosp]
            val_norm = normalize_name(val) if isinstance(val, str) else ""  # ğŸ”§ FIX
            if val_norm in doctor_names:
                dates_by_doc[val_norm].append(date)
                hosp_counts_by_doc[val_norm][hosp] += 1

    gap_violations = 0
    for doc, dlist in dates_by_doc.items():
        dlist = sorted(dlist)
        for i in range(1, len(dlist)):
            if (dlist[i] - dlist[i - 1]).days < 4:
                gap_violations += 1

    hosp_dup_violations = 0
    for doc, hdict in hosp_counts_by_doc.items():
        for _, c in hdict.items():
            if c > 1:
                hosp_dup_violations += (c - 1)

    # åã‚Šï¼ˆç´¯è¨ˆï¼šå‰æœˆ+ä»Šæœˆï¼‰ã® spread
    bg_vals = [prev_bg[d] + assigned_bg.get(d, 0) for d in active_doctors]
    ht_vals = [prev_ht[d] + assigned_ht.get(d, 0) for d in active_doctors]
    wd_vals = [prev_weekday[d] + assigned_weekday.get(d, 0) for d in active_doctors]
    we_vals = [prev_weekend[d] + assigned_weekend.get(d, 0) for d in active_doctors]

    bg_spread = (max(bg_vals) - min(bg_vals)) if bg_vals else 0
    ht_spread = (max(ht_vals) - min(ht_vals)) if ht_vals else 0
    wd_spread = (max(wd_vals) - min(wd_vals)) if wd_vals else 0
    we_spread = (max(we_vals) - min(we_vals)) if we_vals else 0

    bk_ly_imbalance = 0
    for doc in active_doctors:
        if doc in RATIO_EXEMPT_DOCTORS:
            continue
        bk_val = assigned_bk.get(doc, 0)
        ly_val = assigned_ly.get(doc, 0)
        bk_ly_imbalance += abs(bk_val - ly_val)

    penalty = 0
    penalty += fairness_penalty * W_FAIR_TOTAL
    penalty += gap_violations * W_GAP
    penalty += hosp_dup_violations * W_HOSP_DUP
    penalty += unassigned_slots * W_UNASSIGNED
    penalty += cap_violations * W_CAP

    penalty += max(0, bg_spread - 1) * W_BG_SPREAD
    penalty += max(0, ht_spread - 1) * W_HT_SPREAD
    penalty += max(0, wd_spread - 1) * W_WD_SPREAD
    penalty += max(0, we_spread - 1) * W_WE_SPREAD
    penalty += bk_ly_imbalance * W_BK_LY_BALANCE

    raw_score = 100 - penalty
    score = max(raw_score, 0)

    metrics = {
        "raw_score": float(raw_score),
        "penalty_total": float(penalty),
        "max_minus_min_total_active": int(diff_total),
        "gap_violations": int(gap_violations),
        "hospital_dup_violations": int(hosp_dup_violations),
        "unassigned_slots": int(unassigned_slots),
        "cap_violations": int(cap_violations),
        "bg_spread_cum": float(bg_spread),
        "ht_spread_cum": float(ht_spread),
        "weekday_spread_cum": float(wd_spread),
        "weekend_spread_cum": float(we_spread),
        "bk_ly_imbalance": int(bk_ly_imbalance),
    }
    return score, raw_score, metrics

# =========================
# ãƒ­ãƒ¼ã‚«ãƒ«æ¢ç´¢ï¼ˆå…¥æ›¿ swapï¼‰
# ğŸ”§ FIX: date_doc_count ã‚’å®Œå…¨ãª defaultdict(lambda: defaultdict(int)) ã«å¤‰æ›´
# ğŸ”§ FIX: åŒæ—¥é‡è¤‡ãƒã‚§ãƒƒã‚¯ã®å¼·åŒ–
# =========================
def can_assign_doc_to_slot(doc, date, hosp):
    """ãƒãƒ¼ãƒ‰åˆ¶ç´„ã®ã¿ï¼ˆåŒæ—¥é‡è¤‡ã¯åˆ¥ãƒã‚§ãƒƒã‚¯ï¼‰"""
    idx = shift_df.columns.get_loc(hosp)
    dow = pd.to_datetime(date).weekday()

    code = get_avail_code(date, doc)
    if code == 0:
        return False
    if code == 2 and not (B_COL_INDEX <= idx <= M_COL_INDEX):
        return False
    if code == 3 and not (H_COL_INDEX <= idx <= U_COL_INDEX):
        return False
    if H_COL_INDEX <= idx <= U_COL_INDEX:
        if get_sched_code(date, doc):
            return False
    if dow == 2 and H_COL_INDEX <= idx <= U_COL_INDEX and doc in WED_FORBIDDEN_DOCTORS:
        return False
    return True

def build_date_doc_count(pattern_df):
    """date -> doc -> countï¼ˆåŒæ—¥è¤‡æ•°å‰²å½“æ¤œå‡ºã‚‚å…¼ã­ã‚‹ï¼‰"""
    # ğŸ”§ FIX: å®Œå…¨ãª nested defaultdict ã«å¤‰æ›´
    date_doc_count = defaultdict(lambda: defaultdict(int))
    for (ridx, hosp), (date, fixed) in slot_meta.items():
        val = pattern_df.at[ridx, hosp]
        if isinstance(val, str):
            v = normalize_name(val)  # ğŸ”§ FIX
            if v in doctor_names:
                date_doc_count[date][v] += 1
    return date_doc_count

def collect_violation_docs_from_assignments(doc_assignments, assigned_hosp_count):
    bad = set()
    # gap
    for doc, assigns in doc_assignments.items():
        dlist = sorted([d for d, _ in assigns])
        for i in range(1, len(dlist)):
            if (dlist[i] - dlist[i - 1]).days < 4:
                bad.add(doc)
                break
    # hospital dup
    for doc, hdict in assigned_hosp_count.items():
        if any(c > 1 for c in hdict.values()):
            bad.add(doc)
    return bad

def is_better_raw(new_raw, new_metrics, cur_raw, cur_metrics):
    if new_raw > cur_raw:
        return True
    if new_raw < cur_raw:
        return False
    # tie-breakï¼ˆé‡è¦åº¦é †ï¼‰
    keys = [
        "unassigned_slots",
        "cap_violations",
        "gap_violations",
        "hospital_dup_violations",
        "max_minus_min_total_active",
        "bk_ly_imbalance",
        "bg_spread_cum",
        "ht_spread_cum",
        "weekday_spread_cum",
        "weekend_spread_cum",
    ]
    return tuple(new_metrics.get(k, 0) for k in keys) < tuple(cur_metrics.get(k, 0) for k in keys)

def local_search_swap(pattern_df, max_iters=2000, patience=800, refresh_every=200, seed=0):
    """å…¥æ›¿ï¼ˆswapï¼‰å±€æ‰€æ¢ç´¢ï¼špreassignedã¯å‹•ã‹ã•ãšã€freeæ ã®ã¿ã‚’å¯¾è±¡ã«æ”¹å–„ã™ã‚‹"""
    if not movable_positions:
        # å‹•ã‹ã›ã‚‹æ ãŒç„¡ã„ï¼ˆå…¨éƒ¨å›ºå®šãªã©ï¼‰
        counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, *_ = recompute_stats(pattern_df)
        score, raw_score, metrics = evaluate_schedule_with_raw(
            pattern_df,
            counts,
            bg_counts,
            ht_counts,
            wd_counts,
            we_counts,
            bk_counts,
            ly_counts,
        )
        return pattern_df.copy(), score, raw_score, metrics

    rng = random.Random(seed)
    df = pattern_df.copy()

    counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned = recompute_stats(df)
    cur_score, cur_raw, cur_metrics = evaluate_schedule_with_raw(
        df,
        counts,
        bg_counts,
        ht_counts,
        wd_counts,
        we_counts,
        bk_counts,
        ly_counts,
    )
    date_doc_count = build_date_doc_count(df)

    no_improve = 0
    bad_positions = None

    for it in range(1, max_iters + 1):
        if no_improve >= patience:
            break

        if it == 1 or it % refresh_every == 0:
            bad_docs = collect_violation_docs_from_assignments(doc_assignments, assigned_hosp_count)
            if bad_docs:
                tmp = []
                for (ridx, hosp, date) in movable_positions:
                    v = df.at[ridx, hosp]
                    if isinstance(v, str) and normalize_name(v) in bad_docs:  # ğŸ”§ FIX
                        tmp.append((ridx, hosp, date))
                bad_positions = tmp if tmp else None
            else:
                bad_positions = None

        p1 = rng.choice(bad_positions if bad_positions is not None else movable_positions)
        p2 = rng.choice(movable_positions)
        if p1 == p2:
            no_improve += 1
            continue

        r1, h1, d1 = p1
        r2, h2, d2 = p2

        v1 = df.at[r1, h1]
        v2 = df.at[r2, h2]
        if not (isinstance(v1, str) and isinstance(v2, str)):
            no_improve += 1
            continue

        doc1 = normalize_name(v1)  # ğŸ”§ FIX
        doc2 = normalize_name(v2)  # ğŸ”§ FIX
        if doc1 not in doctor_names or doc2 not in doctor_names:
            no_improve += 1
            continue
        if doc1 == doc2:
            no_improve += 1
            continue

        # ğŸ”§ FIX: åŒæ—¥é‡è¤‡ã‚’ä½œã‚‰ãªã„ï¼ˆåŒã˜æ—¥åŒå£«ã®swapã‚‚ãƒã‚§ãƒƒã‚¯ï¼‰
        if d1 == d2:
            # åŒã˜æ—¥ã®slotåŒå£«ã‚’swapã™ã‚‹å ´åˆã€å…ƒã€…åŒã˜doctorãŒã„ãªã‘ã‚Œã°OK
            # ï¼ˆæ—¢ã«doc1!=doc2ã‚’ç¢ºèªæ¸ˆã¿ãªã®ã§ã€è¿½åŠ ãƒã‚§ãƒƒã‚¯ä¸è¦ï¼‰
            pass
        else:
            # ç•°ãªã‚‹æ—¥ã®swap
            if date_doc_count[d2][doc1] > 0:  # doc1ãŒd2ã«æ—¢ã«ã„ã‚‹
                no_improve += 1
                continue
            if date_doc_count[d1][doc2] > 0:  # doc2ãŒd1ã«æ—¢ã«ã„ã‚‹
                no_improve += 1
                continue

        # ãƒãƒ¼ãƒ‰åˆ¶ç´„
        if not can_assign_doc_to_slot(doc1, d2, h2):
            no_improve += 1
            continue
        if not can_assign_doc_to_slot(doc2, d1, h1):
            no_improve += 1
            continue

        # swapï¼ˆin-placeï¼‰
        df.at[r1, h1], df.at[r2, h2] = doc2, doc1

        # ğŸ”§ FIX: date_doc_count æ›´æ–°ï¼ˆdefaultdictãªã®ã§KeyErrorãªã—ï¼‰
        if d1 != d2:
            date_doc_count[d1][doc1] -= 1
            if date_doc_count[d1][doc1] <= 0:
                del date_doc_count[d1][doc1]
            date_doc_count[d2][doc2] -= 1
            if date_doc_count[d2][doc2] <= 0:
                del date_doc_count[d2][doc2]
            date_doc_count[d1][doc2] += 1
            date_doc_count[d2][doc1] += 1

        # å†è©•ä¾¡ï¼ˆå…¨å†è¨ˆç®—ï¼‰
        counts2, bg2, ht2, wd2, we2, bk2, ly2, bg_cat2, assigned_hosp_count2, doc_assignments2, unassigned2 = recompute_stats(df)
        new_score, new_raw, new_metrics = evaluate_schedule_with_raw(
            df,
            counts2,
            bg2,
            ht2,
            wd2,
            we2,
            bk2,
            ly2,
        )

        if is_better_raw(new_raw, new_metrics, cur_raw, cur_metrics):
            cur_score, cur_raw, cur_metrics = new_score, new_raw, new_metrics
            counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat = counts2, bg2, ht2, wd2, we2, bg_cat2
            assigned_hosp_count, doc_assignments = assigned_hosp_count2, doc_assignments2
            no_improve = 0
        else:
            # revert
            df.at[r1, h1], df.at[r2, h2] = doc1, doc2
            if d1 != d2:
                date_doc_count[d1][doc2] -= 1
                if date_doc_count[d1][doc2] <= 0:
                    del date_doc_count[d1][doc2]
                date_doc_count[d2][doc1] -= 1
                if date_doc_count[d2][doc1] <= 0:
                    del date_doc_count[d2][doc1]
                date_doc_count[d1][doc1] += 1
                date_doc_count[d2][doc2] += 1
            no_improve += 1

    return df, cur_score, cur_raw, cur_metrics

# =========================
# ã‚µãƒãƒªãƒ¼åˆ—ï¼ˆSheet4 ã®åˆ—ã‚’åŸºæº–ã«è‡ªå‹•ç”Ÿæˆï¼‰
# =========================
META_COLS_SHEET4 = {"ã‚«ãƒ†å½“ç•ª", "å‡ºå¼µæ—¥", "å‡ºå¼µå…ˆ"}
BASE_SUMMARY_COLS = {"å…¨åˆè¨ˆ", "å¤§å­¦åˆè¨ˆ", "å¤–ç—…é™¢åˆè¨ˆ", "å¹³æ—¥", "ä¼‘æ—¥åˆè¨ˆ"}

UNIV7_SET = {"å¤§å­¦å¹³æ—¥", "å¤§å­¦åœŸæ›œæ˜¼", "å¤§å­¦åœŸæ›œå¤œ", "å¤§å­¦æ—¥æ›œæ˜¼", "å¤§å­¦æ—¥æ›œå¤œ", "å¤§å­¦ç¥æ—¥æ˜¼", "å¤§å­¦ç¥æ—¥å¤œ"}
UNIV7_ORDER = [c for c in sheet4_raw_out.columns if c in UNIV7_SET]
if not UNIV7_ORDER:
    UNIV7_ORDER = ["å¤§å­¦åœŸæ›œæ˜¼", "å¤§å­¦åœŸæ›œå¤œ", "å¤§å­¦æ—¥æ›œæ˜¼", "å¤§å­¦æ—¥æ›œå¤œ", "å¤§å­¦ç¥æ—¥æ˜¼", "å¤§å­¦ç¥æ—¥å¤œ", "å¤§å­¦å¹³æ—¥"]

DETAIL_COLS = [
    c for c in sheet4_raw_out.columns
    if c not in META_COLS_SHEET4 and c not in ["æ°å"] and c not in BASE_SUMMARY_COLS and c not in UNIV7_SET
]

SUMMARY_DETAIL_COLS = UNIV7_ORDER + DETAIL_COLS
SUMMARY_COLS = ["æ°å", "å…¨åˆè¨ˆ", "å¤§å­¦åˆè¨ˆ", "å¤–ç—…é™¢åˆè¨ˆ", "å¹³æ—¥", "ä¼‘æ—¥åˆè¨ˆ"] + SUMMARY_DETAIL_COLS

def count_doc_in_column(df, colname, doc):
    if colname not in df.columns:
        return 0
    s = df[colname]
    cnt = 0
    for v in s:
        if isinstance(v, str) and normalize_name(v) == doc:  # ğŸ”§ FIX
            cnt += 1
    return cnt

def build_summaries(pattern_df, counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat_local):
    rows_month = []
    rows_total = []

    uni_map = {
        "å¤§å­¦å¹³æ—¥": "å¹³æ—¥",
        "å¤§å­¦åœŸæ›œæ˜¼": "åœŸæ›œæ˜¼",
        "å¤§å­¦åœŸæ›œå¤œ": "åœŸæ›œå¤œ",
        "å¤§å­¦æ—¥æ›œæ˜¼": "æ—¥æ›œæ˜¼",
        "å¤§å­¦æ—¥æ›œå¤œ": "æ—¥æ›œå¤œ",
        "å¤§å­¦ç¥æ—¥æ˜¼": "ç¥æ—¥æ˜¼",
        "å¤§å­¦ç¥æ—¥å¤œ": "ç¥æ—¥å¤œ",
    }

    for doc in doctor_names:
        pname = name_match.get(doc)
        base_row = name_to_row.get(pname) if pname and pname in name_to_row else None

        def prev_val(colname):
            if base_row is None:
                return 0.0
            v = base_row.get(colname, 0)
            try:
                return float(v or 0)
            except Exception:
                return 0.0

        # ä»Šæœˆ
        row_m = {c: 0.0 for c in SUMMARY_COLS}
        row_m["æ°å"] = doc
        row_m["å…¨åˆè¨ˆ"] = float(counts.get(doc, 0))
        row_m["å¤§å­¦åˆè¨ˆ"] = float(bg_counts.get(doc, 0))
        row_m["å¤–ç—…é™¢åˆè¨ˆ"] = float(ht_counts.get(doc, 0))
        row_m["å¹³æ—¥"] = float(wd_counts.get(doc, 0))
        row_m["ä¼‘æ—¥åˆè¨ˆ"] = float(we_counts.get(doc, 0))

        # å¤§å­¦7åˆ†é¡
        for col in UNIV7_ORDER:
            cat = uni_map.get(col)
            if cat:
                row_m[col] = float(bg_cat_local[doc].get(cat, 0))

        # ç—…é™¢åˆ—ï¼ˆSheet4æº–æ‹ ï¼‰ã‚’ãã®ã¾ã¾æ•°ãˆã‚‹
        for col in DETAIL_COLS:
            row_m[col] = float(count_doc_in_column(pattern_df, col, doc))

        # ç´¯è¨ˆï¼ˆå‰æœˆï¼‹ä»Šæœˆï¼‰
        row_t = {c: 0.0 for c in SUMMARY_COLS}
        row_t["æ°å"] = doc
        for c in SUMMARY_COLS:
            if c == "æ°å":
                continue
            row_t[c] = prev_val(c) + float(row_m.get(c, 0))

        rows_month.append(row_m)
        rows_total.append(row_t)

    return pd.DataFrame(rows_month)[SUMMARY_COLS], pd.DataFrame(rows_total)[SUMMARY_COLS]

# =========================
# è¨ºæ–­ã‚·ãƒ¼ãƒˆç”Ÿæˆï¼ˆåã‚Š & gapé•åä¸€è¦§ï¼‰
# =========================
def build_gap_details(doc_assignments):
    rows = []
    for doc, assigns in doc_assignments.items():
        assigns_sorted = sorted(assigns, key=lambda x: (x[0], x[1]))
        for i in range(1, len(assigns_sorted)):
            d_prev, h_prev = assigns_sorted[i - 1]
            d_cur, h_cur = assigns_sorted[i]
            gap = (d_cur - d_prev).days
            if gap < 4:
                rows.append({
                    "æ°å": doc,
                    "å‰å›æ—¥ä»˜": d_prev,
                    "å‰å›ç—…é™¢": h_prev,
                    "ä»Šå›æ—¥ä»˜": d_cur,
                    "ä»Šå›ç—…é™¢": h_cur,
                    "é–“éš”(æ—¥)": gap,
                })
    cols = ["æ°å", "å‰å›æ—¥ä»˜", "å‰å›ç—…é™¢", "ä»Šå›æ—¥ä»˜", "ä»Šå›ç—…é™¢", "é–“éš”(æ—¥)"]
    if not rows:
        return pd.DataFrame(columns=cols)
    return pd.DataFrame(rows)[cols].sort_values(["æ°å", "ä»Šå›æ—¥ä»˜"]).reset_index(drop=True)

def build_same_day_duplicates(doc_assignments):
    rows = []
    for doc, assigns in doc_assignments.items():
        by_date = defaultdict(list)
        for d, h in assigns:
            by_date[d].append(h)
        for d, hs in by_date.items():
            if len(hs) > 1:
                rows.append({"æ°å": doc, "æ—¥ä»˜": d, "ä»¶æ•°": len(hs), "ç—…é™¢": ", ".join(sorted(hs))})
    cols = ["æ°å", "æ—¥ä»˜", "ä»¶æ•°", "ç—…é™¢"]
    if not rows:
        return pd.DataFrame(columns=cols)
    return pd.DataFrame(rows)[cols].sort_values(["æ—¥ä»˜", "æ°å"]).reset_index(drop=True)

def build_hosp_dup_details(assigned_hosp_count):
    rows = []
    for doc, hdict in assigned_hosp_count.items():
        for hosp, c in hdict.items():
            if c > 1:
                rows.append({"æ°å": doc, "ç—…é™¢": hosp, "å›æ•°": c, "è¶…é": c - 1})
    cols = ["æ°å", "ç—…é™¢", "å›æ•°", "è¶…é"]
    if not rows:
        return pd.DataFrame(columns=cols)
    return pd.DataFrame(rows)[cols].sort_values(["è¶…é", "æ°å"], ascending=[False, True]).reset_index(drop=True)

def build_unassigned_details(unassigned):
    rows = [{"æ—¥ä»˜": d, "ç—…é™¢": hosp, "row_index": ridx} for d, hosp, ridx in unassigned]
    cols = ["æ—¥ä»˜", "ç—…é™¢", "row_index"]
    if not rows:
        return pd.DataFrame(columns=cols)
    return pd.DataFrame(rows)[cols].sort_values(["æ—¥ä»˜", "ç—…é™¢"]).reset_index(drop=True)

def build_doctor_diag(counts, bg_counts, ht_counts, wd_counts, we_counts, doc_assignments, assigned_hosp_count):
    rows = []
    active_set = set(active_doctors)

    for doc in doctor_names:
        assigns = sorted(doc_assignments.get(doc, []), key=lambda x: x[0])
        gaps = [(assigns[i][0] - assigns[i - 1][0]).days for i in range(1, len(assigns))]
        gap_viol = sum(1 for g in gaps if g < 4)
        min_gap = min(gaps) if gaps else None
        hosp_excess = sum(max(0, c - 1) for c in assigned_hosp_count.get(doc, {}).values())

        row = {
            "æ°å": doc,
            "active": 1 if doc in active_set else 0,
            "cap": TARGET_CAP.get(doc, 0),
            "preassigned": preassigned_count.get(doc, 0),

            "ä»Šæœˆ_å…¨åˆè¨ˆ": counts.get(doc, 0),
            "ç´¯è¨ˆ_å…¨åˆè¨ˆ": prev_total.get(doc, 0) + counts.get(doc, 0),

            "ä»Šæœˆ_å¤§å­¦åˆè¨ˆ": bg_counts.get(doc, 0),
            "ç´¯è¨ˆ_å¤§å­¦åˆè¨ˆ": prev_bg.get(doc, 0) + bg_counts.get(doc, 0),

            "ä»Šæœˆ_å¤–ç—…é™¢åˆè¨ˆ": ht_counts.get(doc, 0),
            "ç´¯è¨ˆ_å¤–ç—…é™¢åˆè¨ˆ": prev_ht.get(doc, 0) + ht_counts.get(doc, 0),

            "ä»Šæœˆ_å¹³æ—¥": wd_counts.get(doc, 0),
            "ç´¯è¨ˆ_å¹³æ—¥": prev_weekday.get(doc, 0) + wd_counts.get(doc, 0),

            "ä»Šæœˆ_ä¼‘æ—¥åˆè¨ˆ": we_counts.get(doc, 0),
            "ç´¯è¨ˆ_ä¼‘æ—¥åˆè¨ˆ": prev_weekend.get(doc, 0) + we_counts.get(doc, 0),

            "gapé•åå›æ•°": gap_viol,
            "æœ€å°é–“éš”(æ—¥)": min_gap if min_gap is not None else "",
            "åŒä¸€ç—…é™¢é‡è¤‡è¶…é": hosp_excess,
        }
        rows.append(row)

    df = pd.DataFrame(rows)

    # åã‚Šï¼ˆactiveå¹³å‡ã¨ã®å·®ï¼‰ã‚‚å‡ºã—ã¦ãŠã
    active_rows = df[df["active"] == 1]
    for col in ["ç´¯è¨ˆ_å…¨åˆè¨ˆ", "ç´¯è¨ˆ_å¤§å­¦åˆè¨ˆ", "ç´¯è¨ˆ_å¤–ç—…é™¢åˆè¨ˆ", "ç´¯è¨ˆ_å¹³æ—¥", "ç´¯è¨ˆ_ä¼‘æ—¥åˆè¨ˆ"]:
        if len(active_rows) > 0:
            mean_val = float(active_rows[col].mean())
            df[col + "_å¹³å‡ã¨ã®å·®"] = df[col] - mean_val
        else:
            df[col + "_å¹³å‡ã¨ã®å·®"] = 0.0

    return df.sort_values(["active", "ç´¯è¨ˆ_å…¨åˆè¨ˆ"], ascending=[False, False]).reset_index(drop=True)

def build_metrics_df(score_clamped, raw_score, metrics):
    row = {"score": float(score_clamped), "raw_score": float(raw_score), **metrics}
    return pd.DataFrame([row])

def build_diagnostics(pattern_df):
    counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned = recompute_stats(pattern_df)
    score, raw, metrics = evaluate_schedule_with_raw(
        pattern_df,
        counts,
        bg_counts,
        ht_counts,
        wd_counts,
        we_counts,
        bk_counts,
        ly_counts,
    )

    df_doctors = build_doctor_diag(counts, bg_counts, ht_counts, wd_counts, we_counts, doc_assignments, assigned_hosp_count)
    df_gap = build_gap_details(doc_assignments)
    df_same = build_same_day_duplicates(doc_assignments)
    df_hdup = build_hosp_dup_details(assigned_hosp_count)
    df_unass = build_unassigned_details(unassigned)
    df_metrics = build_metrics_df(score, raw, metrics)

    return df_doctors, df_gap, df_same, df_hdup, df_unass, df_metrics

# =========================
# ãƒ‘ã‚¿ãƒ¼ãƒ³æ¢ç´¢ï¼ˆgreedy â†’ topå€™è£œã«å±€æ‰€æ¢ç´¢ â†’ top3ï¼‰
# =========================
print("\nğŸš€ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™...")
print(f"   ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {NUM_PATTERNS}")
print(f"   å±€æ‰€æ¢ç´¢: {'æœ‰åŠ¹' if LOCAL_SEARCH_ENABLED else 'ç„¡åŠ¹'}")
print(f"   â€»å‡¦ç†æ™‚é–“: ç´„5-10åˆ†ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³æ•°ã«ä¾å­˜ï¼‰\n")

score_rows = []
candidates = []  # TOP_KEEPã ã‘ä¿æŒ

for i in range(1, NUM_PATTERNS + 1):
    if i % 100 == 0 or i == 1:
        print(f"   é€²æ—: {i}/{NUM_PATTERNS} ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆä¸­...")

    (
        pattern_df,
        counts,
        bg_counts,
        ht_counts,
        wd_counts,
        we_counts,
        bk_counts,
        ly_counts,
        bg_cat,
    ) = build_schedule_pattern(seed=i)
    score, raw_score, metrics = evaluate_schedule_with_raw(
        pattern_df,
        counts,
        bg_counts,
        ht_counts,
        wd_counts,
        we_counts,
        bk_counts,
        ly_counts,
    )

    score_rows.append({"seed": i, "score": score, "raw_score": raw_score, **metrics})

    candidates.append({
        "seed": i,
        "score": score,
        "raw_score": raw_score,
        "metrics": metrics,
        "pattern_df": pattern_df,
    })
    candidates = sorted(candidates, key=lambda e: e["raw_score"], reverse=True)[:TOP_KEEP]

print(f"\nâœ… {NUM_PATTERNS}ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç”Ÿæˆå®Œäº†")
print(f"   TOP{TOP_KEEP}å€™è£œã‚’å±€æ‰€æ¢ç´¢ã§æœ€é©åŒ–ä¸­...")

# ãƒ­ãƒ¼ã‚«ãƒ«æ¢ç´¢ã§å€™è£œã‚’æ”¹å–„
refined = []
for idx, cand in enumerate(candidates[:REFINE_TOP], 1):
    print(f"   å€™è£œ{idx}/{REFINE_TOP}ã‚’æœ€é©åŒ–ä¸­...")
    if LOCAL_SEARCH_ENABLED:
        improved_df, sc2, raw2, met2 = local_search_swap(
            cand["pattern_df"],
            max_iters=LOCAL_MAX_ITERS,
            patience=LOCAL_PATIENCE,
            refresh_every=LOCAL_REFRESH_EVERY,
            seed=1000 + cand["seed"],
        )
    else:
        improved_df = cand["pattern_df"]
        sc2 = cand["score"]
        raw2 = cand["raw_score"]
        met2 = cand["metrics"]

    refined.append({
        "seed": cand["seed"],
        "score_before": cand["score"],
        "raw_before": cand["raw_score"],
        "score_after": sc2,
        "raw_after": raw2,
        "metrics_after": met2,
        "pattern_df": improved_df,
    })

refined_sorted = sorted(refined, key=lambda e: e["raw_after"], reverse=True)
top_patterns = refined_sorted[:3]

scores_df = pd.DataFrame(score_rows).sort_values(["raw_score", "seed"], ascending=[False, True]).reset_index(drop=True)

refined_df = pd.DataFrame([
    {
        "seed": e["seed"],
        "score_before": e["score_before"],
        "raw_before": e["raw_before"],
        "score_after": e["score_after"],
        "raw_after": e["raw_after"],
        **{f"after_{k}": v for k, v in e["metrics_after"].items() if k not in ("raw_score", "penalty_total")},
    }
    for e in refined_sorted
]).sort_values(["raw_after", "seed"], ascending=[False, True]).reset_index(drop=True)

print("\nâœ… å±€æ‰€æ¢ç´¢å®Œäº†")
print("\n=== TOP3ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚¹ã‚³ã‚¢ ===")
for rank, pattern in enumerate(top_patterns, 1):
    print(f"   {rank}ä½: raw_score={pattern['raw_after']:.1f}, " +
          f"gapé•å={pattern['metrics_after']['gap_violations']}, " +
          f"æœªå‰²å½“={pattern['metrics_after']['unassigned_slots']}")

# =========================
# å‡ºåŠ›ï¼ˆpattern + summary + diagnosticsï¼‰
# =========================
base_name = uploaded_filename.rsplit(".", 1)[0]
output_filename = f"{base_name}_auto_schedules_v2.1.xlsx"
output_path = output_filename

print(f"\nğŸ“ çµæœã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ä¸­...")

best_pattern = top_patterns[0]["pattern_df"]
counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, *_ = recompute_stats(best_pattern)
df_month, df_total = build_summaries(best_pattern, counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat)
df_doctors, df_gap, df_same, df_hdup, df_unass, df_metrics = build_diagnostics(best_pattern)

with pd.ExcelWriter(output_path, engine="openpyxl") as writer:
    best_pattern.to_excel(writer, sheet_name="schedule", index=False)
    df_month.to_excel(writer, sheet_name="summary_ä»Šæœˆ", index=False)
    df_total.to_excel(writer, sheet_name="summary_ç´¯è¨ˆ", index=False)

analysis_path = f"{base_name}_analysis.txt"
sorted_counts = sorted(
    counts.items(),
    key=lambda item: (item[1], doctor_col_index[item[0]]),
    reverse=True,
)

with open(analysis_path, "w", encoding="utf-8") as f:
    f.write("å½“ç›´ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è§£æçµæœ\n")
    f.write("=" * 60 + "\n")
    f.write(f"å‡ºåŠ›Excel: {output_path}\n")
    f.write(f"å…¨æ æ•°: {total_slots}\n")
    f.write(f"activeåŒ»å¸«: {len(active_doctors)}äºº\n")
    f.write(f"åŸºæœ¬å‰²å½“æ•°: {BASE_TARGET}å›\n")
    f.write(f"ä½™ã‚Šæ : {EXTRA_SLOTS}æ ï¼ˆä¸‹ã®æ–¹ã®åŒ»å¸«ã«+1å›ï¼‰\n")
    f.write("\n--- ãƒ¡ãƒˆãƒªã‚¯ã‚¹ ---\n")
    if not df_metrics.empty:
        metrics_row = df_metrics.iloc[0].to_dict()
        for key, value in metrics_row.items():
            f.write(f"{key}: {value}\n")
    f.write("\n--- å½“ç›´å›æ•°ä¸€è¦§ ---\n")
    for doc, cnt in sorted_counts:
        f.write(f"{doc}: {cnt}å›\n")
    f.write("\n--- æœªå‰²å½“æ  ---\n")
    if df_unass.empty:
        f.write("ãªã—\n")
    else:
        for _, row in df_unass.iterrows():
            f.write(f"{row['æ—¥ä»˜']} {row['ç—…é™¢']} (row_index={row['row_index']})\n")
    f.write("\n--- gapé•å ---\n")
    if df_gap.empty:
        f.write("ãªã—\n")
    else:
        for _, row in df_gap.iterrows():
            f.write(
                f"{row['æ°å']} {row['å‰å›æ—¥ä»˜']}({row['å‰å›ç—…é™¢']}) -> "
                f"{row['ä»Šå›æ—¥ä»˜']}({row['ä»Šå›ç—…é™¢']}) gap={row['é–“éš”(æ—¥)']}\n"
            )
    f.write("\n--- åŒæ—¥é‡è¤‡ ---\n")
    if df_same.empty:
        f.write("ãªã—\n")
    else:
        for _, row in df_same.iterrows():
            f.write(f"{row['æ°å']} {row['æ—¥ä»˜']} ä»¶æ•°={row['ä»¶æ•°']} ç—…é™¢={row['ç—…é™¢']}\n")
    f.write("\n--- åŒä¸€ç—…é™¢é‡è¤‡è¶…é ---\n")
    if df_hdup.empty:
        f.write("ãªã—\n")
    else:
        for _, row in df_hdup.iterrows():
            f.write(f"{row['æ°å']} {row['ç—…é™¢']} å›æ•°={row['å›æ•°']} è¶…é={row['è¶…é']}\n")

print("\nğŸ“„ è§£æçµæœï¼ˆtxtï¼‰ã‚’å‡ºåŠ›ã—ã¾ã—ãŸ:")
print(f"   {analysis_path}")

print("\nğŸ“Œ å½“ç›´å›æ•°ä¸€è¦§")
for doc, cnt in sorted_counts:
    print(f"   {doc}: {cnt}å›")

print("\n" + "="*60)
print("   ğŸ‰ å®Œäº†ï¼")
print("="*60)
print(f"\nğŸ“¥ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
print("\nã€ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã€‘")
print("  - schedule: æœ€è‰¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«")
print("  - summary_ä»Šæœˆ / summary_ç´¯è¨ˆ: ã‚µãƒãƒªãƒ¼")
print("="*60)

if COLAB_AVAILABLE:
    files.download(output_path)
