# @title å½“ç›´ãã‚“ v6.0.0 (åˆ¶ç´„ä½“ç³»å…¨é¢æ”¹å®š)
# ä¿®æ­£å†…å®¹:
# v6.0.0 (2026-02-02):
# - åˆ¶ç´„ä½“ç³»ã‚’å…¨é¢æ”¹å®š
# - çµ¶å¯¾ç¦å¿Œ(ABS): 11é …ç›®
#   - ABS-001ã€œ009: æ—¢å­˜ã®çµ¶å¯¾ç¦å¿Œ
#   - ABS-010: TARGET_CAPéµå®ˆï¼ˆnè¶…éç¦æ­¢ï¼‰
#   - ABS-011: å¤§å­¦ç³»2å›ã¾ã§ï¼ˆB-Kåˆ—åˆè¨ˆï¼‰
# - ãƒãƒ¼ãƒ‰åˆ¶ç´„(HARD): 3é …ç›®
#   - HARD-001: B/Iåˆ—1å›ã¾ã§ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—Aï¼‰
#   - HARD-002: C-H/J-Kåˆ—1å›ã¾ã§ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—Bï¼‰
#   - HARD-003: å¤–ç—…é™¢1å›ä»¥ä¸Šï¼ˆL-Yåˆ—ï¼‰
# - æº–ãƒãƒ¼ãƒ‰åˆ¶ç´„(SEMI): 2é …ç›®
#   - SEMI-001: Båˆ—ã®ã¿ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰å¿…é ˆï¼ˆsheet3ã€Œ1ã€ã¯ä¾‹å¤–ï¼‰
#   - SEMI-002: C-Håˆ—ã®ã¿ã‚«ãƒ†å½“ç•ªæ—¥å¿…é ˆï¼ˆI-Kåˆ—ã¯å¯¾è±¡å¤–ã€sheet3ã€Œ1ã€ã¯ä¾‹å¤–ï¼‰
# - ã‚½ãƒ•ãƒˆåˆ¶ç´„(SOFT): 3é …ç›®
#   - SOFT-001: å…¬å¹³æ€§ï¼ˆmax-minæœ€å°åŒ–ï¼‰
#   - SOFT-002: ã‚³ãƒ¼ãƒ‰1.2å„ªå…ˆï¼ˆå¤§å­¦ç³»0å›ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
#   - SOFT-003: å¤§å­¦/å¤–ç—…é™¢å·®ï¼ˆå·®3ä»¥ä¸ŠãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
# - ä¸è¦ãªåˆ¶ç´„ã‚’å‰Šé™¤ï¼ˆHARD/ABSã§å¸åï¼‰
# - ABS-001ï¼ˆã‚³ãƒ¼ãƒ‰0ç¦æ­¢ï¼‰ä¿®æ­£
#   - fix_hard_constraint_violations()ã®ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ã‚³ãƒ¼ãƒ‰0ãƒã‚§ãƒƒã‚¯è¿½åŠ 
#   - æœ€çµ‚æ‰‹æ®µã§ã‚‚ã‚³ãƒ¼ãƒ‰0åŒ»å¸«ã‚’é™¤å¤–
#   - å…¨å“¡ã‚³ãƒ¼ãƒ‰0ã®å ´åˆã¯æœªå‰²å½“ã®ã¾ã¾ï¼ˆé•åå‰²å½“ã‚ˆã‚Šå„ªå…ˆï¼‰
# - inactiveåŒ»å¸«å‡¦ç†ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‚ç…§ã‚’è¿½åŠ 
#   - CONSTRAINT_RULES.md Â§5æº–æ‹ ã‚³ãƒ¡ãƒ³ãƒˆ
# v4.7 (2026-01-31):
# - CONSTRAINT_RULES.md v5.2ä»•æ§˜ã«åŸºã¥ãæ•´å‚™
# v4.3 (2026-01-30):
# - C-Håˆ—ã‚«ãƒ†å½“ç•ªåˆ¶ç´„ã‚’ã‚½ãƒ•ãƒˆåˆ¶ç´„ã«å¤‰æ›´ï¼ˆãƒãƒ¼ãƒ‰åˆ¶ç´„ã‹ã‚‰é™¤å¤–ï¼‰
#   - é©æ ¼åŒ»å¸«ä¸è¶³æ™‚ã®ãƒ‘ã‚¿ãƒ¼ãƒ³é™¤å¤–ã‚’é˜²æ­¢
#   - ãƒšãƒŠãƒ«ãƒ†ã‚£(120)ã¨fixé–¢æ•°ã¯ç¶­æŒ
#   - ä¿®æ­£ä¸å¯ã§ã‚‚ãƒ‘ã‚¿ãƒ¼ãƒ³é¸æŠå¯èƒ½ã«
# - recompute_statså‘¼ã³å‡ºã—ã®unpackingä¿®æ­£ï¼ˆ*_è¿½åŠ ï¼‰
# v4.2 (2026-01-30):
# - å¹³æ—¥å¤§å­¦ç³»(B,I-Kåˆ—)ã®åˆ¶ç´„ã‚’ç·©å’Œ
#   - sheet3ã§ã€Œ1ã€ã‚’æŒã¤åŒ»å¸«ã¯ã‚«ãƒ†å½“ç•ªãŒåˆã‚ãªãã¦ã‚‚è¨±å®¹
#   - ã‚«ãƒ†å½“ç•ªãªã—åŒ»å¸«ã‚‚é…ç½®å¯èƒ½
#   - is_weekday_university_slot()ã€is_eligible_for_weekday_university_slot()é–¢æ•°ã‚’è¿½åŠ 
#   - SHEET3_CODE_1_DOCTORSã‚»ãƒƒãƒˆã‚’è¿½åŠ 
# - CCï¼ˆå¤§å‹é€£ä¼‘ç‰¹åˆ¥ã‚·ãƒ•ãƒˆï¼‰ã‚’ç‰¹åˆ¥ã‚«ã‚¦ãƒ³ãƒˆã¨ã—ã¦æ‰±ã†
#   - is_cc_assignment()é–¢æ•°ã‚’è¿½åŠ ï¼ˆCCã‹ã©ã†ã‹åˆ¤å®šï¼‰
#   - recompute_statsã§CCåˆ¥ã‚«ã‚¦ãƒ³ãƒˆï¼ˆcc_counts, cc_bg_counts, cc_ht_countsï¼‰ã‚’è¿½è·¡
#   - ä»¥ä¸‹ã®è¨ˆç®—ã‹ã‚‰CCã‚’é™¤å¤–:
#     - å…¬å¹³æ€§è¨ˆç®—ï¼ˆfairness_penaltyï¼‰
#     - BG/HTä¸å‡è¡¡è¨ˆç®—ï¼ˆbg_ht_imbalance_violationsï¼‰
#     - å¤–ç—…é™¢é‡è¤‡è¨ˆç®—ï¼ˆexternal_hosp_dup_violationsï¼‰
#     - å¤§å­¦3å›ä»¥ä¸Šé•åï¼ˆbg_over_2_violationsï¼‰
#   - å„fixé–¢æ•°ã§ã‚‚CCé™¤å¤–ã‚’é©ç”¨
# v4.1 (2026-01-30):
# - æ æ±ºå®šé †åºã‚’æœ€é©åŒ–
#   - å¤§å­¦ä¼‘æ—¥(C-Håˆ—) â†’ å¤§å­¦å¹³æ—¥(B,I-Kåˆ—) â†’ å¤–ç—…é™¢(L-Yåˆ—) ã®é †ã«å‰²ã‚Šå½“ã¦
#   - C-Håˆ—ã¯ã‚«ãƒ†å½“ç•ªåˆ¶ç´„ãŒã‚ã‚‹ãŸã‚å…ˆã«åŸ‹ã‚ã‚‹ã“ã¨ã§åˆ¶ç´„ã‚’æº€ãŸã—ã‚„ã™ãã™ã‚‹
#   - slot_priorityé–¢æ•°ã‚’è¿½åŠ ã—ã¦å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆ
# - ãƒãƒ¼ãƒ‰åˆ¶ç´„ãƒã‚§ãƒƒã‚¯ã«C-Håˆ—ã‚«ãƒ†å½“ç•ªé•åã‚’è¿½åŠ 
#   - ch_kate_violations > 0 ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å¤–
# v4.0 (2026-01-30):
# - C-Håˆ—ï¼ˆä¼‘æ—¥å¤§å­¦ç³»ï¼‰ã®ã‚«ãƒ†å½“ç•ªåˆ¶ç´„ã‚’è¿½åŠ 
#   - C-Håˆ—ã¯ã‚«ãƒ†å½“ç•ªã®ã‚ã‚‹åŒ»å¸«ï¼ˆãã®æ—¥ã«ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã‚ã‚Šï¼‰ã¾ãŸã¯
#     ã‚«ãƒ†å½“ç•ªãŒä¸€å›ã‚‚ãªã„åŒ»å¸«ï¼ˆsheet3ã«1ã¤ã‚‚ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆãªã—ï¼‰ã®ã¿å‰²ã‚Šå½“ã¦å¯èƒ½
#   - NO_KATE_DOCTORSã‚»ãƒƒãƒˆã‚’è¿½åŠ ï¼ˆã‚«ãƒ†å½“ç•ªãªã—åŒ»å¸«ã®é›†åˆï¼‰
#   - is_ch_slot()ã€is_eligible_for_ch_slot()é–¢æ•°ã‚’è¿½åŠ 
#   - collect_candidatesã«relax_ch_kateãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
#   - fix_ch_kate_violations()é–¢æ•°ã‚’è¿½åŠ ï¼ˆé•åä¿®æ­£ç”¨ï¼‰
#   - ch_kate_violationsãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¿½åŠ ï¼ˆãƒšãƒŠãƒ«ãƒ†ã‚£120ï¼‰
#   - æœ€é©åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³#4.5ã«è¿½åŠ ï¼ˆå¤§å­¦æœ€ä½1å›ã®å¾Œã€gapé•åã®å‰ï¼‰
# v3.9 (2026-01-30):
# - printå‡ºåŠ›ã®æœ€é©åŒ–
#   - tqdmã«ã‚ˆã‚‹é€²æ—ãƒãƒ¼è¡¨ç¤ºï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆã€å±€æ‰€æ¢ç´¢ï¼‰
#   - ã‚»ã‚¯ã‚·ãƒ§ãƒ³åŒºåˆ‡ã‚Šã®çµ±ä¸€ï¼ˆ=== ===å½¢å¼ï¼‰
#   - éšå±¤æ§‹é€ è¡¨ç¤ºï¼ˆâ”œâ”€/â””â”€ï¼‰
#   - TOPãƒ‘ã‚¿ãƒ¼ãƒ³è©•ä¾¡ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
#   - å†—é•·ãªå‡ºåŠ›ã‚’å‰Šæ¸›
# - å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’åæ˜ ï¼ˆfilename_v3.9.xlsxï¼‰
# - VERSIONå®šæ•°ã‚’è¿½åŠ 
# v3.8 (2026-01-30):
# - å¤–ç—…é™¢æœ€ä½1å›ã‚’ãƒãƒ¼ãƒ‰åˆ¶ç´„ã¨ã—ã¦è¿½åŠ ï¼ˆå¤§å­¦3å›ä»¥ä¸Šã‚’é˜²æ­¢ï¼‰
#   - fix_university_over_2_violationsã‚’æ‹¡å¼µã—ã¦å¤–ç—…é™¢0å›ã‚‚æ¤œå‡ºãƒ»ä¿®æ­£
#   - ht_0_violationsãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¿½åŠ ï¼ˆãƒšãƒŠãƒ«ãƒ†ã‚£300ï¼‰
#   - ãƒãƒ¼ãƒ‰åˆ¶ç´„ãƒã‚§ãƒƒã‚¯ã«bg_over_2_violationsã€ht_0_violationsã‚’è¿½åŠ 
# - æœ€é©åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é †åºã‚’ä¿®æ­£
#   - BG/HTä¸å‡è¡¡(#6) â†’ å¤–ç—…é™¢é‡è¤‡(#7) ã®é †åºã«å¤‰æ›´
# - å‡¦ç†ç•ªå·ã®è¡¨ç¤ºã‚’è¿½åŠ  [X/15]
# v3.7 (2026-01-30):
# - build_hard_constraint_violationsã®returnæ–‡æ¬ è½ãƒã‚°ã‚’ä¿®æ­£
# - CODE_2åŒ»å¸«ã®n+1å›é•åã‚’æœ€é©åŒ–å¾Œã«ãƒã‚§ãƒƒã‚¯ãƒ»ä¿®æ­£ã™ã‚‹æ©Ÿèƒ½ã‚’è¿½åŠ 
#   - fix_code_2_extra_violationsé–¢æ•°ã‚’è¿½åŠ ï¼ˆãƒãƒ¼ãƒ‰åˆ¶ç´„ã¨ã—ã¦ä¿®æ­£ï¼‰
#   - evaluate_schedule_with_rawã«code_2_extra_violationsãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¿½åŠ 
#   - ãƒãƒ¼ãƒ‰åˆ¶ç´„ãƒã‚§ãƒƒã‚¯ã«CODE_2 n+1é•åã‚’è¿½åŠ 
#   - æœ€é©åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®#2ã«è¿½åŠ ï¼ˆãƒãƒ¼ãƒ‰åˆ¶ç´„ç›´å¾Œã€TARGET_CAPå‰ï¼‰
# v3.6 (2026-01-30):
# - å¯å¦ã‚³ãƒ¼ãƒ‰2ã®åŒ»å¸«ã‚’EXTRAæ ï¼ˆn+1å›ï¼‰å¯¾è±¡ã‹ã‚‰é™¤å¤–ï¼ˆãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼‰
#   - has_code_2_anywhereé–¢æ•°ã‚’è¿½åŠ ï¼ˆsheet2ã§ã„ãšã‚Œã‹ã®æ—¥ã«2ã‚’æŒã¤åŒ»å¸«ã‚’åˆ¤å®šï¼‰
#   - CODE_2_DOCTORSãƒªã‚¹ãƒˆã‚’ä½œæˆ
#   - EXTRA_ALLOWEDã®è¨ˆç®—æ™‚ã«CODE_2_DOCTORSã‚’é™¤å¤–
#   - å¯å¦ã‚³ãƒ¼ãƒ‰2ã®åŒ»å¸«ã¯å¤§å­¦ç³»ã®ã¿å¯èƒ½ãªãŸã‚ã€å¤–ç—…é™¢æ å¢—åŠ ã¯ä¸é©åˆ‡
#   - å‡ºåŠ›ã«ã€Œå¯å¦ã‚³ãƒ¼ãƒ‰2åŒ»å¸«ï¼ˆEXTRAæ å¯¾è±¡å¤–ï¼‰ã€ã‚’è¡¨ç¤º
# v3.4 (2026-01-29):
# - TARGET_CAPé•åã®å³æ ¼åŒ–
#   - ãƒ‘ã‚¿ãƒ¼ãƒ³é¸æŠæ™‚ã« cap_violations > 0 ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å¤–
#   - gap_violations > 0ã€unassigned_slots > 0 ã‚‚é™¤å¤–
#   - ãƒãƒ¼ãƒ‰åˆ¶ç´„ã‚’æº€ãŸã™ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ã‚’å€™è£œã¨ã—ã¦é¸æŠ
# - å¤šè»¸ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…
#   - å…¬å¹³æ€§é‡è¦–: TARGET_CAPã€åŒ»å¸«é–“ã®å‰²å½“å›æ•°ã®å…¬å¹³æ€§ã‚’æœ€å„ªå…ˆ
#   - é€£ç¶šå½“ç›´å›é¿é‡è¦–: gapé•åã€å¤–ç—…é™¢é‡è¤‡ã‚’æœ€å„ªå…ˆ
#   - ãƒãƒ©ãƒ³ã‚¹é‡è¦–: å¤§å­¦/å¤–ç—…é™¢ãƒãƒ©ãƒ³ã‚¹ã€å¹³æ—¥/ä¼‘æ—¥ãƒãƒ©ãƒ³ã‚¹ã‚’æœ€å„ªå…ˆ
#   - å„è»¸ã‹ã‚‰æœ€è‰¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’1ã¤ãšã¤é¸æŠã—ã€åˆè¨ˆ3ãƒ‘ã‚¿ãƒ¼ãƒ³å‡ºåŠ›
# - å…¬å¹³æ€§ã®å¼·åˆ¶ä¿®æ­£æ©Ÿèƒ½ã‚’è¿½åŠ 
#   - fix_fairness_imbalance: æœ€å¤§å‰²å½“å›æ•°ã¨æœ€å°å‰²å½“å›æ•°ã®å·®ã‚’ç¸®ã‚ã‚‹
#   - 4å›ã®åŒ»å¸«ã‹ã‚‰1å›ã®åŒ»å¸«ã«ã‚·ãƒ•ãƒˆã‚’ç§»å‹•ã—ã€å…¬å¹³æ€§ã‚’é”æˆ
#   - å·®ãŒ1ä»¥ä¸‹ã«ãªã‚‹ã¾ã§ä¿®æ­£ï¼ˆä¾‹: 1å›ã¨4å› â†’ 2å›ã¨3å›ï¼‰
#   - æœ€é©åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ±åˆï¼ˆä¿®æ­£é †åºã®æœ€å¾Œã«å®Ÿè¡Œï¼‰
# v3.3 (2026-01-28):
# - å¤§å­¦ç—…é™¢3å›ä»¥ä¸Šã‚’ç¦æ­¢ï¼ˆä¸æº€ãŒé«˜ã„ï¼‰
#   - bg_over_2_violations: å¤§å­¦3å›ä»¥ä¸Šã®é•åã‚’æ¤œå‡ºï¼ˆãƒšãƒŠãƒ«ãƒ†ã‚£150ï¼‰
#   - fix_university_over_2_violations: æœ€é©åŒ–å¾Œã«å¤§å­¦3å›ä»¥ä¸Šã‚’ä¿®æ­£
#   - å¤§å­¦ã®å‰²å½“ã‚’å¤–ç—…é™¢ã«ç§»å‹•ã€ã¾ãŸã¯å‰Šé™¤ã—ã¦2å›ä»¥ä¸‹ã«åˆ¶é™
# - å¤§å­¦ç—…é™¢ã®å¹³æ—¥åã‚Šåˆ¶ç´„ã‚’è¿½åŠ ï¼ˆå¹³æ—¥2å›ä»¥ä¸Šã¯ä¸æº€ï¼‰
#   - bg_weekday_over_violations: å¤§å­¦ã®å¹³æ—¥2å›ä»¥ä¸Šã®é•åã‚’æ¤œå‡ºï¼ˆãƒšãƒŠãƒ«ãƒ†ã‚£80ï¼‰
#   - fix_university_weekday_balance_violations: æœ€é©åŒ–å¾Œã«å¹³æ—¥åã‚Šã‚’ä¿®æ­£
#   - å¤§å­¦å¹³æ—¥ã®å‰²å½“ã‚’å¤–ç—…é™¢ã«ç§»å‹•ã€ã¾ãŸã¯å‰Šé™¤
# - å…¨ä½“ã®å…¬å¹³æ€§ã‚’å¼·åŒ–ï¼ˆ2å›ã®åŒ»å¸«ãŒã„ã‚‹ãªã‚‰4å›ã®åŒ»å¸«ã‹ã‚‰æ¸¡ã™ï¼‰
#   - fairness_penaltyè¨ˆç®—ã‚’å¼·åŒ–: diff_total >= 2ã®å ´åˆã€2å€ã®ãƒšãƒŠãƒ«ãƒ†ã‚£
#   - W_FAIR_TOTAL: 10 â†’ 30ï¼ˆå…¬å¹³æ€§ã®é‡è¦åº¦ã‚’ä¸Šã’ã‚‹ï¼‰
#   - min=2, max=4ã®ã‚ˆã†ãªå·®ãŒå¤§ãã„å ´åˆã«å¼·ãåˆ¶ç´„
# - ä¿®æ­£ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ‹¡å……
#   - æœ€é©åŒ–å¾Œã«å…¨ã¦ã®åˆ¶ç´„é•åã‚’å¼·åˆ¶çš„ã«ä¿®æ­£
#   - é †åº: ãƒãƒ¼ãƒ‰åˆ¶ç´„ â†’ TARGET_CAPï¼ˆå„ªå…ˆ1ï¼‰ â†’ å¤§å­¦æœ€ä½1å›ï¼ˆæº–ãƒãƒ¼ãƒ‰ã€å„ªå…ˆ2ï¼‰ â†’ gapï¼ˆå„ªå…ˆ3ï¼‰ â†’ å¤–ç—…é™¢DUPï¼ˆå„ªå…ˆ4ï¼‰ â†’ BG/HT â†’ å¤§å­¦3+ â†’ å¤§å­¦å¹³æ—¥åã‚Š â†’ å…¬å¹³æ€§
# v3.2 (2026-01-28):
# - ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³æ•°ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ100ã«æˆ»ã™ï¼ˆå‡¦ç†æ™‚é–“ã®æœ€é©åŒ–ï¼‰
#   - NUM_PATTERNS: 10000 â†’ 100
#   - TOP_KEEP: 100 â†’ 20
#   - REFINE_TOP: 20 â†’ 15
# - å¤§å­¦ç—…é™¢2å›ã®å ´åˆã€å¹³æ—¥1å›+ä¼‘æ—¥1å›ã®ãƒãƒ©ãƒ³ã‚¹åˆ¶ç´„ã‚’è¿½åŠ 
#   - bg_weekday_weekend_imbalance é•åã‚’æ¤œå‡º
#   - ãƒšãƒŠãƒ«ãƒ†ã‚£: 50
# - å„ªå…ˆé †ä½ã‚’å³æ ¼åŒ–ï¼ˆTARGET_CAP > gap > DUP ã‚’æ­»å®ˆï¼‰
#   - W_CAP = 200ï¼ˆå„ªå…ˆåº¦1ä½ï¼‰
#   - W_GAP = 100ï¼ˆå„ªå…ˆåº¦2ä½ã€3â†’100ã«å¼·åŒ–ï¼‰
#   - W_EXTERNAL_HOSP_DUP = 70ï¼ˆå„ªå…ˆåº¦3ä½ï¼‰
# v3.1 (2026-01-28):
# - å¤–ç—…é™¢ï¼ˆLï½Yåˆ—ï¼‰é‡è¤‡ã‚’å³æ ¼åŒ–ã€å¤§å­¦ç—…é™¢ï¼ˆBï½Kåˆ—ï¼‰é‡è¤‡ã¯è¨±å®¹
#   - è©•ä¾¡é–¢æ•°ã§å¤–ç—…é™¢é‡è¤‡ã¨å¤§å­¦ç—…é™¢é‡è¤‡ã‚’åˆ†é›¢
#   - W_EXTERNAL_HOSP_DUP=70ï¼ˆå„ªå…ˆåº¦3ä½ï¼šTARGET_CAP > gap > å¤–ç—…é™¢DUPï¼‰
#   - fix_external_hospital_dup_violationsé–¢æ•°ã§æœ€é©åŒ–å¾Œã«å¤–ç—…é™¢é‡è¤‡ã‚’ä¿®æ­£
#   - åŒã˜æ—¥ã®ä»–ã®å¤–ç—…é™¢ã«ç§»å‹•ã€ã¾ãŸã¯å‰²å½“å‰Šé™¤ã§ä¿®æ­£
# v3.0 (2026-01-28):
# - gapé•åï¼ˆ3æ—¥æœªæº€ã®é–“éš”ã§ã®å‰²å½“ï¼‰ã‚’å®Œå…¨ã«æ’é™¤
#   - åˆæœŸãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆæ™‚ã«gapé•å0å€‹ã®å€™è£œã®ã¿é¸æŠ
#   - å±€æ‰€æ¢ç´¢ã§gapé•å1ä»¥ä¸Šã«ãªã‚‹swapã‚’æ‹’å¦
#   - fix_gap_violationsé–¢æ•°ã§æœ€é©åŒ–å¾Œã«gapé•åã‚’å¼·åˆ¶ä¿®æ­£
#   - ç§»å‹•å…ˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å‰²å½“ã‚’å‰Šé™¤ã—ã¦é•åã‚’è§£æ¶ˆ
#   - åŒã˜ç—…é™¢ã ã‘ã§ãªãä»–ã®ç—…é™¢ã®ç©ºãæ ã‚‚æ¢ç´¢
# v2.8 (2026-01-24):
# - å¤§å­¦ç³»ã¨å¤–ç—…é™¢ã®å·®ãŒ3æœªæº€ã«ãªã‚‹åˆ¶ç´„ã‚’è¿½åŠ 
#   - è©•ä¾¡é–¢æ•°ã«å·®ãŒ3ä»¥ä¸Šã®å ´åˆã®ãƒšãƒŠãƒ«ãƒ†ã‚£è¿½åŠ ï¼ˆé‡ã¿100ï¼‰
#   - fix_bg_ht_imbalance_violationsé–¢æ•°ã§æœ€é©åŒ–å¾Œã«å·®3ä»¥ä¸Šã‚’ä¿®æ­£
# - recompute_statsé–¢æ•°ã®BG/HTç¯„å›²ã‚’ä¿®æ­£ï¼ˆBã€œGâ†’Bã€œKã€Hã€œUâ†’Lã€œYï¼‰
#   - ã“ã‚Œã«ã‚ˆã‚Šå‡ºåŠ›Excelã®ä»Šæœˆ/ç´¯è¨ˆã®å¤§å­¦åˆè¨ˆãƒ»å¤–ç—…é™¢åˆè¨ˆãŒæ­£ã—ãè¨ˆç®—ã•ã‚Œã‚‹
# - å¯å¦ã‚³ãƒ¼ãƒ‰1.2ã®åŒ»å¸«ãŒå¤§å­¦ç³»æœ€ä½1å›ã®åˆ¶ç´„ã‚’è¿½åŠ 
#   - get_avail_codeé–¢æ•°ã§1.2ã‚’èªè­˜ã§ãã‚‹ã‚ˆã†ä¿®æ­£
#   - fix_code_1_2_violationsé–¢æ•°ã§æœ€é©åŒ–å¾Œã«å¤§å­¦ç³»0å›ã‚’ä¿®æ­£
#   - è©•ä¾¡é–¢æ•°ã«1.2ã®åŒ»å¸«ãŒå¤§å­¦ç³»0å›ã®å ´åˆã®ãƒšãƒŠãƒ«ãƒ†ã‚£è¿½åŠ ï¼ˆé‡ã¿150ï¼‰
# - TARGET_CAPé•åã®å¼·åˆ¶ä¿®æ­£æ©Ÿèƒ½ã‚’è¿½åŠ 
#   - fix_target_cap_violationsé–¢æ•°ã§æœ€é©åŒ–å¾Œã«TARGET_CAPè¶…éã‚’ä¿®æ­£
#   - ä¸Šä½åŒ»å¸«ï¼ˆå°æ—ã€åŠå·ç­‰ï¼‰ã®å‰²å½“ã‚’ä¸‹ä½åŒ»å¸«ï¼ˆå¤§æ²³å†…ã€çŒªè‚¡ç­‰ï¼‰ã«ç§»å‹•
#   - W_CAPãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’50â†’200ã«å¼·åŒ–
# - ä½™ã‚Šæ ã®å‰²å½“ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä¿®æ­£ï¼ˆæ˜‡é †ã‚½ãƒ¼ãƒˆâ†’æœ€å¾Œã®EXTRA_SLOTSäººã‚’é¸æŠï¼‰
# - ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¿½åŠ ï¼š+1å›å¯¾è±¡ã®åŒ»å¸«åã€TARGET_CAPè¨­å®šå€¤ã€1.2å¯¾è±¡åŒ»å¸«ã‚’è¡¨ç¤º
# - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³æ•°ã‚’100ã«å¤‰æ›´ï¼ˆç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯èƒ½ï¼‰
# v2.7 (2026-01-24):
# - ãƒãƒ¼ãƒ‰åˆ¶ç´„é•åã®è‡ªå‹•ä¿®æ­£æ©Ÿèƒ½ã‚’å®Ÿè£…
#   - fix_hard_constraint_violationsé–¢æ•°ã‚’è¿½åŠ 
#   - å±€æ‰€æ¢ç´¢å®Œäº†å¾Œã«å…¨ã¦ã®é•åã‚’è‡ªå‹•æ¤œå‡ºãƒ»ä¿®æ­£
#   - ä»£æ›¿åŒ»å¸«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æœªå‰²å½“ã¨ã—ã¦è­¦å‘Šè¡¨ç¤º
#   - ä¿®æ­£å¾Œã«ã‚¹ã‚³ã‚¢ã‚’å†è©•ä¾¡ã—ã¦æœ€çµ‚çµæœã«åæ˜ 
# v2.6 (2026-01-23):
# - get_sched_codeé–¢æ•°ã®é‡å¤§ãªãƒã‚°ã‚’ä¿®æ­£
#   - "0"ã¨"3"ã‚’æœ‰åŠ¹ãªã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ã¨ã—ã¦æ‰±ã‚ãªã„ã‚ˆã†ã«å¤‰æ›´
#   - "0"ã¯ãƒ‡ãƒ¼ã‚¿ãªã—ã€"3"ã¯å¯å¦ã‚³ãƒ¼ãƒ‰ã§ã‚ã‚Šã€ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ã§ã¯ãªã„
#   - ã“ã‚Œã«ã‚ˆã‚Šã€ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ä¿æœ‰åŒ»å¸«ãŒãã®æ—¥ã«"0"ã‚„"3"ã®å ´åˆã€Lã€œYåˆ—ã¸ã®å‰²å½“ãŒæ­£ã—ãè¨±å¯ã•ã‚Œã‚‹
# v2.5 (2026-01-21):
# - ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ã¨åˆ—ã®åˆ¶ç´„ã‚’ä¿®æ­£
#   - sheet3ã§å°‘ãªãã¨ã‚‚1ã¤ã®ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ï¼ˆA,B,C,CC,D,Eç­‰ï¼‰ã‚’æŒã¤åŒ»å¸«ã‚’ç‰¹å®š
#   - ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ä¿æœ‰åŒ»å¸«: ãã®æ—¥ã«ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã®ã¿Bã€œKåˆ—å¯ã€ã‚³ãƒ¼ãƒ‰ãŒãªã„æ—¥ã¯å‰²å½“ãªã—
#   - ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ä¿æœ‰åŒ»å¸«: ãã®æ—¥ã«ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã¯Lã€œYåˆ—ç¦æ­¢
#   - ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰éä¿æœ‰åŒ»å¸«: Bã€œKåˆ—ã«è‡ªç”±ã«å‰²ã‚Šå½“ã¦å¯èƒ½
# - å‡ºåŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’1å€‹ã‹ã‚‰3å€‹ã«å¤‰æ›´ï¼ˆTOP3å€™è£œã‚’æç¤ºï¼‰
# v2.4 (2026-01-21):
# - åˆ—æ§‹é€ ã®å¤‰æ›´å¯¾å¿œï¼ˆBã€œYåˆ—ï¼‰
#   - å¯å¦ã‚³ãƒ¼ãƒ‰2: Bã€œQåˆ—ã®ã¿å¯ï¼ˆå¾“æ¥Bã€œMåˆ—ï¼‰
#   - å¯å¦ã‚³ãƒ¼ãƒ‰3: Lã€œYåˆ—ã®ã¿å¯ï¼ˆå¾“æ¥Hã€œUåˆ—ï¼‰
#   - ã‚«ãƒ†è¡¨åˆ¶ç´„: Lã€œYåˆ—ç¦æ­¢ï¼ˆå¾“æ¥Hã€œUåˆ—ï¼‰
# - Bã€œHåˆ—ã®2å›ä¸Šé™åˆ¶ç´„ã‚’å®Ÿè£…
# - è¨ºæ–­ã‚·ãƒ¼ãƒˆã«Bã€œHåˆ—2å›è¶…éé•åæ¤œå‡ºã‚’è¿½åŠ 
# v2.3 (2026-01-21):
# - Bã€œKåˆ—ã®ã‚«ãƒ†è¡¨è¦ä»¶ã‚’ãƒãƒ¼ãƒ‰åˆ¶ç´„ã«å¤‰æ›´ï¼ˆrelax_scheduleã§ç·©å’Œä¸å¯ï¼‰
# - Bã€œKåˆ—ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰æ¬ å¦‚é•åã®æ¤œå‡ºæ©Ÿèƒ½ã‚’è¿½åŠ 
# - can_assign_doc_to_sloté–¢æ•°ã«Bã€œKåˆ—ã‚«ãƒ†è¡¨ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ ï¼ˆå±€æ‰€æ¢ç´¢ã§ã‚‚é©ç”¨ï¼‰
# v2.2 (2026-01-21):
# - ãƒãƒ¼ãƒ‰åˆ¶ç´„é•åã®ä¿®æ­£ï¼ˆå¯å¦ã‚³ãƒ¼ãƒ‰0ã€ã‚«ãƒ†è¡¨+å¤–ç—…é™¢ã€ã‚³ãƒ¼ãƒ‰2/3é•åï¼‰
# - collect_candidatesé–¢æ•°ã§ã‚³ãƒ¼ãƒ‰0ã‚’å¸¸ã«é™¤å¤–ã™ã‚‹ã‚ˆã†ä¿®æ­£
# - ã‚«ãƒ†è¡¨ãŒã‚ã‚‹æ—¥ã®Hã€œUåˆ—å‰²å½“ã‚’çµ¶å¯¾ç¦æ­¢ã«å¤‰æ›´
# - ãƒãƒ¼ãƒ‰åˆ¶ç´„é•åãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã‚’è¨ºæ–­ã‚·ãƒ¼ãƒˆã«è¿½åŠ 
# v2.1:
# - ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å•é¡Œã®ä¿®æ­£
# - åŒ»å¸«åã®æ­£è¦åŒ–ï¼ˆç©ºç™½é™¤å»ï¼‰
# - sheet4ãƒ˜ãƒƒãƒ€æ¤œå‡ºç¯„å›²ã®æ‹¡å¤§ï¼ˆ30â†’50è¡Œï¼‰
# - date_doc_countã®KeyErrorå¯¾ç­–ï¼ˆdefaultdictåŒ–ï¼‰
# - åŒæ—¥é‡è¤‡ãƒã‚§ãƒƒã‚¯ã®å¼·åŒ–
# - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ”¹å–„

import io
import pandas as pd
import numpy as np
from collections import defaultdict
import random
import importlib.util
import os

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³å®šæ•°
VERSION = "6.0.0"

# tqdmã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆé€²æ—ãƒãƒ¼ç”¨ï¼‰
try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False
    def tqdm(iterable, **kwargs):
        return iterable

COLAB_AVAILABLE = (
    importlib.util.find_spec("google") is not None
    and importlib.util.find_spec("google.colab") is not None
)
if COLAB_AVAILABLE:
    from google.colab import files

# =========================
# ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š
# =========================
HOLIDAYS = set()  # ç¥æ—¥ã‚’å…¥ã‚Œã‚‹ãªã‚‰ã“ã“ï¼ˆä¾‹: {pd.Timestamp("2026-01-01"), ...}ï¼‰
BG_DAY_COLS = set()    # åˆ—åã§ã€Œæ˜¼ã€å›ºå®šã—ãŸã„å¤§å­¦æ ãŒã‚ã‚Œã°è¿½åŠ 
BG_NIGHT_COLS = set()  # åˆ—åã§ã€Œå¤œã€å›ºå®šã—ãŸã„å¤§å­¦æ ãŒã‚ã‚Œã°è¿½åŠ 

WED_FORBIDDEN_DOCTORS = {'é‡‘åŸ', 'å±±ç”°', 'é‡å¯º'}  # æ°´æ›œã® Hã€œU ã‚’ç¦æ­¢ã—ãŸã„åŒ»å¸«

NUM_PATTERNS = int(os.getenv("NUM_PATTERNS", "100"))  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ100ãƒ‘ã‚¿ãƒ¼ãƒ³

# sheet1 ã®ã€Œæ ã€æ‰±ã„ã™ã‚‹å…¥åŠ›å€¤ï¼ˆ1ä»¥å¤–ã®è¨˜å·ã‚‚è¨±å®¹ã—ãŸã„å ´åˆï¼‰
SLOT_MARKERS = {1, 1.0, "1", "ã€‡", "â—‹", "â—¯", "â—"}

# --- ãƒ­ãƒ¼ã‚«ãƒ«æ¢ç´¢ï¼ˆå…¥æ›¿ï¼‰è¨­å®š ---
LOCAL_SEARCH_ENABLED = False   # v5.7.1: æœ€é©åŒ–ç„¡åŠ¹åŒ–
OPTIMIZATION_ENABLED = False   # v5.7.1: fixé–¢æ•°ç¾¤ã‚’ç„¡åŠ¹åŒ–ï¼ˆçµ¶å¯¾ç¦å¿Œã®ã¿å³å®ˆï¼‰
TOP_KEEP = 20                 # greedyã§æ®‹ã™å€™è£œæ•°ï¼ˆ100ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ä¸Šä½20å€™è£œã‚’ä¿æŒï¼‰
REFINE_TOP = 15               # ãƒ­ãƒ¼ã‚«ãƒ«æ¢ç´¢ã‚’ã‹ã‘ã‚‹å€™è£œæ•°ï¼ˆä¸Šä½15å€™è£œã‚’æœ€é©åŒ–ï¼‰
LOCAL_MAX_ITERS = 3000        # 1å€™è£œã‚ãŸã‚Šã®å…¥æ›¿è©¦è¡Œå›æ•°
LOCAL_PATIENCE = 1200         # æ”¹å–„ãŒå‡ºãªã„è©¦è¡ŒãŒã“ã®å›æ•°ç¶šã„ãŸã‚‰æ‰“ã¡åˆ‡ã‚Š
LOCAL_REFRESH_EVERY = 200     # å•é¡ŒåŒ»å¸«ï¼ˆgap/é‡è¤‡ï¼‰ã‚’å†æŠ½å‡ºã™ã‚‹é–“éš”

# v6.0.0 ã‚¹ã‚³ã‚¢é‡ã¿ï¼ˆã‚½ãƒ•ãƒˆåˆ¶ç´„ã®ã¿ï¼‰
# çµ¶å¯¾ç¦å¿Œ(ABS)ã¨ãƒãƒ¼ãƒ‰åˆ¶ç´„(HARD)ã¯å€™è£œé¸å®šæ™‚ã«ãƒã‚§ãƒƒã‚¯æ¸ˆã¿
W_FAIR_TOTAL = 30          # SOFT-001: å…¬å¹³æ€§ï¼ˆmax-minæœ€å°åŒ–ï¼‰
W_CODE_12_UNIV = 150       # SOFT-002: ã‚³ãƒ¼ãƒ‰1.2å„ªå…ˆï¼ˆå¤§å­¦ç³»0å›ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
W_BG_HT_DIFF = 100         # SOFT-003: å¤§å­¦/å¤–ç—…é™¢å·®ï¼ˆå·®3ä»¥ä¸ŠãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
# ä»¥ä¸‹ã¯çµ¶å¯¾ç¦å¿Œã®ãŸã‚ãƒšãƒŠãƒ«ãƒ†ã‚£ä¸è¦ï¼ˆv6.0.0ï¼‰
W_GAP = 0                  # ABS-007ã§å¯¾å¿œ
W_HOSP_DUP = 0             # ABS-008ã§å¯¾å¿œ
W_EXTERNAL_HOSP_DUP = 0    # ABS-008ã§å¯¾å¿œ
W_UNASSIGNED = 0           # ABS-009ã§å¯¾å¿œ
W_CAP = 0                  # ABS-010ã§å¯¾å¿œ
W_BG_SPREAD = 0            # å‰Šé™¤ï¼ˆç°¡ç•¥åŒ–ï¼‰
W_HT_SPREAD = 0            # å‰Šé™¤ï¼ˆç°¡ç•¥åŒ–ï¼‰
W_WD_SPREAD = 0            # å‰Šé™¤ï¼ˆç°¡ç•¥åŒ–ï¼‰
W_WE_SPREAD = 0            # å‰Šé™¤ï¼ˆç°¡ç•¥åŒ–ï¼‰
W_BK_LY_BALANCE = 2        # B-K/L-Y ã®æ¯”ç‡ãƒãƒ©ãƒ³ã‚¹ï¼ˆãªã‚‹ã¹ã1:1ï¼‰

# =========================
# åˆ¶ç´„IDå®šç¾©ï¼ˆv5.2ä»•æ§˜æ›¸æº–æ‹ ï¼‰
# =========================
# çµ¶å¯¾ç¦å¿Œï¼ˆABS: é…ç½®ä¸å¯ï¼‰
CONSTRAINT_ABS_001 = "ABS-001"  # å¯å¦ã‚³ãƒ¼ãƒ‰0ç¦æ­¢
CONSTRAINT_ABS_002 = "ABS-002"  # ã‚³ãƒ¼ãƒ‰2ã®åˆ—åˆ¶ç´„
CONSTRAINT_ABS_003 = "ABS-003"  # ã‚³ãƒ¼ãƒ‰3ã®åˆ—åˆ¶ç´„
CONSTRAINT_ABS_004 = "ABS-004"  # ã‚«ãƒ†å½“ç•ªæ—¥ã®å¤–ç—…é™¢ç¦æ­¢
CONSTRAINT_ABS_005 = "ABS-005"  # åŒæ—¥é‡è¤‡ç¦æ­¢
CONSTRAINT_ABS_006 = "ABS-006"  # æ°´æ›œæ—¥Lã€œYç¦æ­¢åŒ»å¸«

# ãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼ˆHARD: ãƒ‘ã‚¿ãƒ¼ãƒ³é™¤å¤–ï¼‰
CONSTRAINT_HARD_001 = "HARD-001"  # TARGET_CAPè¶…é
CONSTRAINT_HARD_002 = "HARD-002"  # gapé•å
CONSTRAINT_HARD_003 = "HARD-003"  # æœªå‰²å½“æ 
CONSTRAINT_HARD_004 = "HARD-004"  # CODE_2ã®n+1é•å

# æº–ãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼ˆSEMI: ç·©å’Œå¯ï¼‰
CONSTRAINT_SEMI_001 = "SEMI-001"  # å¹³æ—¥å¤§å­¦ç³»ã‚«ãƒ†è¦ä»¶
CONSTRAINT_SEMI_002 = "SEMI-002"  # ä¼‘æ—¥å¤§å­¦ç³»ã‚«ãƒ†å½“ç•ª
CONSTRAINT_SEMI_003 = "SEMI-003"  # gapåˆ¶ç´„
CONSTRAINT_SEMI_004 = "SEMI-004"  # å¤§å­¦æœ€ä½1å›

# ã‚½ãƒ•ãƒˆåˆ¶ç´„ï¼ˆSOFT: ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
CONSTRAINT_SOFT_001 = "SOFT-001"  # å¤–ç—…é™¢0å› (W=300)
CONSTRAINT_SOFT_002 = "SOFT-002"  # å¤§å­¦3å›ä»¥ä¸Š (W=150)
CONSTRAINT_SOFT_003 = "SOFT-003"  # å¤–ç—…é™¢åŒä¸€ç—…é™¢é‡è¤‡ (W=150)
CONSTRAINT_SOFT_004 = "SOFT-004"  # CODE_1.2å¤§å­¦0å› (W=150)
CONSTRAINT_SOFT_005 = "SOFT-005"  # gapé•å (W=100)
CONSTRAINT_SOFT_006 = "SOFT-006"  # BG/HTå·®3ä»¥ä¸Š (W=100)
CONSTRAINT_SOFT_007 = "SOFT-007"  # å¤§å­¦å¹³æ—¥2å›ä»¥ä¸Š (W=80)
CONSTRAINT_SOFT_008 = "SOFT-008"  # å…¬å¹³æ€§ (W=30)
CONSTRAINT_SOFT_009 = "SOFT-009"  # å¤§å­¦ã°ã‚‰ã¤ã (W=3)
CONSTRAINT_SOFT_010 = "SOFT-010"  # å¤–ç—…é™¢ã°ã‚‰ã¤ã (W=3)
CONSTRAINT_SOFT_011 = "SOFT-011"  # ä¼‘æ—¥ã°ã‚‰ã¤ã (W=3)
CONSTRAINT_SOFT_012 = "SOFT-012"  # å¹³æ—¥ã°ã‚‰ã¤ã (W=2)
CONSTRAINT_SOFT_013 = "SOFT-013"  # B-K/L-Yæ¯”ç‡ãƒãƒ©ãƒ³ã‚¹ (W=2)
CONSTRAINT_SOFT_014 = "SOFT-014"  # å¤§å­¦åŒä¸€ç—…é™¢é‡è¤‡ (W=0)

# =========================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================
def strip_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [c.strip() if isinstance(c, str) else c for c in df.columns]
    return df

def make_unique(names):
    """é‡è¤‡åˆ—åã‚’ _2, _3 ... ã§ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–"""
    seen = {}
    out = []
    for n in names:
        n = "" if pd.isna(n) else n
        if n not in seen:
            seen[n] = 1
            out.append(n)
        else:
            seen[n] += 1
            out.append(f"{n}_{seen[n]}")
    return out

def safe_str(x):
    if pd.isna(x):
        return ""
    return str(x).strip()

# ğŸ”§ FIX: åŒ»å¸«åã®æ­£è¦åŒ–é–¢æ•°ã‚’è¿½åŠ 
def normalize_name(name):
    """åŒ»å¸«åã‚’æ­£è¦åŒ–ï¼ˆå…¨è§’/åŠè§’ã‚¹ãƒšãƒ¼ã‚¹é™¤å»ï¼‰"""
    if pd.isna(name):
        return ""
    return str(name).strip().replace(" ", "").replace("ã€€", "")

def find_sheet_name(xls: pd.ExcelFile, target: str):
    """sheetåã®å¤§å°ãƒ»è¡¨è¨˜ã‚†ã‚Œã«è€ãˆã‚‹"""
    if target in xls.sheet_names:
        return target
    low_map = {s.lower(): s for s in xls.sheet_names}
    if target.lower() in low_map:
        return low_map[target.lower()]
    for s in xls.sheet_names:
        if s.strip().lower() == target.strip().lower():
            return s
    return None

def is_slot_value(v) -> bool:
    if isinstance(v, str):
        return v.strip() in SLOT_MARKERS
    if isinstance(v, (int, float, np.integer, np.floating)):
        return float(v) == 1.0
    return False

# =========================
# sheet4 èª­ã¿è¾¼ã¿ï¼ˆãƒ˜ãƒƒãƒ€è¡Œè‡ªå‹•æ¤œå‡ºï¼‹é‡è¤‡è€æ€§ï¼‰
# ğŸ”§ FIX: æ¤œç´¢ç¯„å›²ã‚’30â†’50è¡Œã«æ‹¡å¤§
# =========================
def parse_sheet4_from_grid(grid: pd.DataFrame) -> pd.DataFrame:
    g = grid.copy()
    g = g.dropna(how="all").reset_index(drop=True)

    if len(g) == 0:
        raise ValueError("sheet4 ãŒç©ºã§ã™")

    # ãƒ˜ãƒƒãƒ€è¡Œã‚’æ¢ã™ï¼ˆ'æ°å' ãŒã‚ã‚‹è¡Œï¼‰
    header_row_idx = None
    search_limit = min(50, len(g))  # ğŸ”§ FIX: 30â†’50ã«æ‹¡å¤§
    for i in range(search_limit):
        row = g.iloc[i].astype(str).str.strip()
        if (row == "æ°å").any():
            header_row_idx = i
            break
    if header_row_idx is None:
        raise ValueError(f"sheet4 ã®ãƒ˜ãƒƒãƒ€è¡Œã« 'æ°å' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆå…ˆé ­{search_limit}è¡Œã‚’æ¤œç´¢ï¼‰")

    headers = [safe_str(x) for x in g.iloc[header_row_idx].tolist()]
    headers = [h if (h != "" and h.lower() != "nan") else f"Unnamed_{j}" for j, h in enumerate(headers)]
    headers = make_unique(headers)

    data = g.iloc[header_row_idx + 1:].reset_index(drop=True)
    data.columns = headers

    if "æ°å" not in data.columns:
        raise ValueError("sheet4 ã®ãƒ˜ãƒƒãƒ€è¡Œã« 'æ°å' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆsheet4ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰")

    # æ°åã®ç©ºè¡Œå‰Šé™¤
    data["æ°å"] = data["æ°å"].astype(str).str.strip()
    data = data[(data["æ°å"].notna()) & (data["æ°å"] != "") & (data["æ°å"].str.lower() != "nan")].reset_index(drop=True)

    # æ•°å€¤åŒ–ï¼ˆæ°åä»¥å¤–ï¼‰
    for col in data.columns:
        if col == "æ°å":
            continue
        data[col] = pd.to_numeric(data[col], errors="coerce").fillna(0)

    return data

# =========================
# å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# =========================
print("\n" + "="*60)
print(f"  ğŸ“‚ å½“ç›´ãã‚“ v{VERSION}")
print("="*60)
print("\nsheet1ã€œsheet4ãŒå…¥ã£ãŸå½“ç›´Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")

if COLAB_AVAILABLE:
    uploaded = files.upload()
    uploaded_filename = list(uploaded.keys())[0]

    try:
        xls = pd.ExcelFile(io.BytesIO(uploaded[uploaded_filename]))
    except Exception as e:
        raise ValueError(f"âŒ Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    sheet1_name = find_sheet_name(xls, "sheet1")
    sheet2_name = find_sheet_name(xls, "sheet2")
    sheet3_name = find_sheet_name(xls, "sheet3")
    sheet4_name = find_sheet_name(xls, "sheet4") or find_sheet_name(xls, "Sheet4")

    missing = [k for k, v in [("sheet1", sheet1_name), ("sheet2", sheet2_name), ("sheet3", sheet3_name), ("sheet4", sheet4_name)] if v is None]
    if missing:
        raise ValueError(f"âŒ å¿…è¦ãªã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing}\nå®Ÿéš›ã®ã‚·ãƒ¼ãƒˆå: {xls.sheet_names}")

    # --------- Excel èª­ã¿è¾¼ã¿ ---------
    shift_df = strip_cols(pd.read_excel(xls, sheet_name=sheet1_name))
    availability_raw = strip_cols(pd.read_excel(xls, sheet_name=sheet2_name))
    schedule_raw = strip_cols(pd.read_excel(xls, sheet_name=sheet3_name))

    shift_df.columns = make_unique(list(shift_df.columns))
    availability_raw.columns = make_unique(list(availability_raw.columns))
    schedule_raw.columns = make_unique(list(schedule_raw.columns))

    # sheet4 ã¯ã€Œå‡ºåŠ›ç”¨ã€ã¨ã€Œè§£æç”¨ï¼ˆheader=Noneï¼‰ã€ã‚’åˆ†ã‘ã‚‹
    sheet4_raw_out = strip_cols(pd.read_excel(xls, sheet_name=sheet4_name))
    sheet4_raw_out.columns = make_unique(list(sheet4_raw_out.columns))

    sheet4_grid = pd.read_excel(xls, sheet_name=sheet4_name, header=None)
    sheet4_data = parse_sheet4_from_grid(sheet4_grid)
else:
    from tochoku_data_complete import DATA as LOCAL_DATA

    uploaded_filename = "Tochoku.local.xlsx"
    shift_df = strip_cols(pd.DataFrame(LOCAL_DATA["sheet1"]))
    availability_raw = strip_cols(pd.DataFrame(LOCAL_DATA["sheet2"]))
    schedule_raw = strip_cols(pd.DataFrame(LOCAL_DATA["sheet3"]))

    shift_df.columns = make_unique(list(shift_df.columns))
    availability_raw.columns = make_unique(list(availability_raw.columns))
    schedule_raw.columns = make_unique(list(schedule_raw.columns))

    sheet4_raw_out = strip_cols(pd.DataFrame(LOCAL_DATA["Sheet4"]))
    sheet4_raw_out.columns = make_unique(list(sheet4_raw_out.columns))

    sheet4_data = sheet4_raw_out.copy()
    if "æ°å" not in sheet4_data.columns:
        raise ValueError("âŒ Sheet4 ã® 'æ°å' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰")
    sheet4_data["æ°å"] = sheet4_data["æ°å"].astype(str).str.strip()
    for col in sheet4_data.columns:
        if col == "æ°å":
            continue
        sheet4_data[col] = pd.to_numeric(sheet4_data[col], errors="coerce").fillna(0)

# =========================
# æ—¥ä»˜åˆ—ã®æ•´å½¢
# ğŸ”§ FIX: ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å•é¡Œã®ä¿®æ­£
# =========================
date_col_shift = shift_df.columns[0]
shift_df[date_col_shift] = pd.to_datetime(shift_df[date_col_shift], errors="coerce").dt.normalize().dt.tz_localize(None)  # ğŸ”§ FIX
if shift_df[date_col_shift].isna().all():
    raise ValueError("âŒ sheet1 ã®å…ˆé ­åˆ—ãŒæ—¥ä»˜ã¨ã—ã¦è§£é‡ˆã§ãã¾ã›ã‚“ï¼ˆåˆ—ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰")

date_col_avail = availability_raw.columns[0]
availability_raw[date_col_avail] = pd.to_datetime(availability_raw[date_col_avail], errors="coerce").dt.normalize().dt.tz_localize(None)  # ğŸ”§ FIX
availability_df = availability_raw.set_index(date_col_avail)

date_col_sched = schedule_raw.columns[0]
schedule_raw[date_col_sched] = pd.to_datetime(schedule_raw[date_col_sched], errors="coerce").dt.normalize().dt.tz_localize(None)  # ğŸ”§ FIX
schedule_df = schedule_raw.set_index(date_col_sched)

# ğŸ”§ FIX: ç¥æ—¥ã‚‚ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æ­£è¦åŒ–
HOLIDAYS = {pd.to_datetime(d).normalize().tz_localize(None) for d in HOLIDAYS}

def is_holiday(date):
    return pd.to_datetime(date).normalize().tz_localize(None) in HOLIDAYS

# =========================
# åŸºæœ¬æƒ…å ±
# ğŸ”§ FIX: åŒ»å¸«åã‚’æ­£è¦åŒ–
# =========================
doctor_names = [normalize_name(x) for x in list(availability_raw.columns[1:])]  # ğŸ”§ FIX
doctor_col_index = {doc: idx for idx, doc in enumerate(doctor_names)}

# ğŸ”§ FIX: ç¦æ­¢åŒ»å¸«åã‚‚æ­£è¦åŒ–
WED_FORBIDDEN_DOCTORS = {normalize_name(d) for d in WED_FORBIDDEN_DOCTORS}  # ğŸ”§ FIX

hospital_cols = list(shift_df.columns[1:])
n_cols = len(shift_df.columns)

# åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ä¾å­˜ï¼šBã€œY ã‚’æƒ³å®šï¼‰
B_COL_INDEX = 1
C_COL_INDEX = 2
D_COL_INDEX = min(3, n_cols - 1)
E_COL_INDEX = min(4, n_cols - 1)
F_COL_INDEX = min(5, n_cols - 1)
G_COL_INDEX = min(6, n_cols - 1)
H_COL_INDEX = min(7, n_cols - 1)
I_COL_INDEX = min(8, n_cols - 1)
J_COL_INDEX = min(9, n_cols - 1)
K_COL_INDEX = min(10, n_cols - 1)
L_COL_INDEX = min(11, n_cols - 1)
M_COL_INDEX = min(12, n_cols - 1)
Q_COL_INDEX = min(16, n_cols - 1)
U_COL_INDEX = min(20, n_cols - 1)
Y_COL_INDEX = min(24, n_cols - 1)

# åˆ—ç¯„å›²å®šç¾©
B_H_START_INDEX = B_COL_INDEX  # å¤§å­¦ç³»å‰åŠï¼ˆ2å›ã¾ã§ï¼‰
B_H_END_INDEX = H_COL_INDEX
I_K_START_INDEX = I_COL_INDEX  # å¤§å­¦ç³»å¾ŒåŠ
I_K_END_INDEX = K_COL_INDEX
B_K_START_INDEX = B_COL_INDEX  # å¤§å­¦ç³»å…¨ä½“
B_K_END_INDEX = K_COL_INDEX
L_Y_START_INDEX = L_COL_INDEX  # å¤–ç—…é™¢
L_Y_END_INDEX = min(Y_COL_INDEX, n_cols - 1)

print(f"\nâœ… Excelèª­è¾¼å®Œäº†: åŒ»å¸«{len(doctor_names)}äºº | ç—…é™¢{len(hospital_cols)}åˆ— | {len(shift_df)}æ—¥é–“")

# =========================
# sheet2 å¯å¦ã‚³ãƒ¼ãƒ‰
# =========================
fallback_avail_codes = {}
for doc in doctor_names:
    col_vals = availability_raw[doc]
    first_val = None
    for v in col_vals:
        if pd.notna(v):
            first_val = v
            break
    if first_val is None:
        fallback_avail_codes[doc] = 1
    else:
        try:
            c = int(first_val)
        except Exception:
            c = 1
        if c not in (0, 1, 2, 3):
            c = 1
        fallback_avail_codes[doc] = c

def get_avail_code(date, doctor):
    code = None
    raw_value = None
    if isinstance(availability_df.index, pd.DatetimeIndex):
        try:
            value = availability_df.at[pd.to_datetime(date).normalize().tz_localize(None), doctor]  # ğŸ”§ FIX
            if isinstance(value, pd.Series):
                value = value.iloc[0]
            if pd.notna(value):
                raw_value = float(value)
                # 1.2ã¯ç‰¹åˆ¥æ‰±ã„ï¼šå¤§å­¦ç³»å„ªå…ˆ
                if abs(raw_value - 1.2) < 0.01:
                    code = 1.2
                else:
                    code = int(raw_value)
        except Exception:
            pass
    if code is None:
        code = fallback_avail_codes.get(doctor, 1)
    if code not in (0, 1, 1.2, 2, 3):
        code = 1
    return code

def get_sched_code(date, doctor):
    """ãã®æ—¥ã®æœ‰åŠ¹ãªã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—ï¼ˆ0ã¨3ã¯ç„¡åŠ¹ã¨ã—ã¦æ‰±ã†ï¼‰"""
    if doctor not in schedule_df.columns:
        return None
    try:
        value = schedule_df.at[pd.to_datetime(date).normalize().tz_localize(None), doctor]  # ğŸ”§ FIX
        if isinstance(value, pd.Series):
            value = value.iloc[0]
    except Exception:
        return None
    if pd.isna(value):
        return None
    code_str = str(value).strip()
    # 0ã¨3ã¯æœ‰åŠ¹ãªã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ã§ã¯ãªã„ï¼ˆ0=ãƒ‡ãƒ¼ã‚¿ãªã—ã€3=å¯å¦ã‚³ãƒ¼ãƒ‰ï¼‰
    if not code_str or code_str == "0" or code_str == "3":
        return None
    return code_str

# sheet2 ã¨ sheet3 ã®åŒ»å¸«åˆ—ãŒã‚ºãƒ¬ã¦ã„ãªã„ã‹ï¼ˆã‚ºãƒ¬ã¦ã¦ã‚‚å‹•ããŒã€åˆ¶ç´„ãŒå¼±ããªã‚‹ï¼‰
sched_doctors = [normalize_name(x) for x in list(schedule_raw.columns[1:])]  # ğŸ”§ FIX
if doctor_names != sched_doctors:
    print("âš ï¸ WARNING: sheet2(å¯å¦) ã¨ sheet3(ã‚«ãƒ†è¡¨) ã®åŒ»å¸«åˆ—ãŒä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ã€‚")
    only2 = [d for d in doctor_names if d not in sched_doctors]
    only3 = [d for d in sched_doctors if d not in doctor_names]
    if only2:
        print(f"   sheet2 only (å…ˆé ­10): {only2[:10]}")
    if only3:
        print(f"   sheet3 only (å…ˆé ­10): {only3[:10]}")
    print("   â€»Hã€œU ã®ã€ã‚«ãƒ†è¡¨ã‚ã‚Šä¸å¯ã€åˆ¶ç´„ãŒä¸€éƒ¨ã®åŒ»å¸«ã§åŠ¹ã‹ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

# =========================
# sheet4 å‰æœˆã¾ã§ç´¯ç©
# =========================
name_to_row = {row["æ°å"]: row for _, row in sheet4_data.iterrows()}
prev_names = list(sheet4_data["æ°å"])

def match_prev_name(doc):
    if doc in name_to_row:
        return doc
    ms = [p for p in prev_names if str(p).startswith(doc) or doc.startswith(str(p))]
    return ms[0] if len(ms) == 1 else None

name_match = {doc: match_prev_name(doc) for doc in doctor_names}
unmatched = [d for d in doctor_names if name_match.get(d) is None]
if unmatched:
    print(f"âš ï¸ WARNING: sheet4(ç´¯ç©)ã§åå‰ãŒä¸€è‡´ã—ãªã„åŒ»å¸«ãŒã„ã¾ã™ï¼ˆç´¯ç©ãŒ0æ‰±ã„ã«ãªã‚Šã¾ã™ï¼‰: {unmatched}")

def prev_get(doc, colname):
    pname = name_match.get(doc)
    if pname and pname in name_to_row:
        row = name_to_row[pname]
        v = row.get(colname, 0)
        try:
            return float(v or 0)
        except Exception:
            return 0.0
    return 0.0

prev_total   = {d: prev_get(d, "å…¨åˆè¨ˆ")   for d in doctor_names}
prev_bg      = {d: prev_get(d, "å¤§å­¦åˆè¨ˆ") for d in doctor_names}
prev_ht      = {d: prev_get(d, "å¤–ç—…é™¢åˆè¨ˆ") for d in doctor_names}
prev_weekday = {d: prev_get(d, "å¹³æ—¥")     for d in doctor_names}
prev_weekend = {d: prev_get(d, "ä¼‘æ—¥åˆè¨ˆ") for d in doctor_names}

# =========================
# å…¨æ æ•°ã‚«ã‚¦ãƒ³ãƒˆ + slots_by_date å‰è¨ˆç®—
# =========================
slots_by_date = defaultdict(lambda: {"preassigned": [], "free": []})
preassigned_count = {d: 0 for d in doctor_names}
total_slots = 0

for ridx in shift_df.index:
    date = shift_df.at[ridx, date_col_shift]
    if pd.isna(date):
        continue
    date = pd.to_datetime(date).normalize().tz_localize(None)  # ğŸ”§ FIX

    for hosp in hospital_cols:
        val = shift_df.at[ridx, hosp]

        # å›ºå®šå‰²å½“ï¼ˆã‚»ãƒ«ã«åŒ»å¸«åãŒå…¥ã£ã¦ã„ã‚‹ï¼‰
        val_str = normalize_name(val) if isinstance(val, str) else ""  # ğŸ”§ FIX
        if val_str in doctor_names:
            doc = val_str
            slots_by_date[date]["preassigned"].append((ridx, hosp, doc))
            preassigned_count[doc] += 1
            total_slots += 1
            continue

        # è‡ªå‹•æ ï¼ˆ1/ã€‡ãªã©ï¼‰
        if is_slot_value(val):
            slots_by_date[date]["free"].append((ridx, hosp))
            total_slots += 1

if len(doctor_names) == 0:
    raise ValueError("âŒ sheet2 ã«åŒ»å¸«åãŒã‚ã‚Šã¾ã›ã‚“")

all_dates = sorted(slots_by_date.keys())
all_shift_dates = sorted(pd.to_datetime(shift_df[date_col_shift].dropna()).dt.normalize().dt.tz_localize(None).unique())  # ğŸ”§ FIX

# =========================
# capè¨­è¨ˆï¼šnå›ãƒ™ãƒ¼ã‚¹ï¼‹ä½™ã‚Šã¯å³å´ï¼ˆä¸‹å´ï¼‰ã‹ã‚‰n+1å›
# inactiveåŒ»å¸«ã®æ‰±ã„ï¼ˆv5.2ä»•æ§˜æ›¸Â§5æº–æ‹ ï¼‰:
#   - è§£æå‡¦ç†ã‹ã‚‰å®Œå…¨é™¤å¤–ï¼ˆå€™è£œã«å«ã‚ãªã„ï¼‰
#   - TARGET_CAPè¨ˆç®—ã‹ã‚‰é™¤å¤–ï¼ˆactiveåŒ»å¸«ã®ã¿ã§è¨ˆç®—ï¼‰
#   - å‡ºåŠ›Excelã«ã¯0å›ã¨ã—ã¦è¨˜è¼‰ï¼ˆæ°åã¯è¡¨ç¤ºï¼‰
# =========================
def is_always_unavailable(doc):
    """inactiveåŒ»å¸«ã®åˆ¤å®š: sheet2ã§å…¨æ—¥=0ã‹ã¤äº‹å‰å‰²å½“ãªã—"""
    if preassigned_count.get(doc, 0) > 0:
        return False
    return all(get_avail_code(d, doc) == 0 for d in all_shift_dates)

inactive_doctors = [d for d in doctor_names if is_always_unavailable(d)]
active_doctors = [d for d in doctor_names if d not in inactive_doctors]
if len(active_doctors) == 0:
    raise ValueError("âŒ å½“æœˆã«å‰²ã‚Šå½“ã¦å¯èƒ½ãªåŒ»å¸«ãŒã„ã¾ã›ã‚“")
if inactive_doctors:
    print(f"âš ï¸ inactiveåŒ»å¸«ï¼ˆè§£æé™¤å¤–ã€å‡ºåŠ›ã®ã¿ï¼‰: {len(inactive_doctors)}äºº")

# å¯å¦ã‚³ãƒ¼ãƒ‰2ã®åŒ»å¸«ï¼ˆå¤§å­¦ç³»ã®ã¿å¯èƒ½ã€EXTRAæ å¯¾è±¡å¤–ï¼‰
def has_code_2_anywhere(doc):
    """åŒ»å¸«ãŒsheet2ã§ã„ãšã‚Œã‹ã®æ—¥ã«å¯å¦ã‚³ãƒ¼ãƒ‰2ã‚’æŒã£ã¦ã„ã‚‹ã‹"""
    if doc not in availability_df.columns:
        return False
    for date in all_shift_dates:
        code = get_avail_code(date, doc)
        if code == 2:
            return True
    return False

CODE_2_DOCTORS = {doc for doc in doctor_names if has_code_2_anywhere(doc)}

BASE_TARGET = total_slots // len(active_doctors)
EXTRA_SLOTS = total_slots - BASE_TARGET * len(active_doctors)

# ä½™ã‚Šæ ã¯å³å´ï¼ˆä¸‹ä½ï¼‰ã®åŒ»å¸«ã«å‰²ã‚Šå½“ã¦ã‚‹ï¼ˆå¯å¦ã‚³ãƒ¼ãƒ‰2ã®åŒ»å¸«ã¯é™¤å¤–ï¼šãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼‰
# ä¾‹ï¼šå°æ—(0), åŠå·(1), ..., å¤§æ²³å†…(30), çŒªè‚¡(31) ã®å ´åˆã€å³å´ã®åŒ»å¸«ã‚’é¸æŠ
active_sorted_by_index = sorted(active_doctors, key=lambda d: doctor_col_index[d])  # æ˜‡é †ã‚½ãƒ¼ãƒˆ
# å¯å¦ã‚³ãƒ¼ãƒ‰2ã®åŒ»å¸«ã¯EXTRAæ å¯¾è±¡ã‹ã‚‰é™¤å¤–ï¼ˆå¤§å­¦ç³»ã®ã¿å¯ã®ãŸã‚ã€å¤–ç—…é™¢æ å¢—åŠ ã¯ä¸é©åˆ‡ï¼‰
extra_eligible = [d for d in active_sorted_by_index if d not in CODE_2_DOCTORS]
EXTRA_ALLOWED = set(extra_eligible[-EXTRA_SLOTS:] if EXTRA_SLOTS > 0 else [])  # æœ€å¾Œã®EXTRA_SLOTSäººï¼ˆå³å´/ä¸‹ä½ï¼‰

TARGET_CAP = {d: 0 for d in doctor_names}
for d in active_doctors:
    TARGET_CAP[d] = BASE_TARGET
for d in EXTRA_ALLOWED:
    TARGET_CAP[d] = BASE_TARGET + 1
for d in doctor_names:
    if preassigned_count.get(d, 0) > TARGET_CAP.get(d, 0):
        TARGET_CAP[d] = preassigned_count[d]

floor_shifts = BASE_TARGET

print(f"\nâœ… å‰²å½“è¨­è¨ˆå®Œäº†")
print(f"   â”œâ”€ å…¨æ æ•°: {total_slots} | activeåŒ»å¸«: {len(active_doctors)}äºº")
print(f"   â”œâ”€ åŸºæœ¬å‰²å½“: {BASE_TARGET}å› (+1å›å¯¾è±¡: {len(EXTRA_ALLOWED)}äºº)")

# å¯å¦ã‚³ãƒ¼ãƒ‰2ã®åŒ»å¸«ãŒEXTRAæ ã‹ã‚‰é™¤å¤–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’è¡¨ç¤º
code_2_in_active = [d for d in active_sorted_by_index if d in CODE_2_DOCTORS]
if code_2_in_active:
    print(f"   â””â”€ CODE_2åŒ»å¸«ï¼ˆEXTRAå¯¾è±¡å¤–ï¼‰: {len(code_2_in_active)}äºº")

# =========================
# B-K / L-Y æ¯”ç‡ãƒãƒ©ãƒ³ã‚¹ï¼ˆsheet3ã§ã€Œ3ã€è¨˜è¼‰ã®åŒ»å¸«ã¯é™¤å¤–ï¼‰
# sheet3ã§ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ä¿æœ‰åŒ»å¸«ã®ç‰¹å®š
# =========================
def has_sheet3_code_3(doc):
    if doc not in schedule_df.columns:
        return False
    values = schedule_df[doc].dropna()
    return any(str(v).strip() == "3" for v in values)

def has_any_schedule_code(doc):
    """åŒ»å¸«ãŒsheet3ã§å°‘ãªãã¨ã‚‚1ã¤ã®ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ï¼ˆA,B,C,CC,D,Eç­‰ã€3ä»¥å¤–ï¼‰ã‚’æŒã£ã¦ã„ã‚‹ã‹"""
    if doc not in schedule_df.columns:
        return False
    values = schedule_df[doc].dropna()
    for v in values:
        s = str(v).strip()
        if s and s != "0" and s != "3":  # 0ã¨3ä»¥å¤–ã®ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Œã°True
            return True
    return False

RATIO_EXEMPT_DOCTORS = {doc for doc in doctor_names if has_sheet3_code_3(doc)}
if RATIO_EXEMPT_DOCTORS:
    print(f"   æ¯”ç‡ãƒãƒ©ãƒ³ã‚¹é™¤å¤–ï¼ˆsheet3ã«3ã‚ã‚Šï¼‰: {sorted(RATIO_EXEMPT_DOCTORS)}")

SCHEDULE_CODE_HOLDERS = {doc for doc in doctor_names if has_any_schedule_code(doc)}
print(f"   â””â”€ ã‚«ãƒ†è¡¨ä¿æœ‰: {len(SCHEDULE_CODE_HOLDERS)}äºº")

# ã‚«ãƒ†å½“ç•ªãªã—åŒ»å¸«ï¼ˆsheet3ã«1ã¤ã‚‚ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆãŒãªã„åŒ»å¸«ï¼‰
# C-Håˆ—ï¼ˆä¼‘æ—¥å¤§å­¦ç³»ï¼‰ã«è‡ªç”±ã«å‰²ã‚Šå½“ã¦å¯èƒ½
NO_KATE_DOCTORS = {doc for doc in doctor_names if not has_any_schedule_code(doc)}
print(f"   â””â”€ ã‚«ãƒ†å½“ç•ªãªã—: {len(NO_KATE_DOCTORS)}äºº")

# sheet3ã§ã€Œ1ã€ã‚’æŒã¤åŒ»å¸«ï¼ˆå¹³æ—¥å¤§å­¦ç³»ã§ã‚«ãƒ†å½“ç•ªä¸ä¸€è‡´ã‚’è¨±å®¹ï¼‰
def has_sheet3_code_1(doc):
    """åŒ»å¸«ãŒsheet3ã§å°‘ãªãã¨ã‚‚1ã¤ã®ã€Œ1ã€ã‚³ãƒ¼ãƒ‰ã‚’æŒã£ã¦ã„ã‚‹ã‹"""
    if doc not in schedule_df.columns:
        return False
    values = schedule_df[doc].dropna()
    return any(str(v).strip() == "1" for v in values)

SHEET3_CODE_1_DOCTORS = {doc for doc in doctor_names if has_sheet3_code_1(doc)}
if SHEET3_CODE_1_DOCTORS:
    print(f"   â””â”€ sheet3ã«1ã‚ã‚Šï¼ˆå¹³æ—¥ç·©å’Œï¼‰: {len(SHEET3_CODE_1_DOCTORS)}äºº")

def is_ch_slot(col_idx):
    """C-Håˆ—ï¼ˆä¼‘æ—¥å¤§å­¦ç³»ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹2-7ï¼‰ã‹ã©ã†ã‹"""
    return C_COL_INDEX <= col_idx <= H_COL_INDEX

def is_weekday_university_slot(col_idx):
    """Båˆ—ã¾ãŸã¯I-Kåˆ—ï¼ˆå¹³æ—¥å¤§å­¦ç³»ï¼‰ã‹ã©ã†ã‹"""
    return col_idx == B_COL_INDEX or (I_COL_INDEX <= col_idx <= K_COL_INDEX)

def is_eligible_for_ch_slot(doc, date):
    """C-Håˆ—ï¼ˆä¼‘æ—¥å¤§å­¦ç³»ï¼‰ã«å‰²ã‚Šå½“ã¦å¯èƒ½ã‹ã©ã†ã‹
    æ¡ä»¶ï¼šãã®æ—¥ã«ã‚«ãƒ†å½“ç•ªã‚ã‚Š OR ã‚«ãƒ†å½“ç•ªãŒä¸€å›ã‚‚ãªã„åŒ»å¸«
    """
    # ã‚«ãƒ†å½“ç•ªãŒä¸€å›ã‚‚ãªã„åŒ»å¸«ã¯OK
    if doc in NO_KATE_DOCTORS:
        return True
    # ã‚«ãƒ†å½“ç•ªä¿æœ‰åŒ»å¸«ã¯ã€ãã®æ—¥ã«ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Œã°OK
    if get_sched_code(date, doc):
        return True
    return False

def is_eligible_for_weekday_university_slot(doc, date):
    """Båˆ—/I-Kåˆ—ï¼ˆå¹³æ—¥å¤§å­¦ç³»ï¼‰ã«å‰²ã‚Šå½“ã¦å¯èƒ½ã‹ã©ã†ã‹
    æ¡ä»¶ï¼šã‚«ãƒ†å½“ç•ªãªã—åŒ»å¸« OR ãã®æ—¥ã«ã‚«ãƒ†å½“ç•ªã‚ã‚Š OR sheet3ã§ã€Œ1ã€ã‚’æŒã¤åŒ»å¸«
    ã€Œ1ã€ã‚’æŒã¤åŒ»å¸«ã¯ã‚«ãƒ†å½“ç•ªãŒåˆã‚ãªãã¦ã‚‚è¨±å®¹
    """
    # ã‚«ãƒ†å½“ç•ªãŒä¸€å›ã‚‚ãªã„åŒ»å¸«ã¯OK
    if doc in NO_KATE_DOCTORS:
        return True
    # ãã®æ—¥ã«ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Œã°OK
    sched_code = get_sched_code(date, doc)
    if sched_code:
        return True
    # sheet3ã§ã€Œ1ã€ã‚’æŒã¤åŒ»å¸«ã¯ã‚«ãƒ†å½“ç•ªãªã—ã§ã‚‚è¨±å®¹ï¼ˆå¹³æ—¥å¤§å­¦ç³»ã®ã¿ï¼‰
    if doc in SHEET3_CODE_1_DOCTORS:
        return True
    return False

def is_cc_assignment(date, doc):
    """ãã®æ—¥ã®ãã®åŒ»å¸«ã®å‰²ã‚Šå½“ã¦ãŒCCï¼ˆå¤§å‹é€£ä¼‘ç‰¹åˆ¥ã‚·ãƒ•ãƒˆï¼‰ã‹ã©ã†ã‹"""
    sched_code = get_sched_code(date, doc)
    return sched_code == "CC" if sched_code else False

def has_any_cc_assignment(doc, pattern_df):
    """åŒ»å¸«ãŒCCå‰²ã‚Šå½“ã¦ã‚’æŒã£ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’pattern_dfã‹ã‚‰åˆ¤å®š"""
    for ridx in pattern_df.index:
        date = pattern_df.at[ridx, date_col_shift]
        if pd.isna(date):
            continue
        date = pd.to_datetime(date).normalize().tz_localize(None)
        for hosp in hospital_cols:
            val = pattern_df.at[ridx, hosp]
            if isinstance(val, str) and normalize_name(val) == doc:
                if is_cc_assignment(date, doc):
                    return True
    return False

# å¯å¦ã‚³ãƒ¼ãƒ‰1.2ã®åŒ»å¸«ï¼ˆå¤§å­¦ç³»æœ€ä½1å›å¿…é ˆï¼‰
def has_code_1_2(doc):
    """åŒ»å¸«ãŒsheet2ã§å°‘ãªãã¨ã‚‚1ã¤ã®1.2ã‚³ãƒ¼ãƒ‰ã‚’æŒã£ã¦ã„ã‚‹ã‹"""
    if doc not in availability_df.columns:
        return False
    for date in all_shift_dates:
        code = get_avail_code(date, doc)
        if code == 1.2:
            return True
    return False

CODE_1_2_DOCTORS = {doc for doc in doctor_names if has_code_1_2(doc)}

# å¤§å­¦ç³»æœ€ä½1å›å¿…é ˆã®åŒ»å¸«ï¼ˆæº–ãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼šã‚³ãƒ¼ãƒ‰3ä»¥å¤–ã®å…¨åŒ»å¸«ï¼‰
# ã‚³ãƒ¼ãƒ‰3ã¯å¤–ç—…é™¢å°‚é–€ãªã®ã§é™¤å¤–
UNIVERSITY_MINIMUM_REQUIRED_DOCTORS = {doc for doc in active_doctors if doc not in RATIO_EXEMPT_DOCTORS}

# =========================
# å¤§å­¦(Bã€œG)ã®æ˜¼å¤œåˆ¤å®š & 7åˆ†é¡
# =========================
def is_bg_day_shift(hosp_name, col_idx):
    if hosp_name in BG_DAY_COLS:
        return True
    if hosp_name in BG_NIGHT_COLS:
        return False
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šB,C,E,F=æ˜¼ / D,G=å¤œ
    if col_idx in (B_COL_INDEX, C_COL_INDEX, E_COL_INDEX, F_COL_INDEX):
        return True
    if col_idx in (D_COL_INDEX, G_COL_INDEX):
        return False
    mid = (B_COL_INDEX + G_COL_INDEX) // 2
    return col_idx <= mid

def is_bk_slot(col_idx):
    return B_K_START_INDEX <= col_idx <= B_K_END_INDEX

def is_ly_slot(col_idx):
    return L_Y_START_INDEX <= col_idx <= L_Y_END_INDEX

def classify_bg_category(date, hosp_name):
    idx = shift_df.columns.get_loc(hosp_name)
    is_day = is_bg_day_shift(hosp_name, idx)
    dow = pd.to_datetime(date).weekday()
    holi = is_holiday(date)

    weekday = dow < 5
    # å¹³æ—¥ã‹ã¤ C,D,F,G ã¯ç¥æ—¥æ‰±ã„
    if weekday and idx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX):
        holi = True

    if holi and weekday:
        base = "ç¥æ—¥"
    elif dow == 5:
        base = "åœŸæ›œ"
    elif dow == 6:
        base = "æ—¥æ›œ"
    else:
        return "å¹³æ—¥"

    return base + ("æ˜¼" if is_day else "å¤œ")

# =========================
# 1æ ã®åŒ»å¸«é¸æŠï¼ˆgreedyï¼‰
# =========================
def choose_doctor_for_slot(
    date,
    hospital_name,
    assigned_count,
    assigned_dates,
    assigned_bg,
    assigned_ht,
    assigned_weekday,
    assigned_weekend,
    assigned_be,
    assigned_fg,
    assigned_bk,
    assigned_ly,
    assigned_bh,
    assigned_bi,      # v6.0.0: B/Iåˆ—ã®åˆè¨ˆï¼ˆHARD-001ï¼‰
    assigned_chjk,    # v6.0.0: C-H/J-Kåˆ—ã®åˆè¨ˆï¼ˆHARD-002ï¼‰
    assigned_hosp_count,
):
    idx = shift_df.columns.get_loc(hospital_name)
    is_BE = B_COL_INDEX <= idx <= E_COL_INDEX
    is_BG = B_COL_INDEX <= idx <= K_COL_INDEX
    is_BH = B_H_START_INDEX <= idx <= B_H_END_INDEX
    is_LY_range = L_COL_INDEX <= idx <= L_Y_END_INDEX
    is_BK = is_bk_slot(idx)
    is_LY = is_ly_slot(idx)
    # v6.0.0: æ–°ã—ã„åˆ—ã‚°ãƒ«ãƒ¼ãƒ—
    is_B_or_I = (idx == B_COL_INDEX or idx == I_COL_INDEX)  # ã‚°ãƒ«ãƒ¼ãƒ—A
    is_CH_or_JK = ((C_COL_INDEX <= idx <= H_COL_INDEX) or (J_COL_INDEX <= idx <= K_COL_INDEX))  # ã‚°ãƒ«ãƒ¼ãƒ—B
    is_B_only = (idx == B_COL_INDEX)  # SEMI-001å¯¾è±¡
    is_CH_only = (C_COL_INDEX <= idx <= H_COL_INDEX)  # SEMI-002å¯¾è±¡
    dow = pd.to_datetime(date).weekday()
    weekday = dow < 5

    def collect_candidates(
        relax_semi=False,  # v6.0.0: SEMIåˆ¶ç´„ã‚’ç·©å’Œï¼ˆsheet3ã€Œ1ã€ä»¥å¤–ã‚‚è¨±å®¹ï¼‰
    ):
        candidates = []
        for doc in doctor_names:
            # === çµ¶å¯¾ç¦å¿Œï¼ˆABSï¼‰: ç·©å’Œä¸å¯ ===

            # ABS-006: åŒæ—¥é‡è¤‡ç¦æ­¢
            if date in assigned_dates[doc]:
                continue

            code = get_avail_code(date, doc)

            # ABS-001: ã‚³ãƒ¼ãƒ‰0ã¯å…¨åˆ—ç¦æ­¢
            if code == 0:
                continue

            # ABS-002: ã‚³ãƒ¼ãƒ‰2ã¯Bã€œQåˆ—ã®ã¿ï¼ˆR-Yåˆ—ç¦æ­¢ï¼‰
            if code == 2 and not (B_COL_INDEX <= idx <= Q_COL_INDEX):
                continue

            # ABS-003: ã‚³ãƒ¼ãƒ‰3ã¯Lã€œYåˆ—ã®ã¿ï¼ˆå¤§å­¦ç³»ç¦æ­¢ï¼‰
            if code == 3 and not (L_COL_INDEX <= idx <= L_Y_END_INDEX):
                continue

            # ABS-004: ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ã‚ã‚Šã®æ—¥ã¯Lã€œYåˆ—ä¸å¯
            if L_COL_INDEX <= idx <= L_Y_END_INDEX:
                if get_sched_code(date, doc):
                    continue

            # ABS-005: æ°´æ›œæ—¥Lã€œYåˆ—ç¦æ­¢åŒ»å¸«
            if dow == 2 and is_LY_range:
                if doc in WED_FORBIDDEN_DOCTORS:
                    continue

            # ABS-007: gap >= 3æ—¥å¿…é ˆ
            if assigned_dates[doc]:
                min_gap = min(abs((pd.to_datetime(date) - x).days) for x in assigned_dates[doc])
                if min_gap < 3:
                    continue

            # ABS-008: åŒä¸€ç—…é™¢é‡è¤‡ç¦æ­¢ï¼ˆå…¨åˆ—ï¼‰
            if assigned_hosp_count[doc].get(hospital_name, 0) >= 1:
                continue

            # ABS-010: TARGET_CAPéµå®ˆï¼ˆnè¶…éç¦æ­¢ï¼‰
            if assigned_count[doc] >= TARGET_CAP.get(doc, 0):
                continue

            # ABS-011: å¤§å­¦ç³»2å›ã¾ã§ï¼ˆB-Kåˆ—åˆè¨ˆï¼‰
            if is_BG and assigned_bg[doc] >= 2:
                continue

            # === ãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼ˆHARDï¼‰: ã‚«ãƒ†ãªã—åŒ»å¸«ã¯å¿…é ˆéµå®ˆ ===

            # ã‚«ãƒ†å½“ç•ªã®æœ‰ç„¡ã‚’åˆ¤å®š
            is_kate_holder = doc in SCHEDULE_CODE_HOLDERS
            is_sheet3_one = doc in SHEET3_CODE_1_DOCTORS

            # HARD-001: B/Iåˆ—1å›ã¾ã§ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—Aï¼‰
            if is_B_or_I and assigned_bi[doc] >= 1:
                # ã‚«ãƒ†ãªã—åŒ»å¸«ã¯å¿…é ˆéµå®ˆ
                if not is_kate_holder:
                    continue
                # ã‚«ãƒ†ã‚ã‚ŠåŒ»å¸«ã§ã‚‚sheet3ã€Œ1ã€ä»¥å¤–ã¯éµå®ˆ
                if is_kate_holder and not is_sheet3_one:
                    continue

            # HARD-002: C-H/J-Kåˆ—1å›ã¾ã§ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—Bï¼‰
            if is_CH_or_JK and assigned_chjk[doc] >= 1:
                # ã‚«ãƒ†ãªã—åŒ»å¸«ã¯å¿…é ˆéµå®ˆ
                if not is_kate_holder:
                    continue
                # ã‚«ãƒ†ã‚ã‚ŠåŒ»å¸«ã§ã‚‚sheet3ã€Œ1ã€ä»¥å¤–ã¯éµå®ˆ
                if is_kate_holder and not is_sheet3_one:
                    continue

            # === æº–ãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼ˆSEMIï¼‰: sheet3ã€Œ1ã€ã¯ç·©å’Œå¯¾è±¡ ===

            # SEMI-001: Båˆ—ã®ã¿ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰å¿…é ˆ
            if not relax_semi and is_B_only:
                if is_kate_holder and not get_sched_code(date, doc):
                    if not is_sheet3_one:
                        continue

            # SEMI-002: C-Håˆ—ã®ã¿ã‚«ãƒ†å½“ç•ªæ—¥å¿…é ˆï¼ˆI-Kåˆ—ã¯å¯¾è±¡å¤–ï¼‰
            if not relax_semi and is_CH_only:
                if not is_eligible_for_ch_slot(doc, date):
                    if not is_sheet3_one:
                        continue

            candidates.append(doc)
        return candidates

    candidates = collect_candidates()
    if not candidates:
        candidates = collect_candidates(relax_semi=True)

    if not candidates:
        return None

    any_under_floor = any(assigned_count[d] < floor_shifts for d in active_doctors)
    if any_under_floor:
        under_floor = [d for d in candidates if assigned_count[d] < floor_shifts]
        if under_floor:
            candidates = under_floor

    # â˜… C-Håˆ—ï¼ˆåœŸæ—¥å¤§å­¦ï¼‰ã¯ã‚«ãƒ†å½“ç•ªåŒ»å¸«ã‚’æœ€å„ªå…ˆï¼ˆã‚«ãƒ†ãªã—åŒ»å¸«ã¯æœ€å¾Œã®æ‰‹æ®µï¼‰
    # ã‚«ãƒ†å½“ç•ªåŒ»å¸«ãŒã„ã‚‹å ´åˆã€ã‚«ãƒ†ãªã—åŒ»å¸«ã‚ˆã‚Šå„ªå…ˆã—ã¦é…ç½®
    if is_ch_slot(idx) and candidates:
        kate_docs_on_day = [d for d in candidates if get_sched_code(date, d)]
        if kate_docs_on_day:
            candidates = kate_docs_on_day

    # gap
    gaps = {}
    for d in candidates:
        if not assigned_dates[d]:
            gaps[d] = 999
        else:
            gaps[d] = min(abs((pd.to_datetime(date) - x).days) for x in assigned_dates[d])

    # å„ªå…ˆé †ä½: 7,4,5,æ¯”ç‡(B-K/L-Y),2,3,6,8,1(>=4),10

    # 7 å…¨ä½“ï¼ˆå‰æœˆ+ä»Šæœˆï¼‰
    metric_total = {d: prev_total[d] + assigned_count[d] for d in candidates}
    min_total = min(metric_total.values())
    candidates = [d for d in candidates if metric_total[d] == min_total]

    # 4 å¤§å­¦/å¤–ç—…é™¢åã‚Šï¼ˆå‰æœˆ+ä»Šæœˆï¼‰
    if is_BG:
        metric_bg = {d: prev_bg[d] + assigned_bg[d] for d in candidates}
        mb = min(metric_bg.values())
        candidates = [d for d in candidates if metric_bg[d] == mb]
    elif is_LY_range:
        metric_ht = {d: prev_ht[d] + assigned_ht[d] for d in candidates}
        mh = min(metric_ht.values())
        candidates = [d for d in candidates if metric_ht[d] == mh]

    # 5 Bã€œE / Fã€œG
    if is_BG:
        if is_BE:
            mbe = min(assigned_be[d] for d in candidates)
            candidates = [d for d in candidates if assigned_be[d] == mbe]
        else:
            mfg = min(assigned_fg[d] for d in candidates)
            candidates = [d for d in candidates if assigned_fg[d] == mfg]

    # B-K / L-Y ã®æ¯”ç‡ãƒãƒ©ãƒ³ã‚¹ï¼ˆé™¤å¤–åŒ»å¸«ä»¥å¤–ï¼‰
    if (is_BK or is_LY) and candidates:
        def imbalance_score(doc):
            if doc in RATIO_EXEMPT_DOCTORS:
                return 0
            bk = assigned_bk[doc] + (1 if is_BK else 0)
            ly = assigned_ly[doc] + (1 if is_LY else 0)
            return abs(bk - ly)

        min_imbalance = min(imbalance_score(d) for d in candidates)
        candidates = [d for d in candidates if imbalance_score(d) == min_imbalance]

    # (å‰Šé™¤: åŒä¸€ç—…é™¢é‡è¤‡ã¯çµ¶å¯¾ç¦å¿Œã¨ã—ã¦ collect_candidates ã§ãƒã‚§ãƒƒã‚¯æ¸ˆã¿)

    # 3 Bã€œG ã¯ã‚«ãƒ†è¡¨ã‚ã‚Šå„ªå…ˆï¼ˆã‚½ãƒ•ãƒˆå„ªå…ˆï¼‰
    if is_BG:
        with_sched = [d for d in candidates if get_sched_code(date, d)]
        if with_sched:
            candidates = with_sched

    # 6 å¹³æ—¥/ä¼‘æ—¥åã‚Šï¼ˆå‰æœˆ+ä»Šæœˆï¼‰
    holi_flag = (
        is_holiday(date)
        or dow >= 5
        or (weekday and idx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX))
    )
    if holi_flag:
        metric_we = {d: prev_weekend[d] + assigned_weekend[d] for d in candidates}
        mwe = min(metric_we.values())
        candidates = [d for d in candidates if metric_we[d] == mwe]
    else:
        metric_wd = {d: prev_weekday[d] + assigned_weekday[d] for d in candidates}
        mwd = min(metric_wd.values())
        candidates = [d for d in candidates if metric_wd[d] == mwd]

    # 8 flooræœªæº€å„ªå…ˆ
    under_floor = [d for d in candidates if assigned_count[d] < floor_shifts]
    if under_floor:
        candidates = under_floor

    # (å‰Šé™¤: gap >= 3 ã¯çµ¶å¯¾ç¦å¿Œã¨ã—ã¦ collect_candidates ã§ãƒã‚§ãƒƒã‚¯æ¸ˆã¿)

    # 10 åŒç‚¹ãªã‚‰å³å´
    return max(candidates, key=lambda d: doctor_col_index[d])

# =========================
# 1ãƒ¶æœˆåˆ†ç”Ÿæˆï¼ˆgreedyï¼‰
# =========================
def build_schedule_pattern(seed=0):
    random.seed(seed)

    df = shift_df.copy()
    for col in hospital_cols:
        df[col] = df[col].astype(object)

    assigned_count = {d: 0 for d in doctor_names}
    assigned_dates = {d: set() for d in doctor_names}

    assigned_bg = {d: 0 for d in doctor_names}
    assigned_ht = {d: 0 for d in doctor_names}
    assigned_weekday = {d: 0 for d in doctor_names}
    assigned_weekend = {d: 0 for d in doctor_names}
    assigned_be = {d: 0 for d in doctor_names}
    assigned_fg = {d: 0 for d in doctor_names}
    assigned_bk = {d: 0 for d in doctor_names}
    assigned_ly = {d: 0 for d in doctor_names}
    assigned_bh = {d: 0 for d in doctor_names}  # Bã€œHåˆ—ã®å‰²å½“å›æ•°ï¼ˆæ—§: 2å›ã¾ã§ï¼‰
    assigned_bi = {d: 0 for d in doctor_names}  # v6.0.0: B/Iåˆ—ã®åˆè¨ˆï¼ˆHARD-001: 1å›ã¾ã§ï¼‰
    assigned_chjk = {d: 0 for d in doctor_names}  # v6.0.0: C-H/J-Kåˆ—ã®åˆè¨ˆï¼ˆHARD-002: 1å›ã¾ã§ï¼‰
    assigned_hosp_count = {d: defaultdict(int) for d in doctor_names}
    bg_cat = {d: defaultdict(int) for d in doctor_names}

    # å›ºå®šå½“ç›´
    for date in all_dates:
        for ridx, hosp, doc in slots_by_date[date]["preassigned"]:
            df.at[ridx, hosp] = doc
            assigned_count[doc] += 1
            assigned_dates[doc].add(date)
            assigned_hosp_count[doc][hosp] += 1

            hidx = shift_df.columns.get_loc(hosp)
            if B_COL_INDEX <= hidx <= K_COL_INDEX:
                assigned_bg[doc] += 1
                if B_COL_INDEX <= hidx <= E_COL_INDEX:
                    assigned_be[doc] += 1
                elif F_COL_INDEX <= hidx <= G_COL_INDEX:
                    assigned_fg[doc] += 1
                bg_cat[doc][classify_bg_category(date, hosp)] += 1
            elif L_COL_INDEX <= hidx <= L_Y_END_INDEX:
                assigned_ht[doc] += 1

            # Bã€œHåˆ—ã®ã‚«ã‚¦ãƒ³ãƒˆï¼ˆæ—§ï¼‰
            if B_H_START_INDEX <= hidx <= B_H_END_INDEX:
                assigned_bh[doc] += 1

            # v6.0.0: B/Iåˆ—ã®ã‚«ã‚¦ãƒ³ãƒˆï¼ˆHARD-001ï¼‰
            if hidx == B_COL_INDEX or hidx == I_COL_INDEX:
                assigned_bi[doc] += 1

            # v6.0.0: C-H/J-Kåˆ—ã®ã‚«ã‚¦ãƒ³ãƒˆï¼ˆHARD-002ï¼‰
            if (C_COL_INDEX <= hidx <= H_COL_INDEX) or (J_COL_INDEX <= hidx <= K_COL_INDEX):
                assigned_chjk[doc] += 1

            dow = date.weekday()
            weekday = dow < 5
            holi_flag = (
                is_holiday(date)
                or dow >= 5
                or (weekday and hidx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX))
            )
            if holi_flag:
                assigned_weekend[doc] += 1
            else:
                assigned_weekday[doc] += 1

            if is_bk_slot(hidx):
                assigned_bk[doc] += 1
            elif is_ly_slot(hidx):
                assigned_ly[doc] += 1

    # è‡ªå‹•å‰²å½“
    # æ æ±ºå®šé †åº: å¤§å­¦ä¼‘æ—¥(C-H) â†’ å¤§å­¦å¹³æ—¥(B,I-K) â†’ å¤–ç—…é™¢(L-Y)
    # C-Håˆ—ã¯ã‚«ãƒ†å½“ç•ªåˆ¶ç´„ãŒã‚ã‚‹ãŸã‚å…ˆã«åŸ‹ã‚ã‚‹
    def slot_priority(slot_tuple):
        ridx, hosp = slot_tuple
        hidx = shift_df.columns.get_loc(hosp)
        # C-Håˆ—ï¼ˆä¼‘æ—¥å¤§å­¦ç³»ï¼‰: å„ªå…ˆåº¦0ï¼ˆæœ€åˆï¼‰
        if C_COL_INDEX <= hidx <= H_COL_INDEX:
            return (0, hidx)
        # Båˆ—ã€I-Kåˆ—ï¼ˆå¹³æ—¥å¤§å­¦ç³»ï¼‰: å„ªå…ˆåº¦1
        elif hidx == B_COL_INDEX or (I_COL_INDEX <= hidx <= K_COL_INDEX):
            return (1, hidx)
        # L-Yåˆ—ï¼ˆå¤–ç—…é™¢ï¼‰: å„ªå…ˆåº¦2ï¼ˆæœ€å¾Œï¼‰
        else:
            return (2, hidx)

    for date in all_dates:
        free_slots = slots_by_date[date]["free"].copy()
        # å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆå¾Œã€åŒä¸€å„ªå…ˆåº¦å†…ã§ã‚·ãƒ£ãƒƒãƒ•ãƒ«
        random.shuffle(free_slots)  # ã¾ãšã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¦ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’ç¢ºä¿
        free_slots.sort(key=slot_priority)  # å®‰å®šã‚½ãƒ¼ãƒˆã§å„ªå…ˆåº¦é †ã«

        for ridx, hosp in free_slots:
            chosen = choose_doctor_for_slot(
                date=date,
                hospital_name=hosp,
                assigned_count=assigned_count,
                assigned_dates=assigned_dates,
                assigned_bg=assigned_bg,
                assigned_ht=assigned_ht,
                assigned_weekday=assigned_weekday,
                assigned_weekend=assigned_weekend,
                assigned_be=assigned_be,
                assigned_fg=assigned_fg,
                assigned_bk=assigned_bk,
                assigned_ly=assigned_ly,
                assigned_bh=assigned_bh,
                assigned_bi=assigned_bi,        # v6.0.0
                assigned_chjk=assigned_chjk,    # v6.0.0
                assigned_hosp_count=assigned_hosp_count,
            )
            if chosen is None:
                # v6.0.0 ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: çµ¶å¯¾ç¦å¿Œ(ABS)ã‚’ã™ã¹ã¦ãƒã‚§ãƒƒã‚¯
                hidx = shift_df.columns.get_loc(hosp)
                is_bg_slot = B_COL_INDEX <= hidx <= K_COL_INDEX

                def is_valid_fallback(d):
                    code = get_avail_code(date, d)
                    # ABS-001: ã‚³ãƒ¼ãƒ‰0ç¦æ­¢
                    if code == 0:
                        return False
                    # ABS-002: ã‚³ãƒ¼ãƒ‰2ã¯Bã€œQåˆ—ã®ã¿
                    if code == 2 and not (B_COL_INDEX <= hidx <= Q_COL_INDEX):
                        return False
                    # ABS-003: ã‚³ãƒ¼ãƒ‰3ã¯Lã€œYåˆ—ã®ã¿
                    if code == 3 and not (L_COL_INDEX <= hidx <= L_Y_END_INDEX):
                        return False
                    # ABS-006: åŒæ—¥é‡è¤‡ç¦æ­¢
                    if date in assigned_dates[d]:
                        return False
                    # ABS-007: gap >= 3æ—¥å¿…é ˆ
                    if assigned_dates[d]:
                        min_gap = min(abs((pd.to_datetime(date) - x).days) for x in assigned_dates[d])
                        if min_gap < 3:
                            return False
                    # ABS-008: åŒä¸€ç—…é™¢é‡è¤‡ç¦æ­¢
                    if assigned_hosp_count[d].get(hosp, 0) >= 1:
                        return False
                    # ABS-010: TARGET_CAPéµå®ˆ
                    if assigned_count[d] >= TARGET_CAP.get(d, 0):
                        return False
                    # ABS-011: å¤§å­¦ç³»2å›ã¾ã§
                    if is_bg_slot and assigned_bg[d] >= 2:
                        return False
                    return True

                remaining = [d for d in doctor_names if is_valid_fallback(d)]
                if remaining:
                    fallback_doc = min(remaining, key=lambda d: (assigned_count[d], doctor_col_index[d]))
                else:
                    # å…¨å“¡ãŒçµ¶å¯¾ç¦å¿Œã«è©²å½“ã™ã‚‹å ´åˆã¯æœªå‰²å½“ã®ã¾ã¾ï¼ˆNoneï¼‰
                    fallback_doc = None
                if fallback_doc is not None:
                    df.at[ridx, hosp] = fallback_doc
                    chosen = fallback_doc
                # fallback_doc ãŒ None ã®å ´åˆã¯æœªå‰²å½“ã®ã¾ã¾ï¼ˆå¾Œç¶šå‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            else:
                df.at[ridx, hosp] = chosen

            # chosen ãŒ None ã§ãªã‘ã‚Œã°ã‚«ã‚¦ãƒ³ãƒˆæ›´æ–°
            if chosen is not None:
                assigned_count[chosen] += 1
                assigned_dates[chosen].add(date)
                assigned_hosp_count[chosen][hosp] += 1

                hidx = shift_df.columns.get_loc(hosp)
                if B_COL_INDEX <= hidx <= K_COL_INDEX:
                    assigned_bg[chosen] += 1
                    if B_COL_INDEX <= hidx <= E_COL_INDEX:
                        assigned_be[chosen] += 1
                    elif F_COL_INDEX <= hidx <= G_COL_INDEX:
                        assigned_fg[chosen] += 1
                    bg_cat[chosen][classify_bg_category(date, hosp)] += 1
                elif L_COL_INDEX <= hidx <= L_Y_END_INDEX:
                    assigned_ht[chosen] += 1

                # Bã€œHåˆ—ã®ã‚«ã‚¦ãƒ³ãƒˆï¼ˆæ—§ï¼‰
                if B_H_START_INDEX <= hidx <= B_H_END_INDEX:
                    assigned_bh[chosen] += 1

                # v6.0.0: B/Iåˆ—ã®ã‚«ã‚¦ãƒ³ãƒˆï¼ˆHARD-001ï¼‰
                if hidx == B_COL_INDEX or hidx == I_COL_INDEX:
                    assigned_bi[chosen] += 1

                # v6.0.0: C-H/J-Kåˆ—ã®ã‚«ã‚¦ãƒ³ãƒˆï¼ˆHARD-002ï¼‰
                if (C_COL_INDEX <= hidx <= H_COL_INDEX) or (J_COL_INDEX <= hidx <= K_COL_INDEX):
                    assigned_chjk[chosen] += 1

                dow = date.weekday()
                weekday = dow < 5
                holi_flag = (
                    is_holiday(date)
                    or dow >= 5
                    or (weekday and hidx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX))
                )
                if holi_flag:
                    assigned_weekend[chosen] += 1
                else:
                    assigned_weekday[chosen] += 1

                if is_bk_slot(hidx):
                    assigned_bk[chosen] += 1
                elif is_ly_slot(hidx):
                    assigned_ly[chosen] += 1

    return (
        df,
        assigned_count,
        assigned_bg,
        assigned_ht,
        assigned_weekday,
        assigned_weekend,
        assigned_bk,
        assigned_ly,
        bg_cat,
    )

# =========================
# slot_meta / movable_positionsï¼ˆãƒ­ãƒ¼ã‚«ãƒ«æ¢ç´¢ç”¨ï¼‰
# =========================
slot_meta = {}  # (ridx,hosp) -> (date, fixed)
movable_positions = []  # (ridx,hosp,date)

for date in all_dates:
    for ridx, hosp, doc in slots_by_date[date]["preassigned"]:
        slot_meta[(ridx, hosp)] = (date, True)
    for ridx, hosp in slots_by_date[date]["free"]:
        slot_meta[(ridx, hosp)] = (date, False)
        movable_positions.append((ridx, hosp, date))

# =========================
# ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆå†è¨ˆç®—ï¼ˆpattern_df ã‹ã‚‰ï¼‰
# =========================
def recompute_stats(pattern_df):
    counts = {d: 0 for d in doctor_names}
    bg_counts = {d: 0 for d in doctor_names}
    ht_counts = {d: 0 for d in doctor_names}
    wd_counts = {d: 0 for d in doctor_names}
    we_counts = {d: 0 for d in doctor_names}
    bk_counts = {d: 0 for d in doctor_names}
    ly_counts = {d: 0 for d in doctor_names}
    bg_cat = {d: defaultdict(int) for d in doctor_names}
    assigned_hosp_count = {d: defaultdict(int) for d in doctor_names}
    doc_assignments = {d: [] for d in doctor_names}  # (date,hosp)
    unassigned = []  # (date,hosp,ridx)
    # CCï¼ˆå¤§å‹é€£ä¼‘ç‰¹åˆ¥ã‚·ãƒ•ãƒˆï¼‰ã‚«ã‚¦ãƒ³ãƒˆ - å„ç¨®ãƒãƒ©ãƒ³ã‚¹è¨ˆç®—ã‹ã‚‰é™¤å¤–ç”¨
    cc_counts = {d: 0 for d in doctor_names}
    cc_bg_counts = {d: 0 for d in doctor_names}  # CCã®ã†ã¡å¤§å­¦ç³»
    cc_ht_counts = {d: 0 for d in doctor_names}  # CCã®ã†ã¡å¤–ç—…é™¢

    for (ridx, hosp), (date, fixed) in slot_meta.items():
        val = pattern_df.at[ridx, hosp]

        # æœªå‰²ã‚Šå½“ã¦ãƒã‚§ãƒƒã‚¯ï¼ˆNone, NaN, éåŒ»å¸«åã®å ´åˆï¼‰
        if pd.isna(val):
            unassigned.append((date, hosp, ridx))
            continue
        if not isinstance(val, str):
            # æ•°å€¤ãªã©ï¼ˆ1ãªã©ï¼‰ã¯æœªå‰²ã‚Šå½“ã¦
            unassigned.append((date, hosp, ridx))
            continue
        v = normalize_name(val)  # ğŸ”§ FIX
        if v not in doctor_names:
            # åŒ»å¸«åã§ãªã„æ–‡å­—åˆ—ï¼ˆ"UNASSIGNED"ã‚„"1"ãªã©ï¼‰ã‚‚æœªå‰²ã‚Šå½“ã¦
            unassigned.append((date, hosp, ridx))
            continue

        doc = v
        counts[doc] += 1
        assigned_hosp_count[doc][hosp] += 1
        doc_assignments[doc].append((date, hosp))

        # CCåˆ¤å®š
        is_cc = is_cc_assignment(date, doc)
        if is_cc:
            cc_counts[doc] += 1

        hidx = shift_df.columns.get_loc(hosp)
        # å¤§å­¦ç³»ã¯Bã€œKåˆ—ï¼ˆB_COL_INDEX=1 ã€œ K_COL_INDEX=10ï¼‰
        if B_COL_INDEX <= hidx <= B_K_END_INDEX:
            bg_counts[doc] += 1
            bg_cat[doc][classify_bg_category(date, hosp)] += 1
            if is_cc:
                cc_bg_counts[doc] += 1
        # å¤–ç—…é™¢ã¯Lã€œYåˆ—ï¼ˆL_COL_INDEX=11 ã€œ Y_COL_INDEX=24ï¼‰
        elif L_COL_INDEX <= hidx <= L_Y_END_INDEX:
            ht_counts[doc] += 1
            if is_cc:
                cc_ht_counts[doc] += 1

        dow = date.weekday()
        weekday = dow < 5
        holi_flag = (
            is_holiday(date)
            or dow >= 5
            or (weekday and hidx in (C_COL_INDEX, D_COL_INDEX, F_COL_INDEX, G_COL_INDEX))
        )
        if holi_flag:
            we_counts[doc] += 1
        else:
            wd_counts[doc] += 1

        if is_bk_slot(hidx):
            bk_counts[doc] += 1
        elif is_ly_slot(hidx):
            ly_counts[doc] += 1

    return (
        counts,
        bg_counts,
        ht_counts,
        wd_counts,
        we_counts,
        bk_counts,
        ly_counts,
        bg_cat,
        assigned_hosp_count,
        doc_assignments,
        unassigned,
        cc_counts,
        cc_bg_counts,
        cc_ht_counts,
    )

# =========================
# ã‚¹ã‚³ã‚¢è©•ä¾¡ï¼ˆraw_scoreã‚‚ä¿æŒã—ã¦ 0 ã§æ½°ã‚Œãªã„ã‚ˆã†ã«ï¼‰
# =========================
def evaluate_schedule_with_raw(
    pattern_df,
    assigned_count,
    assigned_bg,
    assigned_ht,
    assigned_weekday,
    assigned_weekend,
    assigned_bk,
    assigned_ly,
):
    # UNASSIGNED - slot_metaã«ç™»éŒ²ã•ã‚ŒãŸã‚¹ãƒ­ãƒƒãƒˆã®ã†ã¡ã€åŒ»å¸«åãŒå…¥ã£ã¦ã„ãªã„ã‚‚ã®ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    # None, NaN, éåŒ»å¸«åï¼ˆ1, ã€‡ãªã©ï¼‰ã‚‚æœªå‰²ã‚Šå½“ã¦ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆ
    unassigned_slots = 0
    for (ridx, hosp), (date, fixed) in slot_meta.items():
        v = pattern_df.at[ridx, hosp]
        # åŒ»å¸«åã§ãªã„å ´åˆã¯æœªå‰²ã‚Šå½“ã¦
        if pd.isna(v):
            unassigned_slots += 1
        elif isinstance(v, str):
            v_norm = normalize_name(v)
            if v_norm not in doctor_names:
                unassigned_slots += 1
        else:
            # æ•°å€¤ãªã©ï¼ˆ1ãªã©ï¼‰ã¯æœªå‰²ã‚Šå½“ã¦
            unassigned_slots += 1

    # CCï¼ˆå¤§å‹é€£ä¼‘ç‰¹åˆ¥ã‚·ãƒ•ãƒˆï¼‰ã‚«ã‚¦ãƒ³ãƒˆ - ãƒãƒ©ãƒ³ã‚¹è¨ˆç®—ã‹ã‚‰é™¤å¤–ç”¨
    cc_counts = {d: 0 for d in doctor_names}
    cc_bg_counts = {d: 0 for d in doctor_names}
    cc_ht_counts = {d: 0 for d in doctor_names}
    cc_hosp_counts = {d: defaultdict(int) for d in doctor_names}  # CCåˆ†ã®ç—…é™¢åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
    for ridx in pattern_df.index:
        date = pattern_df.at[ridx, date_col_shift]
        if pd.isna(date):
            continue
        date = pd.to_datetime(date).normalize().tz_localize(None)
        for hosp in hospital_cols:
            val = pattern_df.at[ridx, hosp]
            if not isinstance(val, str):
                continue
            doc = normalize_name(val)
            if doc not in doctor_names:
                continue
            if is_cc_assignment(date, doc):
                cc_counts[doc] += 1
                cc_hosp_counts[doc][hosp] += 1
                hidx = shift_df.columns.get_loc(hosp)
                if B_COL_INDEX <= hidx <= B_K_END_INDEX:
                    cc_bg_counts[doc] += 1
                elif L_COL_INDEX <= hidx <= L_Y_END_INDEX:
                    cc_ht_counts[doc] += 1

    # capé•å
    cap_violations = 0
    for doc in doctor_names:
        cap = TARGET_CAP.get(doc, 0)
        if assigned_count.get(doc, 0) > cap:
            cap_violations += (assigned_count[doc] - cap)

    # CODE_2åŒ»å¸«ã®n+1é•åï¼ˆBASE_TARGETè¶…éï¼‰
    code_2_extra_violations = 0
    for doc in CODE_2_DOCTORS:
        if doc not in active_doctors:
            continue
        if assigned_count.get(doc, 0) > BASE_TARGET:
            code_2_extra_violations += (assigned_count[doc] - BASE_TARGET)

    # å…¨åˆè¨ˆå…¬å¹³æ€§ï¼ˆactiveã®ã¿ã€CCé™¤å¤–ï¼‰
    # CCã¯å¤§å‹é€£ä¼‘ç‰¹åˆ¥ã‚·ãƒ•ãƒˆãªã®ã§å…¬å¹³æ€§è¨ˆç®—ã‹ã‚‰é™¤å¤–
    active_counts_no_cc = [assigned_count.get(d, 0) - cc_counts.get(d, 0) for d in active_doctors]
    max_c = max(active_counts_no_cc) if active_counts_no_cc else 0
    min_c = min(active_counts_no_cc) if active_counts_no_cc else 0
    diff_total = max_c - min_c
    # å·®ãŒ2ä»¥ä¸Šã®å ´åˆã€ä¸æº€ãŒé«˜ã„ã®ã§å¼·ã„ãƒšãƒŠãƒ«ãƒ†ã‚£
    # ä¾‹: min=2, max=4ã®å ´åˆã€4å›ã®åŒ»å¸«ã‹ã‚‰2å›ã®åŒ»å¸«ã«æ¸¡ã™ã¹ã
    if diff_total >= 2:
        fairness_penalty = diff_total * 2  # 2å€ã®ãƒšãƒŠãƒ«ãƒ†ã‚£
    else:
        fairness_penalty = max(0, diff_total - 1)

    # gap(4æ—¥æœªæº€) ã¨ åŒä¸€ç—…é™¢é‡è¤‡
    dates_by_doc = defaultdict(list)
    hosp_counts_by_doc = {doc: defaultdict(int) for doc in doctor_names}

    for ridx in pattern_df.index:
        date = pattern_df.at[ridx, date_col_shift]
        if pd.isna(date):
            continue
        date = pd.to_datetime(date).normalize().tz_localize(None)  # ğŸ”§ FIX
        for hosp in hospital_cols:
            val = pattern_df.at[ridx, hosp]
            val_norm = normalize_name(val) if isinstance(val, str) else ""  # ğŸ”§ FIX
            if val_norm in doctor_names:
                dates_by_doc[val_norm].append(date)
                hosp_counts_by_doc[val_norm][hosp] += 1

    gap_violations = 0
    for doc, dlist in dates_by_doc.items():
        dlist = sorted(dlist)
        for i in range(1, len(dlist)):
            if (dlist[i] - dlist[i - 1]).days < 3:
                gap_violations += 1

    hosp_dup_violations = 0
    external_hosp_dup_violations = 0  # å¤–ç—…é™¢é‡è¤‡ï¼ˆå³ã—ãæ‰±ã†ï¼‰
    for doc, hdict in hosp_counts_by_doc.items():
        for hosp, c in hdict.items():
            # CCåˆ†ã‚’é™¤å¤–ï¼ˆCCã¯ç‰¹åˆ¥ã‚·ãƒ•ãƒˆãªã®ã§é‡è¤‡ã‚«ã‚¦ãƒ³ãƒˆã‹ã‚‰é™¤å¤–ï¼‰
            c_no_cc = c - cc_hosp_counts.get(doc, {}).get(hosp, 0)
            if c_no_cc > 1:
                # ç—…é™¢ãŒå¤–ç—…é™¢ï¼ˆLï½Yåˆ—ï¼‰ã‹ã©ã†ã‹ã‚’åˆ¤å®š
                hidx = shift_df.columns.get_loc(hosp)
                if L_COL_INDEX <= hidx <= L_Y_END_INDEX:
                    external_hosp_dup_violations += (c_no_cc - 1)
                else:
                    hosp_dup_violations += (c_no_cc - 1)

    # åã‚Šï¼ˆç´¯è¨ˆï¼šå‰æœˆ+ä»Šæœˆï¼‰ã® spread
    bg_vals = [prev_bg[d] + assigned_bg.get(d, 0) for d in active_doctors]
    ht_vals = [prev_ht[d] + assigned_ht.get(d, 0) for d in active_doctors]
    wd_vals = [prev_weekday[d] + assigned_weekday.get(d, 0) for d in active_doctors]
    we_vals = [prev_weekend[d] + assigned_weekend.get(d, 0) for d in active_doctors]

    bg_spread = (max(bg_vals) - min(bg_vals)) if bg_vals else 0
    ht_spread = (max(ht_vals) - min(ht_vals)) if ht_vals else 0
    wd_spread = (max(wd_vals) - min(wd_vals)) if wd_vals else 0
    we_spread = (max(we_vals) - min(we_vals)) if we_vals else 0

    bk_ly_imbalance = 0
    for doc in active_doctors:
        if doc in RATIO_EXEMPT_DOCTORS:
            continue
        bk_val = assigned_bk.get(doc, 0)
        ly_val = assigned_ly.get(doc, 0)
        bk_ly_imbalance += abs(bk_val - ly_val)

    # å¯å¦ã‚³ãƒ¼ãƒ‰1.2ã®åŒ»å¸«ãŒå¤§å­¦ç³»0å›ã®å ´åˆã®ãƒšãƒŠãƒ«ãƒ†ã‚£
    code_1_2_violations = 0
    for doc in CODE_1_2_DOCTORS:
        if assigned_bg.get(doc, 0) == 0:
            code_1_2_violations += 1

    # å¤§å­¦ç³»ã¨å¤–ç—…é™¢ã®å·®ãŒ3ä»¥ä¸Šã®å ´åˆã®ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆCCé™¤å¤–ï¼‰
    bg_ht_imbalance_violations = 0
    for doc in active_doctors:
        # CCã¯å¤§å‹é€£ä¼‘ç‰¹åˆ¥ã‚·ãƒ•ãƒˆãªã®ã§ãƒãƒ©ãƒ³ã‚¹è¨ˆç®—ã‹ã‚‰é™¤å¤–
        bg = assigned_bg.get(doc, 0) - cc_bg_counts.get(doc, 0)
        ht = assigned_ht.get(doc, 0) - cc_ht_counts.get(doc, 0)
        diff = abs(bg - ht)
        if diff >= 3:
            bg_ht_imbalance_violations += (diff - 2)  # å·®ãŒ3ä»¥ä¸Šã®è¶…éåˆ†ã‚’ã‚«ã‚¦ãƒ³ãƒˆ

    # å¤§å­¦ç—…é™¢2å›ã®å ´åˆã€å¹³æ—¥1å›+ä¼‘æ—¥1å›ã®ãƒãƒ©ãƒ³ã‚¹é•å
    bg_weekday_weekend_imbalance = 0
    bg_over_2_violations = 0  # å¤§å­¦3å›ä»¥ä¸Šã®é•åï¼ˆä¸æº€ãŒé«˜ã„ï¼‰
    ht_0_violations = 0  # å¤–ç—…é™¢0å›ã®é•åï¼ˆãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼šå¤§å­¦3å›ä»¥ä¸Šã‚’é˜²ãï¼‰
    bg_weekday_over_violations = 0  # å¤§å­¦ã®å¹³æ—¥åã‚Šï¼ˆå¹³æ—¥2å›ä»¥ä¸Šã¯ä¸æº€ï¼‰
    for doc in active_doctors:
        if doc in RATIO_EXEMPT_DOCTORS:  # ã‚³ãƒ¼ãƒ‰3ã¯å¤–ç—…é™¢å°‚é–€ãªã®ã§é™¤å¤–
            continue
        # CCé™¤å¤–ï¼ˆå¤§å‹é€£ä¼‘ç‰¹åˆ¥ã‚·ãƒ•ãƒˆã¯ãƒãƒ©ãƒ³ã‚¹è¨ˆç®—ã‹ã‚‰é™¤å¤–ï¼‰
        bg_total_no_cc = assigned_bg.get(doc, 0) - cc_bg_counts.get(doc, 0)
        ht_total_no_cc = assigned_ht.get(doc, 0) - cc_ht_counts.get(doc, 0)
        # å…ƒã®å€¤ï¼ˆht_0_violationsãªã©ãƒãƒ¼ãƒ‰åˆ¶ç´„ç”¨ï¼‰
        bg_total = assigned_bg.get(doc, 0)
        ht_total = assigned_ht.get(doc, 0)
        weekday_count = bg_cat[doc].get("å¹³æ—¥", 0)

        # å¤§å­¦3å›ä»¥ä¸Šã¯ä¸å¯ï¼ˆCCé™¤å¤–ï¼‰
        if bg_total_no_cc >= 3:
            bg_over_2_violations += (bg_total_no_cc - 2)

        # å¤–ç—…é™¢0å›ã‹ã¤å¤§å­¦1å›ä»¥ä¸Šã¯ãƒãƒ¼ãƒ‰åˆ¶ç´„é•åï¼ˆCCã¯é™¤å¤–ã—ãªã„ï¼šãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼‰
        if ht_total == 0 and bg_total >= 1:
            ht_0_violations += 1

        # å¤§å­¦2å›ã®å ´åˆã€å¹³æ—¥1å›+ä¼‘æ—¥1å›ãŒç†æƒ³ï¼ˆCCé™¤å¤–ï¼‰
        if bg_total_no_cc == 2:
            if weekday_count == 0 or weekday_count == 2:
                bg_weekday_weekend_imbalance += 1

        # å¤§å­¦ã®å¹³æ—¥ãŒ2å›ä»¥ä¸Šã¯ä¸æº€ï¼ˆCCé™¤å¤–ï¼‰
        # æ³¨ï¼šweekday_countã‹ã‚‰CCã‚’é™¤å¤–ã™ã‚‹ã«ã¯è¿½åŠ ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãŒå¿…è¦
        # ç¾æ™‚ç‚¹ã§ã¯weekday_countã¯ãã®ã¾ã¾ä½¿ç”¨ï¼ˆå¤§å‹é€£ä¼‘ã¯å¹³æ—¥ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã«ãã„ï¼‰
        if weekday_count >= 2:
            bg_weekday_over_violations += (weekday_count - 1)

    # C-Håˆ—ï¼ˆä¼‘æ—¥å¤§å­¦ç³»ï¼‰ã‚«ãƒ†å½“ç•ªé•å
    # ã‚«ãƒ†å½“ç•ªä¿æœ‰åŒ»å¸«ãŒãã®æ—¥ã«ã‚«ãƒ†å½“ç•ªãªã—ã§C-Håˆ—ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆ
    ch_kate_violations = 0
    for ridx in pattern_df.index:
        date = pattern_df.at[ridx, date_col_shift]
        if pd.isna(date):
            continue
        date = pd.to_datetime(date).normalize().tz_localize(None)
        for hosp in hospital_cols:
            idx = shift_df.columns.get_loc(hosp)
            if not is_ch_slot(idx):
                continue
            val = pattern_df.at[ridx, hosp]
            val_norm = normalize_name(val) if isinstance(val, str) else ""
            if val_norm in doctor_names:
                if not is_eligible_for_ch_slot(val_norm, date):
                    ch_kate_violations += 1

    penalty = 0
    penalty += fairness_penalty * W_FAIR_TOTAL
    penalty += gap_violations * W_GAP
    penalty += hosp_dup_violations * W_HOSP_DUP
    penalty += external_hosp_dup_violations * W_EXTERNAL_HOSP_DUP  # å¤–ç—…é™¢é‡è¤‡ã¯å³æ ¼
    penalty += unassigned_slots * W_UNASSIGNED
    penalty += cap_violations * W_CAP
    penalty += code_2_extra_violations * 300  # CODE_2åŒ»å¸«ã®n+1é•åã¯å³æ ¼ï¼ˆãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼‰
    penalty += code_1_2_violations * 150  # 1.2ã®åŒ»å¸«ãŒå¤§å­¦ç³»0å›ã®å ´åˆã€å¤§ããªãƒšãƒŠãƒ«ãƒ†ã‚£
    penalty += bg_ht_imbalance_violations * 100  # å¤§å­¦ç³»ã¨å¤–ç—…é™¢ã®å·®ãŒ3ä»¥ä¸Šã®å ´åˆã€å¤§ããªãƒšãƒŠãƒ«ãƒ†ã‚£
    penalty += bg_weekday_weekend_imbalance * 50  # å¤§å­¦ç—…é™¢2å›ã®å¹³æ—¥/ä¼‘æ—¥ãƒãƒ©ãƒ³ã‚¹é•å
    penalty += bg_over_2_violations * 300  # å¤§å­¦3å›ä»¥ä¸Šã®é•åï¼ˆãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼‰
    penalty += ht_0_violations * 300  # å¤–ç—…é™¢0å›ã®é•åï¼ˆãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼‰
    penalty += bg_weekday_over_violations * 80  # å¤§å­¦ã®å¹³æ—¥åã‚Šï¼ˆå¹³æ—¥2å›ä»¥ä¸Šã¯ä¸æº€ï¼‰
    penalty += ch_kate_violations * 120  # C-Håˆ—ã‚«ãƒ†å½“ç•ªé•åï¼ˆå„ªå…ˆåº¦é«˜ï¼‰

    penalty += max(0, bg_spread - 1) * W_BG_SPREAD
    penalty += max(0, ht_spread - 1) * W_HT_SPREAD
    penalty += max(0, wd_spread - 1) * W_WD_SPREAD
    penalty += max(0, we_spread - 1) * W_WE_SPREAD
    penalty += bk_ly_imbalance * W_BK_LY_BALANCE

    raw_score = 100 - penalty
    score = max(raw_score, 0)

    metrics = {
        "raw_score": float(raw_score),
        "penalty_total": float(penalty),
        "max_minus_min_total_active": int(diff_total),
        "gap_violations": int(gap_violations),
        "hospital_dup_violations": int(hosp_dup_violations),
        "external_hosp_dup_violations": int(external_hosp_dup_violations),
        "unassigned_slots": int(unassigned_slots),
        "cap_violations": int(cap_violations),
        "code_2_extra_violations": int(code_2_extra_violations),
        "code_1_2_violations": int(code_1_2_violations),
        "bg_ht_imbalance_violations": int(bg_ht_imbalance_violations),
        "bg_weekday_weekend_imbalance": int(bg_weekday_weekend_imbalance),
        "bg_over_2_violations": int(bg_over_2_violations),
        "ht_0_violations": int(ht_0_violations),
        "bg_weekday_over_violations": int(bg_weekday_over_violations),
        "ch_kate_violations": int(ch_kate_violations),
        "bg_spread_cum": float(bg_spread),
        "ht_spread_cum": float(ht_spread),
        "weekday_spread_cum": float(wd_spread),
        "weekend_spread_cum": float(we_spread),
        "bk_ly_imbalance": int(bk_ly_imbalance),
    }
    return score, raw_score, metrics

# =========================
# ãƒ­ãƒ¼ã‚«ãƒ«æ¢ç´¢ï¼ˆå…¥æ›¿ swapï¼‰
# ğŸ”§ FIX: date_doc_count ã‚’å®Œå…¨ãª defaultdict(lambda: defaultdict(int)) ã«å¤‰æ›´
# ğŸ”§ FIX: åŒæ—¥é‡è¤‡ãƒã‚§ãƒƒã‚¯ã®å¼·åŒ–
# =========================
def can_assign_doc_to_slot(doc, date, hosp):
    """ãƒãƒ¼ãƒ‰åˆ¶ç´„ã®ã¿ï¼ˆåŒæ—¥é‡è¤‡ã¯åˆ¥ãƒã‚§ãƒƒã‚¯ï¼‰"""
    idx = shift_df.columns.get_loc(hosp)
    dow = pd.to_datetime(date).weekday()

    code = get_avail_code(date, doc)
    if code == 0:
        return False
    # å¯å¦ã‚³ãƒ¼ãƒ‰2 â†’ Bã€œQåˆ—ã®ã¿å¯
    if code == 2 and not (B_COL_INDEX <= idx <= Q_COL_INDEX):
        return False
    # å¯å¦ã‚³ãƒ¼ãƒ‰3 â†’ Lã€œYåˆ—ã®ã¿å¯
    if code == 3 and not (L_COL_INDEX <= idx <= L_Y_END_INDEX):
        return False
    # ãã®æ—¥ã«ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ã‚ã‚Š â†’ Lã€œYåˆ—ä¸å¯
    if L_COL_INDEX <= idx <= L_Y_END_INDEX:
        if get_sched_code(date, doc):
            return False
    # Bã€œKåˆ—ã¯ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ä¿æœ‰åŒ»å¸«ã®ã¿ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ãŒå¿…è¦ï¼ˆEXTRAåŒ»å¸«ã¯ä¾‹å¤–ï¼‰
    if B_COL_INDEX <= idx <= B_K_END_INDEX:
        if doc in SCHEDULE_CODE_HOLDERS and not get_sched_code(date, doc) and doc not in EXTRA_ALLOWED:
            return False
    # æ°´æ›œæ—¥Lã€œYåˆ—ç¦æ­¢åŒ»å¸«
    if dow == 2 and L_COL_INDEX <= idx <= L_Y_END_INDEX and doc in WED_FORBIDDEN_DOCTORS:
        return False
    return True

def build_date_doc_count(pattern_df):
    """date -> doc -> countï¼ˆåŒæ—¥è¤‡æ•°å‰²å½“æ¤œå‡ºã‚‚å…¼ã­ã‚‹ï¼‰"""
    # ğŸ”§ FIX: å®Œå…¨ãª nested defaultdict ã«å¤‰æ›´
    date_doc_count = defaultdict(lambda: defaultdict(int))
    for (ridx, hosp), (date, fixed) in slot_meta.items():
        val = pattern_df.at[ridx, hosp]
        if isinstance(val, str):
            v = normalize_name(val)  # ğŸ”§ FIX
            if v in doctor_names:
                date_doc_count[date][v] += 1
    return date_doc_count

def collect_violation_docs_from_assignments(doc_assignments, assigned_hosp_count):
    bad = set()
    # gap
    for doc, assigns in doc_assignments.items():
        dlist = sorted([d for d, _ in assigns])
        for i in range(1, len(dlist)):
            if (dlist[i] - dlist[i - 1]).days < 3:
                bad.add(doc)
                break
    # hospital dup
    for doc, hdict in assigned_hosp_count.items():
        if any(c > 1 for c in hdict.values()):
            bad.add(doc)
    return bad

def is_better_raw(new_raw, new_metrics, cur_raw, cur_metrics):
    if new_raw > cur_raw:
        return True
    if new_raw < cur_raw:
        return False
    # tie-breakï¼ˆé‡è¦åº¦é †ï¼‰
    keys = [
        "unassigned_slots",
        "cap_violations",
        "gap_violations",
        "hospital_dup_violations",
        "max_minus_min_total_active",
        "bk_ly_imbalance",
        "bg_spread_cum",
        "ht_spread_cum",
        "weekday_spread_cum",
        "weekend_spread_cum",
    ]
    return tuple(new_metrics.get(k, 0) for k in keys) < tuple(cur_metrics.get(k, 0) for k in keys)

def local_search_swap(pattern_df, max_iters=2000, patience=800, refresh_every=200, seed=0):
    """å…¥æ›¿ï¼ˆswapï¼‰å±€æ‰€æ¢ç´¢ï¼špreassignedã¯å‹•ã‹ã•ãšã€freeæ ã®ã¿ã‚’å¯¾è±¡ã«æ”¹å–„ã™ã‚‹"""
    if not movable_positions:
        # å‹•ã‹ã›ã‚‹æ ãŒç„¡ã„ï¼ˆå…¨éƒ¨å›ºå®šãªã©ï¼‰
        counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, *_ = recompute_stats(pattern_df)
        score, raw_score, metrics = evaluate_schedule_with_raw(
            pattern_df,
            counts,
            bg_counts,
            ht_counts,
            wd_counts,
            we_counts,
            bk_counts,
            ly_counts,
        )
        return pattern_df.copy(), score, raw_score, metrics

    rng = random.Random(seed)
    df = pattern_df.copy()

    counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, *_ = recompute_stats(df)
    cur_score, cur_raw, cur_metrics = evaluate_schedule_with_raw(
        df,
        counts,
        bg_counts,
        ht_counts,
        wd_counts,
        we_counts,
        bk_counts,
        ly_counts,
    )
    date_doc_count = build_date_doc_count(df)

    no_improve = 0
    bad_positions = None

    for it in range(1, max_iters + 1):
        if no_improve >= patience:
            break

        if it == 1 or it % refresh_every == 0:
            bad_docs = collect_violation_docs_from_assignments(doc_assignments, assigned_hosp_count)
            if bad_docs:
                tmp = []
                for (ridx, hosp, date) in movable_positions:
                    v = df.at[ridx, hosp]
                    if isinstance(v, str) and normalize_name(v) in bad_docs:  # ğŸ”§ FIX
                        tmp.append((ridx, hosp, date))
                bad_positions = tmp if tmp else None
            else:
                bad_positions = None

        p1 = rng.choice(bad_positions if bad_positions is not None else movable_positions)
        p2 = rng.choice(movable_positions)
        if p1 == p2:
            no_improve += 1
            continue

        r1, h1, d1 = p1
        r2, h2, d2 = p2

        v1 = df.at[r1, h1]
        v2 = df.at[r2, h2]
        if not (isinstance(v1, str) and isinstance(v2, str)):
            no_improve += 1
            continue

        doc1 = normalize_name(v1)  # ğŸ”§ FIX
        doc2 = normalize_name(v2)  # ğŸ”§ FIX
        if doc1 not in doctor_names or doc2 not in doctor_names:
            no_improve += 1
            continue
        if doc1 == doc2:
            no_improve += 1
            continue

        # ğŸ”§ FIX: åŒæ—¥é‡è¤‡ã‚’ä½œã‚‰ãªã„ï¼ˆåŒã˜æ—¥åŒå£«ã®swapã‚‚ãƒã‚§ãƒƒã‚¯ï¼‰
        if d1 == d2:
            # åŒã˜æ—¥ã®slotåŒå£«ã‚’swapã™ã‚‹å ´åˆã€å…ƒã€…åŒã˜doctorãŒã„ãªã‘ã‚Œã°OK
            # ï¼ˆæ—¢ã«doc1!=doc2ã‚’ç¢ºèªæ¸ˆã¿ãªã®ã§ã€è¿½åŠ ãƒã‚§ãƒƒã‚¯ä¸è¦ï¼‰
            pass
        else:
            # ç•°ãªã‚‹æ—¥ã®swap
            if date_doc_count[d2][doc1] > 0:  # doc1ãŒd2ã«æ—¢ã«ã„ã‚‹
                no_improve += 1
                continue
            if date_doc_count[d1][doc2] > 0:  # doc2ãŒd1ã«æ—¢ã«ã„ã‚‹
                no_improve += 1
                continue

        # ãƒãƒ¼ãƒ‰åˆ¶ç´„
        if not can_assign_doc_to_slot(doc1, d2, h2):
            no_improve += 1
            continue
        if not can_assign_doc_to_slot(doc2, d1, h1):
            no_improve += 1
            continue

        # swapï¼ˆin-placeï¼‰
        df.at[r1, h1], df.at[r2, h2] = doc2, doc1

        # ğŸ”§ FIX: date_doc_count æ›´æ–°ï¼ˆdefaultdictãªã®ã§KeyErrorãªã—ï¼‰
        if d1 != d2:
            date_doc_count[d1][doc1] -= 1
            if date_doc_count[d1][doc1] <= 0:
                del date_doc_count[d1][doc1]
            date_doc_count[d2][doc2] -= 1
            if date_doc_count[d2][doc2] <= 0:
                del date_doc_count[d2][doc2]
            date_doc_count[d1][doc2] += 1
            date_doc_count[d2][doc1] += 1

        # å†è©•ä¾¡ï¼ˆå…¨å†è¨ˆç®—ï¼‰
        counts2, bg2, ht2, wd2, we2, bk2, ly2, bg_cat2, assigned_hosp_count2, doc_assignments2, unassigned2, *_ = recompute_stats(df)
        new_score, new_raw, new_metrics = evaluate_schedule_with_raw(
            df,
            counts2,
            bg2,
            ht2,
            wd2,
            we2,
            bk2,
            ly2,
        )

        # çµ¶å¯¾ç¦å¿Œãƒã‚§ãƒƒã‚¯: gapé•åã¾ãŸã¯å¤–ç—…é™¢é‡è¤‡ãŒã‚ã‚Œã°æ‹’å¦
        new_gap_violations = new_metrics.get("gap_violations", 0)
        new_external_hosp_dup = new_metrics.get("external_hosp_dup_violations", 0)
        if new_gap_violations > 0 or new_external_hosp_dup > 0:
            # revert
            df.at[r1, h1], df.at[r2, h2] = doc1, doc2
            if d1 != d2:
                date_doc_count[d1][doc2] -= 1
                if date_doc_count[d1][doc2] <= 0:
                    del date_doc_count[d1][doc2]
                date_doc_count[d2][doc1] -= 1
                if date_doc_count[d2][doc1] <= 0:
                    del date_doc_count[d2][doc1]
                date_doc_count[d1][doc1] += 1
                date_doc_count[d2][doc2] += 1
            no_improve += 1
        elif is_better_raw(new_raw, new_metrics, cur_raw, cur_metrics):
            cur_score, cur_raw, cur_metrics = new_score, new_raw, new_metrics
            counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat = counts2, bg2, ht2, wd2, we2, bg_cat2
            assigned_hosp_count, doc_assignments = assigned_hosp_count2, doc_assignments2
            no_improve = 0
        else:
            # revert
            df.at[r1, h1], df.at[r2, h2] = doc1, doc2
            if d1 != d2:
                date_doc_count[d1][doc2] -= 1
                if date_doc_count[d1][doc2] <= 0:
                    del date_doc_count[d1][doc2]
                date_doc_count[d2][doc1] -= 1
                if date_doc_count[d2][doc1] <= 0:
                    del date_doc_count[d2][doc1]
                date_doc_count[d1][doc1] += 1
                date_doc_count[d2][doc2] += 1
            no_improve += 1

    return df, cur_score, cur_raw, cur_metrics

# =========================
# ã‚µãƒãƒªãƒ¼åˆ—ï¼ˆSheet4 ã®åˆ—ã‚’åŸºæº–ã«è‡ªå‹•ç”Ÿæˆï¼‰
# =========================
META_COLS_SHEET4 = {"ã‚«ãƒ†å½“ç•ª", "å‡ºå¼µæ—¥", "å‡ºå¼µå…ˆ"}
BASE_SUMMARY_COLS = {"å…¨åˆè¨ˆ", "å¤§å­¦åˆè¨ˆ", "å¤–ç—…é™¢åˆè¨ˆ", "å¹³æ—¥", "ä¼‘æ—¥åˆè¨ˆ"}

UNIV7_SET = {"å¤§å­¦å¹³æ—¥", "å¤§å­¦åœŸæ›œæ˜¼", "å¤§å­¦åœŸæ›œå¤œ", "å¤§å­¦æ—¥æ›œæ˜¼", "å¤§å­¦æ—¥æ›œå¤œ", "å¤§å­¦ç¥æ—¥æ˜¼", "å¤§å­¦ç¥æ—¥å¤œ"}
UNIV7_ORDER = [c for c in sheet4_raw_out.columns if c in UNIV7_SET]
if not UNIV7_ORDER:
    UNIV7_ORDER = ["å¤§å­¦åœŸæ›œæ˜¼", "å¤§å­¦åœŸæ›œå¤œ", "å¤§å­¦æ—¥æ›œæ˜¼", "å¤§å­¦æ—¥æ›œå¤œ", "å¤§å­¦ç¥æ—¥æ˜¼", "å¤§å­¦ç¥æ—¥å¤œ", "å¤§å­¦å¹³æ—¥"]

DETAIL_COLS = [
    c for c in sheet4_raw_out.columns
    if c not in META_COLS_SHEET4 and c not in ["æ°å"] and c not in BASE_SUMMARY_COLS and c not in UNIV7_SET
]

SUMMARY_DETAIL_COLS = UNIV7_ORDER + DETAIL_COLS
SUMMARY_COLS = ["æ°å", "å…¨åˆè¨ˆ", "å¤§å­¦åˆè¨ˆ", "å¤–ç—…é™¢åˆè¨ˆ", "å¹³æ—¥", "ä¼‘æ—¥åˆè¨ˆ"] + SUMMARY_DETAIL_COLS

def count_doc_in_column(df, colname, doc):
    if colname not in df.columns:
        return 0
    s = df[colname]
    cnt = 0
    for v in s:
        if isinstance(v, str) and normalize_name(v) == doc:  # ğŸ”§ FIX
            cnt += 1
    return cnt

def build_summaries(pattern_df, counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat_local):
    rows_month = []
    rows_total = []

    uni_map = {
        "å¤§å­¦å¹³æ—¥": "å¹³æ—¥",
        "å¤§å­¦åœŸæ›œæ˜¼": "åœŸæ›œæ˜¼",
        "å¤§å­¦åœŸæ›œå¤œ": "åœŸæ›œå¤œ",
        "å¤§å­¦æ—¥æ›œæ˜¼": "æ—¥æ›œæ˜¼",
        "å¤§å­¦æ—¥æ›œå¤œ": "æ—¥æ›œå¤œ",
        "å¤§å­¦ç¥æ—¥æ˜¼": "ç¥æ—¥æ˜¼",
        "å¤§å­¦ç¥æ—¥å¤œ": "ç¥æ—¥å¤œ",
    }

    for doc in doctor_names:
        pname = name_match.get(doc)
        base_row = name_to_row.get(pname) if pname and pname in name_to_row else None

        def prev_val(colname):
            if base_row is None:
                return 0.0
            v = base_row.get(colname, 0)
            try:
                return float(v or 0)
            except Exception:
                return 0.0

        # ä»Šæœˆ
        row_m = {c: 0.0 for c in SUMMARY_COLS}
        row_m["æ°å"] = doc
        row_m["å…¨åˆè¨ˆ"] = float(counts.get(doc, 0))
        row_m["å¤§å­¦åˆè¨ˆ"] = float(bg_counts.get(doc, 0))
        row_m["å¤–ç—…é™¢åˆè¨ˆ"] = float(ht_counts.get(doc, 0))
        row_m["å¹³æ—¥"] = float(wd_counts.get(doc, 0))
        row_m["ä¼‘æ—¥åˆè¨ˆ"] = float(we_counts.get(doc, 0))

        # å¤§å­¦7åˆ†é¡
        for col in UNIV7_ORDER:
            cat = uni_map.get(col)
            if cat:
                row_m[col] = float(bg_cat_local[doc].get(cat, 0))

        # ç—…é™¢åˆ—ï¼ˆSheet4æº–æ‹ ï¼‰ã‚’ãã®ã¾ã¾æ•°ãˆã‚‹
        for col in DETAIL_COLS:
            row_m[col] = float(count_doc_in_column(pattern_df, col, doc))

        # ç´¯è¨ˆï¼ˆå‰æœˆï¼‹ä»Šæœˆï¼‰
        row_t = {c: 0.0 for c in SUMMARY_COLS}
        row_t["æ°å"] = doc
        for c in SUMMARY_COLS:
            if c == "æ°å":
                continue
            row_t[c] = prev_val(c) + float(row_m.get(c, 0))

        rows_month.append(row_m)
        rows_total.append(row_t)

    return pd.DataFrame(rows_month)[SUMMARY_COLS], pd.DataFrame(rows_total)[SUMMARY_COLS]

# =========================
# è¨ºæ–­ã‚·ãƒ¼ãƒˆç”Ÿæˆï¼ˆåã‚Š & gapé•åä¸€è¦§ï¼‰
# =========================
def build_gap_details(doc_assignments):
    rows = []
    for doc, assigns in doc_assignments.items():
        assigns_sorted = sorted(assigns, key=lambda x: (x[0], x[1]))
        for i in range(1, len(assigns_sorted)):
            d_prev, h_prev = assigns_sorted[i - 1]
            d_cur, h_cur = assigns_sorted[i]
            gap = (d_cur - d_prev).days
            if gap < 3:
                rows.append({
                    "æ°å": doc,
                    "å‰å›æ—¥ä»˜": d_prev,
                    "å‰å›ç—…é™¢": h_prev,
                    "ä»Šå›æ—¥ä»˜": d_cur,
                    "ä»Šå›ç—…é™¢": h_cur,
                    "é–“éš”(æ—¥)": gap,
                })
    cols = ["æ°å", "å‰å›æ—¥ä»˜", "å‰å›ç—…é™¢", "ä»Šå›æ—¥ä»˜", "ä»Šå›ç—…é™¢", "é–“éš”(æ—¥)"]
    if not rows:
        return pd.DataFrame(columns=cols)
    return pd.DataFrame(rows)[cols].sort_values(["æ°å", "ä»Šå›æ—¥ä»˜"]).reset_index(drop=True)

def build_same_day_duplicates(doc_assignments):
    rows = []
    for doc, assigns in doc_assignments.items():
        by_date = defaultdict(list)
        for d, h in assigns:
            by_date[d].append(h)
        for d, hs in by_date.items():
            if len(hs) > 1:
                rows.append({"æ°å": doc, "æ—¥ä»˜": d, "ä»¶æ•°": len(hs), "ç—…é™¢": ", ".join(sorted(hs))})
    cols = ["æ°å", "æ—¥ä»˜", "ä»¶æ•°", "ç—…é™¢"]
    if not rows:
        return pd.DataFrame(columns=cols)
    return pd.DataFrame(rows)[cols].sort_values(["æ—¥ä»˜", "æ°å"]).reset_index(drop=True)

def build_hosp_dup_details(assigned_hosp_count):
    rows = []
    for doc, hdict in assigned_hosp_count.items():
        for hosp, c in hdict.items():
            if c > 1:
                rows.append({"æ°å": doc, "ç—…é™¢": hosp, "å›æ•°": c, "è¶…é": c - 1})
    cols = ["æ°å", "ç—…é™¢", "å›æ•°", "è¶…é"]
    if not rows:
        return pd.DataFrame(columns=cols)
    return pd.DataFrame(rows)[cols].sort_values(["è¶…é", "æ°å"], ascending=[False, True]).reset_index(drop=True)

def build_unassigned_details(unassigned):
    rows = [{"æ—¥ä»˜": d, "ç—…é™¢": hosp, "row_index": ridx} for d, hosp, ridx in unassigned]
    cols = ["æ—¥ä»˜", "ç—…é™¢", "row_index"]
    if not rows:
        return pd.DataFrame(columns=cols)
    return pd.DataFrame(rows)[cols].sort_values(["æ—¥ä»˜", "ç—…é™¢"]).reset_index(drop=True)

def build_doctor_diag(counts, bg_counts, ht_counts, wd_counts, we_counts, doc_assignments, assigned_hosp_count):
    rows = []
    active_set = set(active_doctors)

    for doc in doctor_names:
        assigns = sorted(doc_assignments.get(doc, []), key=lambda x: x[0])
        gaps = [(assigns[i][0] - assigns[i - 1][0]).days for i in range(1, len(assigns))]
        gap_viol = sum(1 for g in gaps if g < 3)
        min_gap = min(gaps) if gaps else None
        hosp_excess = sum(max(0, c - 1) for c in assigned_hosp_count.get(doc, {}).values())

        row = {
            "æ°å": doc,
            "active": 1 if doc in active_set else 0,
            "cap": TARGET_CAP.get(doc, 0),
            "preassigned": preassigned_count.get(doc, 0),

            "ä»Šæœˆ_å…¨åˆè¨ˆ": counts.get(doc, 0),
            "ç´¯è¨ˆ_å…¨åˆè¨ˆ": prev_total.get(doc, 0) + counts.get(doc, 0),

            "ä»Šæœˆ_å¤§å­¦åˆè¨ˆ": bg_counts.get(doc, 0),
            "ç´¯è¨ˆ_å¤§å­¦åˆè¨ˆ": prev_bg.get(doc, 0) + bg_counts.get(doc, 0),

            "ä»Šæœˆ_å¤–ç—…é™¢åˆè¨ˆ": ht_counts.get(doc, 0),
            "ç´¯è¨ˆ_å¤–ç—…é™¢åˆè¨ˆ": prev_ht.get(doc, 0) + ht_counts.get(doc, 0),

            "ä»Šæœˆ_å¹³æ—¥": wd_counts.get(doc, 0),
            "ç´¯è¨ˆ_å¹³æ—¥": prev_weekday.get(doc, 0) + wd_counts.get(doc, 0),

            "ä»Šæœˆ_ä¼‘æ—¥åˆè¨ˆ": we_counts.get(doc, 0),
            "ç´¯è¨ˆ_ä¼‘æ—¥åˆè¨ˆ": prev_weekend.get(doc, 0) + we_counts.get(doc, 0),

            "gapé•åå›æ•°": gap_viol,
            "æœ€å°é–“éš”(æ—¥)": min_gap if min_gap is not None else "",
            "åŒä¸€ç—…é™¢é‡è¤‡è¶…é": hosp_excess,
        }
        rows.append(row)

    df = pd.DataFrame(rows)

    # åã‚Šï¼ˆactiveå¹³å‡ã¨ã®å·®ï¼‰ã‚‚å‡ºã—ã¦ãŠã
    active_rows = df[df["active"] == 1]
    for col in ["ç´¯è¨ˆ_å…¨åˆè¨ˆ", "ç´¯è¨ˆ_å¤§å­¦åˆè¨ˆ", "ç´¯è¨ˆ_å¤–ç—…é™¢åˆè¨ˆ", "ç´¯è¨ˆ_å¹³æ—¥", "ç´¯è¨ˆ_ä¼‘æ—¥åˆè¨ˆ"]:
        if len(active_rows) > 0:
            mean_val = float(active_rows[col].mean())
            df[col + "_å¹³å‡ã¨ã®å·®"] = df[col] - mean_val
        else:
            df[col + "_å¹³å‡ã¨ã®å·®"] = 0.0

    return df.sort_values(["active", "ç´¯è¨ˆ_å…¨åˆè¨ˆ"], ascending=[False, False]).reset_index(drop=True)

def build_metrics_df(score_clamped, raw_score, metrics):
    row = {"score": float(score_clamped), "raw_score": float(raw_score), **metrics}
    return pd.DataFrame([row])

def build_hard_constraint_violations(pattern_df):
    """ãƒãƒ¼ãƒ‰åˆ¶ç´„é•åã®è©³ç´°ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ"""
    rows = []

    for ridx in pattern_df.index:
        date = pattern_df.at[ridx, date_col_shift]
        if pd.isna(date):
            continue
        date = pd.to_datetime(date).normalize().tz_localize(None)
        dow = date.weekday()

        for hosp in hospital_cols:
            val = pattern_df.at[ridx, hosp]
            if not isinstance(val, str):
                continue
            doc = normalize_name(val)
            if doc not in doctor_names:
                continue

            idx = shift_df.columns.get_loc(hosp)
            code = get_avail_code(date, doc)
            sched_code = get_sched_code(date, doc)

            # é•å1: å¯å¦ã‚³ãƒ¼ãƒ‰0 (ABS-001)
            if code == 0:
                rows.append({
                    "åˆ¶ç´„ID": CONSTRAINT_ABS_001,
                    "é•åç¨®åˆ¥": "å¯å¦ã‚³ãƒ¼ãƒ‰0é•å",
                    "æ—¥ä»˜": date,
                    "åŒ»å¸«å": doc,
                    "ç—…é™¢": hosp,
                    "åˆ—ç•ªå·": idx,
                    "å¯å¦ã‚³ãƒ¼ãƒ‰": code,
                    "ã‚«ãƒ†è¡¨": sched_code if sched_code else "",
                    "è©³ç´°": f"[{CONSTRAINT_ABS_001}] ã‚³ãƒ¼ãƒ‰0ï¼ˆä¸å¯ï¼‰ã®æ—¥ã«å‰²å½“",
                })

            # é•å2: å¯å¦ã‚³ãƒ¼ãƒ‰2é•åï¼ˆQåˆ—ã‚ˆã‚Šå¾Œã«å‰²å½“ï¼‰(ABS-002)
            if code == 2 and not (B_COL_INDEX <= idx <= Q_COL_INDEX):
                rows.append({
                    "åˆ¶ç´„ID": CONSTRAINT_ABS_002,
                    "é•åç¨®åˆ¥": "å¯å¦ã‚³ãƒ¼ãƒ‰2é•å",
                    "æ—¥ä»˜": date,
                    "åŒ»å¸«å": doc,
                    "ç—…é™¢": hosp,
                    "åˆ—ç•ªå·": idx,
                    "å¯å¦ã‚³ãƒ¼ãƒ‰": code,
                    "ã‚«ãƒ†è¡¨": sched_code if sched_code else "",
                    "è©³ç´°": f"[{CONSTRAINT_ABS_002}] ã‚³ãƒ¼ãƒ‰2ã¯Bã€œQåˆ—ã®ã¿å¯ã€‚åˆ—{idx}ã«å‰²å½“",
                })

            # é•å3: å¯å¦ã‚³ãƒ¼ãƒ‰3é•åï¼ˆLã€œYåˆ—ä»¥å¤–ã«å‰²å½“ï¼‰(ABS-003)
            if code == 3 and not (L_COL_INDEX <= idx <= L_Y_END_INDEX):
                rows.append({
                    "åˆ¶ç´„ID": CONSTRAINT_ABS_003,
                    "é•åç¨®åˆ¥": "å¯å¦ã‚³ãƒ¼ãƒ‰3é•å",
                    "æ—¥ä»˜": date,
                    "åŒ»å¸«å": doc,
                    "ç—…é™¢": hosp,
                    "åˆ—ç•ªå·": idx,
                    "å¯å¦ã‚³ãƒ¼ãƒ‰": code,
                    "ã‚«ãƒ†è¡¨": sched_code if sched_code else "",
                    "è©³ç´°": f"[{CONSTRAINT_ABS_003}] ã‚³ãƒ¼ãƒ‰3ã¯Lã€œYåˆ—ã®ã¿å¯ã€‚åˆ—{idx}ã«å‰²å½“",
                })

            # é•å4: ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ã‚ã‚Šï¼‹Lã€œYåˆ—é•å (ABS-004)
            if L_COL_INDEX <= idx <= L_Y_END_INDEX and sched_code:
                rows.append({
                    "åˆ¶ç´„ID": CONSTRAINT_ABS_004,
                    "é•åç¨®åˆ¥": "ã‚«ãƒ†è¡¨+å¤–ç—…é™¢é•å",
                    "æ—¥ä»˜": date,
                    "åŒ»å¸«å": doc,
                    "ç—…é™¢": hosp,
                    "åˆ—ç•ªå·": idx,
                    "å¯å¦ã‚³ãƒ¼ãƒ‰": code,
                    "ã‚«ãƒ†è¡¨": sched_code,
                    "è©³ç´°": f"[{CONSTRAINT_ABS_004}] ã‚«ãƒ†è¡¨ï¼ˆ{sched_code}ï¼‰ãŒã‚ã‚‹æ—¥ã¯å¤–ç—…é™¢ï¼ˆLã€œYåˆ—ï¼‰ã«å‰²å½“ä¸å¯ã€‚åˆ—{idx}ã«å‰²å½“",
                })

            # é•å5: Bã€œKåˆ—ã§ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ãªã—ï¼ˆã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ä¿æœ‰åŒ»å¸«ã®ã¿ã€EXTRAåŒ»å¸«ã¯ä¾‹å¤–ï¼‰(SEMI-001/002)
            if B_COL_INDEX <= idx <= B_K_END_INDEX and doc in SCHEDULE_CODE_HOLDERS and not sched_code and doc not in EXTRA_ALLOWED:
                # C-Håˆ—ã¯ä¼‘æ—¥å¤§å­¦ç³»(SEMI-002)ã€ãã‚Œä»¥å¤–ã¯å¹³æ—¥å¤§å­¦ç³»(SEMI-001)
                constraint_id = CONSTRAINT_SEMI_002 if C_COL_INDEX <= idx <= H_COL_INDEX else CONSTRAINT_SEMI_001
                rows.append({
                    "åˆ¶ç´„ID": constraint_id,
                    "é•åç¨®åˆ¥": "B-Kåˆ—ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰æ¬ å¦‚",
                    "æ—¥ä»˜": date,
                    "åŒ»å¸«å": doc,
                    "ç—…é™¢": hosp,
                    "åˆ—ç•ªå·": idx,
                    "å¯å¦ã‚³ãƒ¼ãƒ‰": code,
                    "ã‚«ãƒ†è¡¨": "",
                    "è©³ç´°": f"[{constraint_id}] Bã€œKåˆ—ï¼ˆå¤§å­¦ç³»ï¼‰ã®å‰²å½“ã«ã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ãŒå¿…è¦ï¼ˆã‚«ãƒ†è¡¨ã‚³ãƒ¼ãƒ‰ä¿æœ‰åŒ»å¸«ã€EXTRAåŒ»å¸«ã¯ä¾‹å¤–ï¼‰ã€‚åˆ—{idx}ã«å‰²å½“",
                })

            # é•å6: æ°´æ›œæ—¥Lã€œYåˆ—ç¦æ­¢åŒ»å¸« (ABS-006)
            if dow == 2 and L_COL_INDEX <= idx <= L_Y_END_INDEX and doc in WED_FORBIDDEN_DOCTORS:
                rows.append({
                    "åˆ¶ç´„ID": CONSTRAINT_ABS_006,
                    "é•åç¨®åˆ¥": "æ°´æ›œæ—¥Lã€œYåˆ—ç¦æ­¢é•å",
                    "æ—¥ä»˜": date,
                    "åŒ»å¸«å": doc,
                    "ç—…é™¢": hosp,
                    "åˆ—ç•ªå·": idx,
                    "å¯å¦ã‚³ãƒ¼ãƒ‰": code,
                    "ã‚«ãƒ†è¡¨": sched_code if sched_code else "",
                    "è©³ç´°": f"[{CONSTRAINT_ABS_006}] {doc}ã¯æ°´æ›œæ—¥ã®Lã€œYåˆ—ç¦æ­¢",
                })

    # Bã€œHåˆ—ã®2å›è¶…éé•åã‚’ãƒã‚§ãƒƒã‚¯
    bh_counts = defaultdict(list)
    for ridx in pattern_df.index:
        date = pattern_df.at[ridx, date_col_shift]
        if pd.isna(date):
            continue
        date = pd.to_datetime(date).normalize().tz_localize(None)

        for hosp in hospital_cols:
            val = pattern_df.at[ridx, hosp]
            if not isinstance(val, str):
                continue
            doc = normalize_name(val)
            if doc not in doctor_names:
                continue

            idx = shift_df.columns.get_loc(hosp)
            if B_H_START_INDEX <= idx <= B_H_END_INDEX:
                bh_counts[doc].append((date, hosp, idx))

    # é•å7: Bã€œHåˆ—ãŒ2å›è¶…é (SOFT-002: å¤§å­¦3å›ä»¥ä¸Š)
    for doc, assignments in bh_counts.items():
        if len(assignments) > 2:
            for date, hosp, idx in assignments[2:]:  # 3å›ç›®ä»¥é™
                code = get_avail_code(date, doc)
                sched_code = get_sched_code(date, doc)
                rows.append({
                    "åˆ¶ç´„ID": CONSTRAINT_SOFT_002,
                    "é•åç¨®åˆ¥": "B-Håˆ—2å›è¶…éé•å",
                    "æ—¥ä»˜": date,
                    "åŒ»å¸«å": doc,
                    "ç—…é™¢": hosp,
                    "åˆ—ç•ªå·": idx,
                    "å¯å¦ã‚³ãƒ¼ãƒ‰": code,
                    "ã‚«ãƒ†è¡¨": sched_code if sched_code else "",
                    "è©³ç´°": f"[{CONSTRAINT_SOFT_002}] Bã€œHåˆ—ã¯2å›ã¾ã§ã€‚{len(assignments)}å›ç›®ã®å‰²å½“",
                })

    cols = ["åˆ¶ç´„ID", "é•åç¨®åˆ¥", "æ—¥ä»˜", "åŒ»å¸«å", "ç—…é™¢", "åˆ—ç•ªå·", "å¯å¦ã‚³ãƒ¼ãƒ‰", "ã‚«ãƒ†è¡¨", "è©³ç´°"]
    if not rows:
        return pd.DataFrame(columns=cols)
    return pd.DataFrame(rows)[cols].sort_values(["åˆ¶ç´„ID", "æ—¥ä»˜", "åŒ»å¸«å"]).reset_index(drop=True)

def fix_hard_constraint_violations(pattern_df, max_attempts=50, verbose=True):
    """
    ãƒãƒ¼ãƒ‰åˆ¶ç´„é•åã‚’è‡ªå‹•ä¿®æ­£ã™ã‚‹

    Args:
        pattern_df: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«DataFrame
        max_attempts: æœ€å¤§è©¦è¡Œå›æ•°
        verbose: ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã‹

    Returns:
        (ä¿®æ­£å¾Œã®DataFrame, æˆåŠŸãƒ•ãƒ©ã‚°, ä¿®æ­£æ•°, ä¿®æ­£å¤±æ•—æ•°)
    """
    df = pattern_df.copy()
    total_fixed = 0
    total_failed = 0

    for attempt in range(max_attempts):
        violations_df = build_hard_constraint_violations(df)

        if len(violations_df) == 0:
            if verbose and total_fixed > 0:
                print(f"   âœ… ãƒãƒ¼ãƒ‰åˆ¶ç´„é•åã‚’{total_fixed}ä»¶ä¿®æ­£ã—ã¾ã—ãŸ")
            return df, True, total_fixed, total_failed

        if attempt == 0 and verbose:
            print(f"   âš ï¸ ãƒãƒ¼ãƒ‰åˆ¶ç´„é•åã‚’{len(violations_df)}ä»¶æ¤œå‡º â†’ è‡ªå‹•ä¿®æ­£ã‚’é–‹å§‹...")

        # å„é•åã‚’ä¿®æ­£è©¦è¡Œ
        fixed_in_this_iteration = 0

        for _, violation in violations_df.iterrows():
            date = violation['æ—¥ä»˜']
            doc = violation['åŒ»å¸«å']
            hosp = violation['ç—…é™¢']
            violation_type = violation['é•åç¨®åˆ¥']

            # è©²å½“è¡Œã‚’æ¢ã™
            ridx = None
            for idx in df.index:
                if pd.to_datetime(df.at[idx, date_col_shift]).normalize().tz_localize(None) == date:
                    ridx = idx
                    break

            if ridx is None:
                continue

            # é•åã—ã¦ã„ã‚‹å‰²å½“ã‚’è§£é™¤
            current_val = df.at[ridx, hosp]
            if not isinstance(current_val, str) or normalize_name(current_val) != doc:
                continue

            df.at[ridx, hosp] = None

            # ä»£æ›¿åŒ»å¸«ã‚’æ¢ã™
            col_idx = shift_df.columns.get_loc(hosp)
            dow = pd.to_datetime(date).weekday()

            # ã“ã®æ—¥ã«æ—¢ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹åŒ»å¸«ã‚’é™¤å¤–
            already_assigned_on_date = set()
            for h in hospital_cols:
                v = df.at[ridx, h]
                if isinstance(v, str):
                    already_assigned_on_date.add(normalize_name(v))

            # å€™è£œåŒ»å¸«ã‚’æ¢ã™ï¼ˆãƒãƒ¼ãƒ‰åˆ¶ç´„ã®ã¿ãƒã‚§ãƒƒã‚¯ï¼‰
            candidates = []
            for candidate_doc in doctor_names:
                # åŒæ—¥é‡è¤‡ãƒã‚§ãƒƒã‚¯
                if candidate_doc in already_assigned_on_date:
                    continue

                # ãƒãƒ¼ãƒ‰åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
                if can_assign_doc_to_slot(candidate_doc, date, hosp):
                    candidates.append(candidate_doc)

            if candidates:
                # å„ªå…ˆé †ä½ï¼šå…¨ä½“åˆè¨ˆãŒå°‘ãªã„åŒ»å¸«ã‚’å„ªå…ˆ
                candidates.sort(key=lambda d: prev_total.get(d, 0) + len([1 for h in hospital_cols for ridx2 in df.index if isinstance(df.at[ridx2, h], str) and normalize_name(df.at[ridx2, h]) == d]))
                new_doc = candidates[0]
                df.at[ridx, hosp] = new_doc
                fixed_in_this_iteration += 1
                total_fixed += 1
            else:
                # ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: çµ¶å¯¾ç¦å¿Œã‚’ã™ã¹ã¦å›é¿
                # åŒ»å¸«ã®ç¾åœ¨ã®å‰²å½“æ—¥ã‚’å–å¾—ï¼ˆgap1ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰
                def get_doc_dates(d):
                    dates = []
                    for ridx2 in df.index:
                        dt2 = df.at[ridx2, date_col_shift]
                        if pd.isna(dt2):
                            continue
                        dt2 = pd.to_datetime(dt2).normalize().tz_localize(None)
                        for h in hospital_cols:
                            v = df.at[ridx2, h]
                            if isinstance(v, str) and normalize_name(v) == d:
                                dates.append(dt2)
                    return dates

                # åŒ»å¸«ã®å¤–ç—…é™¢å‰²å½“å›æ•°ã‚’å–å¾—
                def get_doc_hosp_count(d, target_hosp):
                    count = 0
                    for ridx2 in df.index:
                        v = df.at[ridx2, target_hosp]
                        if isinstance(v, str) and normalize_name(v) == d:
                            count += 1
                    return count

                is_external = L_COL_INDEX <= col_idx <= L_Y_END_INDEX

                def is_valid_emergency(d):
                    # åŒæ—¥é‡è¤‡ç¦æ­¢
                    if d in already_assigned_on_date:
                        return False
                    # ABS-001: ã‚³ãƒ¼ãƒ‰0ç¦æ­¢
                    if get_avail_code(date, d) == 0:
                        return False
                    # gap1ç¦æ­¢
                    doc_dates = get_doc_dates(d)
                    if doc_dates:
                        min_gap = min(abs((date - dt).days) for dt in doc_dates)
                        if min_gap < 2:
                            return False
                    # å¤–ç—…é™¢é‡è¤‡ç¦æ­¢
                    if is_external and get_doc_hosp_count(d, hosp) >= 1:
                        return False
                    return True

                emergency_candidates = [d for d in doctor_names if is_valid_emergency(d)]
                if emergency_candidates:
                    # å…¨ä½“åˆè¨ˆãŒæœ€ã‚‚å°‘ãªã„åŒ»å¸«ã‚’é¸æŠ
                    emergency_candidates.sort(key=lambda d: prev_total.get(d, 0) + len([1 for h in hospital_cols for ridx2 in df.index if isinstance(df.at[ridx2, h], str) and normalize_name(df.at[ridx2, h]) == d]))
                    new_doc = emergency_candidates[0]
                    df.at[ridx, hosp] = new_doc
                    fixed_in_this_iteration += 1
                    total_fixed += 1
                    if verbose:
                        print(f"   âš ï¸ ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {date.strftime('%Y-%m-%d')} {hosp} â†’ {new_doc}")
                else:
                    # çµ¶å¯¾ç¦å¿Œã‚’æº€ãŸã™å€™è£œãŒã„ãªã„å ´åˆã¯æœªå‰²å½“ã®ã¾ã¾
                    total_failed += 1
                    if verbose:
                        print(f"   âŒ ä¿®æ­£ä¸å¯ï¼ˆçµ¶å¯¾ç¦å¿Œå›é¿ä¸å¯ï¼‰: {date.strftime('%Y-%m-%d')} {hosp}")

        # é€²æ—ãŒãªã‘ã‚Œã°ãƒ«ãƒ¼ãƒ—çµ‚äº†
        # ä¿®æ­£ãŒé€²ã¾ãªãã¦ã‚‚max_attemptsã¾ã§è©¦è¡Œã‚’ç¶šã‘ã‚‹
        # if fixed_in_this_iteration == 0:
        #     break

    # æœ€çµ‚ãƒã‚§ãƒƒã‚¯
    final_violations = build_hard_constraint_violations(df)
    success = len(final_violations) == 0

    if verbose:
        if success:
            print(f"   âœ… å…¨ã¦ã®ãƒãƒ¼ãƒ‰åˆ¶ç´„é•åã‚’ä¿®æ­£ã—ã¾ã—ãŸï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")
        else:
            print(f"   âš ï¸ {len(final_violations)}ä»¶ã®ãƒãƒ¼ãƒ‰åˆ¶ç´„é•åãŒæ®‹ã£ã¦ã„ã¾ã™ï¼ˆä¿®æ­£æ•°: {total_fixed}, å¤±æ•—: {total_failed}ï¼‰")

    return df, success, total_fixed, total_failed

def fix_target_cap_violations(pattern_df, max_attempts=100, verbose=True):
    """
    TARGET_CAPé•åã‚’ä¿®æ­£ã™ã‚‹ï¼ˆä¸Šé™è¶…éã¨BASE_TARGETæœªé”ã®ä¸¡æ–¹ï¼‰

    Args:
        pattern_df: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«DataFrame
        max_attempts: æœ€å¤§è©¦è¡Œå›æ•°
        verbose: ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã‹

    Returns:
        (ä¿®æ­£å¾Œã®DataFrame, æˆåŠŸãƒ•ãƒ©ã‚°, ä¿®æ­£æ•°)
    """
    df = pattern_df.copy()
    total_fixed = 0

    for attempt in range(max_attempts):
        # ç¾åœ¨ã®å‰²å½“å›æ•°ã‚’å†è¨ˆç®—
        counts, *_ = recompute_stats(df)

        # capè¶…éãƒ»BASE_TARGETæœªé”ã®åŒ»å¸«ã‚’ç‰¹å®š
        over_cap_docs = []  # capè¶…é
        under_base_docs = []  # BASE_TARGETæœªé”ï¼ˆæ–°è¦ï¼‰
        at_base_docs = []  # BASE_TARGETã¡ã‚‡ã†ã©
        over_base_docs = []  # BASE_TARGETè¶…éã ãŒcapä»¥ä¸‹

        for doc in active_doctors:
            current = counts.get(doc, 0)
            cap = TARGET_CAP.get(doc, 0)

            if current > cap:
                over_cap_docs.append((doc, current - cap))
            elif current < BASE_TARGET:
                under_base_docs.append((doc, BASE_TARGET - current))
            elif current == BASE_TARGET:
                at_base_docs.append(doc)
            else:  # BASE_TARGET < current <= cap
                over_base_docs.append((doc, current - BASE_TARGET))

        # é•åãŒãªã‘ã‚Œã°çµ‚äº†
        if not over_cap_docs and not under_base_docs:
            if verbose and total_fixed > 0:
                print(f"   âœ… TARGET_CAPé•åã‚’{total_fixed}ä»¶ä¿®æ­£ã—ã¾ã—ãŸ")
            return df, True, total_fixed

        if attempt == 0 and verbose:
            if over_cap_docs:
                print(f"   âš ï¸ TARGET_CAPè¶…éã‚’{len(over_cap_docs)}ä»¶æ¤œå‡º â†’ è‡ªå‹•ä¿®æ­£ã‚’é–‹å§‹...")
            if under_base_docs:
                print(f"   âš ï¸ BASE_TARGETæœªé”ã‚’{len(under_base_docs)}ä»¶æ¤œå‡º â†’ è‡ªå‹•ä¿®æ­£ã‚’é–‹å§‹...")

        # ä¿®æ­£è©¦è¡Œ
        fixed_in_this_iteration = 0

        # 1. capè¶…éã®ä¿®æ­£ï¼ˆå„ªå…ˆï¼‰
        for over_doc, excess in over_cap_docs:
            if excess <= 0:
                continue

            over_doc_positions = []
            for ridx in df.index:
                date = df.at[ridx, date_col_shift]
                if pd.isna(date):
                    continue
                date = pd.to_datetime(date).normalize().tz_localize(None)

                for hosp in hospital_cols:
                    val = df.at[ridx, hosp]
                    if isinstance(val, str) and normalize_name(val) == over_doc:
                        over_doc_positions.append((ridx, hosp, date))

            import random
            random.shuffle(over_doc_positions)

            for ridx, hosp, date in over_doc_positions[:min(excess, 3)]:
                already_assigned_on_date = set()
                for h in hospital_cols:
                    v = df.at[ridx, h]
                    if isinstance(v, str):
                        already_assigned_on_date.add(normalize_name(v))

                # BASE_TARGETæœªé”ã®åŒ»å¸«ã‚’å„ªå…ˆã€æ¬¡ã«at_base
                candidates = []
                for under_doc, deficit in under_base_docs:
                    if deficit <= 0:
                        continue
                    if under_doc in already_assigned_on_date:
                        continue
                    if can_assign_doc_to_slot(under_doc, date, hosp):
                        candidates.append((under_doc, 0))  # å„ªå…ˆåº¦0ï¼ˆæœ€å„ªå…ˆï¼‰

                for at_doc in at_base_docs:
                    if at_doc in already_assigned_on_date:
                        continue
                    if can_assign_doc_to_slot(at_doc, date, hosp):
                        if TARGET_CAP.get(at_doc, 0) > BASE_TARGET:
                            candidates.append((at_doc, 1))  # å„ªå…ˆåº¦1

                if candidates:
                    candidates.sort(key=lambda x: (x[1], prev_total.get(x[0], 0) + counts.get(x[0], 0)))
                    new_doc = candidates[0][0]

                    df.at[ridx, hosp] = new_doc
                    fixed_in_this_iteration += 1
                    total_fixed += 1

                    # ãƒªã‚¹ãƒˆã‚’æ›´æ–°
                    for i, (d, deficit) in enumerate(under_base_docs):
                        if d == new_doc:
                            under_base_docs[i] = (d, deficit - 1)
                            if deficit - 1 <= 0 and d in at_base_docs:
                                pass
                            elif deficit - 1 <= 0:
                                at_base_docs.append(d)
                            break
                    if new_doc in at_base_docs:
                        over_base_docs.append((new_doc, 1))
                    break

        # 2. BASE_TARGETæœªé”ã®ä¿®æ­£
        for under_doc, deficit in under_base_docs:
            if deficit <= 0:
                continue

            # over_baseï¼ˆBASE_TARGETè¶…éã ãŒcapä»¥ä¸‹ï¼‰ã®åŒ»å¸«ã‹ã‚‰å–ã‚‹
            donor_candidates = over_base_docs[:3]

            for donor_doc, _ in donor_candidates:
                donor_positions = []
                for ridx in df.index:
                    date = df.at[ridx, date_col_shift]
                    if pd.isna(date):
                        continue
                    date = pd.to_datetime(date).normalize().tz_localize(None)

                    for hosp in hospital_cols:
                        val = df.at[ridx, hosp]
                        if isinstance(val, str) and normalize_name(val) == donor_doc:
                            donor_positions.append((ridx, hosp, date))

                import random
                random.shuffle(donor_positions)

                for ridx, hosp, date in donor_positions[:2]:
                    already_assigned_on_date = set()
                    for h in hospital_cols:
                        v = df.at[ridx, h]
                        if isinstance(v, str):
                            already_assigned_on_date.add(normalize_name(v))

                    if under_doc in already_assigned_on_date:
                        continue
                    if not can_assign_doc_to_slot(under_doc, date, hosp):
                        continue

                    df.at[ridx, hosp] = under_doc
                    fixed_in_this_iteration += 1
                    total_fixed += 1
                    break

                if fixed_in_this_iteration > 0:
                    break

    # æœ€çµ‚ç¢ºèª
    counts, *_ = recompute_stats(df)
    remaining_over = sum(1 for doc in active_doctors if counts.get(doc, 0) > TARGET_CAP.get(doc, 0))
    remaining_under = sum(1 for doc in active_doctors if counts.get(doc, 0) < BASE_TARGET)

    if verbose:
        if remaining_over == 0 and remaining_under == 0:
            print(f"   âœ… å…¨ã¦ã®TARGET_CAPé•åã‚’ä¿®æ­£ã—ã¾ã—ãŸï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")
        else:
            if remaining_over > 0:
                print(f"   âš ï¸ {remaining_over}ä»¶ã®TARGET_CAPè¶…éé•åãŒæ®‹ã£ã¦ã„ã¾ã™ï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")
            if remaining_under > 0:
                print(f"   âš ï¸ {remaining_under}ä»¶ã®BASE_TARGETæœªé”é•åãŒæ®‹ã£ã¦ã„ã¾ã™ï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")

    return df, (remaining_over == 0 and remaining_under == 0), total_fixed

def fix_code_2_extra_violations(pattern_df, max_attempts=100, verbose=True):
    """
    å¯å¦ã‚³ãƒ¼ãƒ‰2åŒ»å¸«ã®n+1å›é•åã‚’ä¿®æ­£ã™ã‚‹ï¼ˆãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼‰
    CODE_2_DOCTORSã¯BASE_TARGETå›ã¾ã§ã—ã‹å‰²å½“ã§ããªã„

    Args:
        pattern_df: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«DataFrame
        max_attempts: æœ€å¤§è©¦è¡Œå›æ•°
        verbose: ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã‹

    Returns:
        (ä¿®æ­£å¾Œã®DataFrame, æˆåŠŸãƒ•ãƒ©ã‚°, ä¿®æ­£æ•°)
    """
    df = pattern_df.copy()
    total_fixed = 0

    for attempt in range(max_attempts):
        # ç¾åœ¨ã®å‰²å½“å›æ•°ã‚’å†è¨ˆç®—
        counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, *_ = recompute_stats(df)

        # CODE_2åŒ»å¸«ã§BASE_TARGETã‚’è¶…ãˆã¦ã„ã‚‹åŒ»å¸«ã‚’ç‰¹å®š
        code_2_over_docs = []
        for doc in CODE_2_DOCTORS:
            if doc not in active_doctors:
                continue
            current = counts.get(doc, 0)
            if current > BASE_TARGET:
                code_2_over_docs.append((doc, current - BASE_TARGET))

        # é•åãŒãªã‘ã‚Œã°çµ‚äº†
        if not code_2_over_docs:
            if verbose and total_fixed > 0:
                print(f"   âœ… å¯å¦ã‚³ãƒ¼ãƒ‰2åŒ»å¸«ã®n+1é•åã‚’{total_fixed}ä»¶ä¿®æ­£ã—ã¾ã—ãŸ")
            return df, True, total_fixed

        if attempt == 0 and verbose:
            over_docs_str = ", ".join([f"{d}({excess}å›è¶…é)" for d, excess in code_2_over_docs])
            print(f"   âš ï¸ å¯å¦ã‚³ãƒ¼ãƒ‰2åŒ»å¸«ã®n+1é•åã‚’{len(code_2_over_docs)}ä»¶æ¤œå‡º â†’ è‡ªå‹•ä¿®æ­£ã‚’é–‹å§‹...")
            print(f"      å¯¾è±¡: {over_docs_str}")

        # ä¿®æ­£è©¦è¡Œ
        fixed_in_this_iteration = 0

        for over_doc, excess in code_2_over_docs:
            if excess <= 0:
                continue

            # over_docã®å‰²å½“ä½ç½®ã‚’å–å¾—
            over_doc_positions = []
            for ridx in df.index:
                date = df.at[ridx, date_col_shift]
                if pd.isna(date):
                    continue
                date = pd.to_datetime(date).normalize().tz_localize(None)

                for hosp in hospital_cols:
                    val = df.at[ridx, hosp]
                    if isinstance(val, str) and normalize_name(val) == over_doc:
                        over_doc_positions.append((ridx, hosp, date))

            import random
            random.shuffle(over_doc_positions)

            for ridx, hosp, date in over_doc_positions[:min(excess, 3)]:
                # ãã®æ—¥ã«æ—¢ã«å‰²å½“ã•ã‚Œã¦ã„ã‚‹åŒ»å¸«
                already_assigned_on_date = set()
                for h in hospital_cols:
                    v = df.at[ridx, h]
                    if isinstance(v, str):
                        already_assigned_on_date.add(normalize_name(v))

                # ä»£æ›¿åŒ»å¸«ã‚’æ¢ã™ï¼ˆCODE_2ä»¥å¤–ã®åŒ»å¸«ã§BASE_TARGETæœªé”ã¾ãŸã¯ä½™è£•ã®ã‚ã‚‹åŒ»å¸«ï¼‰
                candidates = []
                for alt_doc in active_doctors:
                    if alt_doc == over_doc:
                        continue
                    if alt_doc in already_assigned_on_date:
                        continue
                    if alt_doc in CODE_2_DOCTORS:
                        continue  # CODE_2åŒ»å¸«ã¯ä»£æ›¿ã«ãªã‚‰ãªã„

                    alt_current = counts.get(alt_doc, 0)
                    alt_cap = TARGET_CAP.get(alt_doc, 0)

                    if alt_current >= alt_cap:
                        continue  # æ—¢ã«capåˆ°é”

                    if can_assign_doc_to_slot(alt_doc, date, hosp):
                        # å„ªå…ˆåº¦: BASE_TARGETæœªé” > ã¡ã‚‡ã†ã© > è¶…é
                        priority = 0 if alt_current < BASE_TARGET else (1 if alt_current == BASE_TARGET else 2)
                        candidates.append((alt_doc, priority))

                if candidates:
                    candidates.sort(key=lambda x: x[1])
                    new_doc = candidates[0][0]
                    df.at[ridx, hosp] = new_doc
                    counts[over_doc] = counts.get(over_doc, 0) - 1
                    counts[new_doc] = counts.get(new_doc, 0) + 1
                    total_fixed += 1
                    fixed_in_this_iteration += 1
                else:
                    # ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: çµ¶å¯¾ç¦å¿Œã‚’ã™ã¹ã¦å›é¿
                    col_idx = shift_df.columns.get_loc(hosp)
                    is_external = L_COL_INDEX <= col_idx <= L_Y_END_INDEX

                    def is_valid_emergency_target(d):
                        # åŒæ—¥é‡è¤‡ç¦æ­¢
                        if d in already_assigned_on_date:
                            return False
                        if d == over_doc:
                            return False
                        # ABS-001: ã‚³ãƒ¼ãƒ‰0ç¦æ­¢
                        if get_avail_code(date, d) == 0:
                            return False
                        # gap1ç¦æ­¢
                        doc_dates = sorted([dt for dt, _ in doc_assignments.get(d, [])])
                        if doc_dates:
                            min_gap = min(abs((date - dt).days) for dt in doc_dates)
                            if min_gap < 2:
                                return False
                        # å¤–ç—…é™¢é‡è¤‡ç¦æ­¢
                        if is_external and assigned_hosp_count.get(d, {}).get(hosp, 0) >= 1:
                            return False
                        return True

                    emergency = [d for d in doctor_names if is_valid_emergency_target(d)]
                    if emergency:
                        emergency.sort(key=lambda d: counts.get(d, 0))
                        new_doc = emergency[0]
                        df.at[ridx, hosp] = new_doc
                        counts[over_doc] = counts.get(over_doc, 0) - 1
                        counts[new_doc] = counts.get(new_doc, 0) + 1
                        total_fixed += 1
                        fixed_in_this_iteration += 1
                        if verbose:
                            print(f"      âš ï¸ {over_doc}â†’{new_doc}(ç·Šæ€¥): {date.strftime('%m/%d')} {hosp}")
                    else:
                        # æœ€çµ‚æ‰‹æ®µ: å…ƒã®åŒ»å¸«ã‚’ç¶­æŒï¼ˆå‰Šé™¤ã—ãªã„ï¼‰
                        if verbose:
                            print(f"      âš ï¸ {over_doc}ã®{date.strftime('%m/%d')} {hosp}ã‚’ç¶­æŒï¼ˆçµ¶å¯¾ç¦å¿Œå›é¿ä¸å¯ï¼‰")

        if fixed_in_this_iteration == 0:
            break

    # æœ€çµ‚çŠ¶æ…‹ã‚’ç¢ºèª
    counts, *_ = recompute_stats(df)
    remaining = sum(1 for doc in CODE_2_DOCTORS if doc in active_doctors and counts.get(doc, 0) > BASE_TARGET)

    if verbose:
        if remaining == 0:
            if total_fixed > 0:
                print(f"   âœ… å…¨ã¦ã®å¯å¦ã‚³ãƒ¼ãƒ‰2åŒ»å¸«ã®n+1é•åã‚’ä¿®æ­£ã—ã¾ã—ãŸï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")
        else:
            print(f"   âš ï¸ {remaining}ä»¶ã®å¯å¦ã‚³ãƒ¼ãƒ‰2åŒ»å¸«ã®n+1é•åãŒæ®‹ã£ã¦ã„ã¾ã™ï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")

    return df, (remaining == 0), total_fixed

def fix_university_minimum_requirement(pattern_df, max_attempts=100, verbose=True):
    """
    å¤§å­¦ç³»æœ€ä½1å›å¿…é ˆé•åã‚’ä¿®æ­£ã™ã‚‹ï¼ˆæº–ãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼šã‚³ãƒ¼ãƒ‰3ä»¥å¤–ã®å…¨åŒ»å¸«ï¼‰

    Args:
        pattern_df: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«DataFrame
        max_attempts: æœ€å¤§è©¦è¡Œå›æ•°
        verbose: ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã‹

    Returns:
        (ä¿®æ­£å¾Œã®DataFrame, æˆåŠŸãƒ•ãƒ©ã‚°, ä¿®æ­£æ•°)
    """
    if not UNIVERSITY_MINIMUM_REQUIRED_DOCTORS:
        return pattern_df, True, 0

    df = pattern_df.copy()
    total_fixed = 0

    for attempt in range(max_attempts):
        # ç¾åœ¨ã®å‰²å½“å›æ•°ã‚’å†è¨ˆç®—
        counts, bg_counts, *_ = recompute_stats(df)

        # å¤§å­¦ç³»0å›ã®åŒ»å¸«ã‚’ç‰¹å®šï¼ˆã‚³ãƒ¼ãƒ‰3é™¤å¤–ï¼‰
        zero_bg_docs = []
        for doc in UNIVERSITY_MINIMUM_REQUIRED_DOCTORS:
            if bg_counts.get(doc, 0) == 0:
                zero_bg_docs.append(doc)

        if not zero_bg_docs:
            if verbose and total_fixed > 0:
                print(f"   âœ… å¤§å­¦ç³»æœ€ä½1å›å¿…é ˆé•åã‚’{total_fixed}ä»¶ä¿®æ­£ã—ã¾ã—ãŸ")
            return df, True, total_fixed

        if attempt == 0 and verbose:
            print(f"   âš ï¸ å¤§å­¦ç³»æœ€ä½1å›å¿…é ˆé•åã‚’{len(zero_bg_docs)}ä»¶æ¤œå‡º â†’ è‡ªå‹•ä¿®æ­£ã‚’é–‹å§‹...")

        # ä¿®æ­£è©¦è¡Œ
        fixed_in_this_iteration = 0

        for zero_doc in zero_bg_docs:
            # ã“ã®zero_docã®å¤–ç—…é™¢ï¼ˆLã€œYï¼‰å‰²å½“ã‚’æ¢ã™
            zero_doc_ly_positions = []
            for ridx in df.index:
                date = df.at[ridx, date_col_shift]
                if pd.isna(date):
                    continue
                date = pd.to_datetime(date).normalize().tz_localize(None)

                for hosp in hospital_cols:
                    idx = shift_df.columns.get_loc(hosp)
                    # Lã€œYåˆ—ï¼ˆå¤–ç—…é™¢ï¼‰ã®ã¿
                    if L_COL_INDEX <= idx <= L_Y_END_INDEX:
                        val = df.at[ridx, hosp]
                        if isinstance(val, str) and normalize_name(val) == zero_doc:
                            zero_doc_ly_positions.append((ridx, hosp, date))

            # å¤–ç—…é™¢ã®å‰²å½“ã‚’1ã¤å¤§å­¦ç³»ã«å¤‰æ›´
            import random
            random.shuffle(zero_doc_ly_positions)

            for ridx, hosp, date in zero_doc_ly_positions[:1]:  # 1ã¤ã ã‘è©¦è¡Œ
                # ã“ã®æ—¥ä»˜ã®Bã€œKåˆ—ï¼ˆå¤§å­¦ç³»ï¼‰ã§ç©ºã„ã¦ã„ã‚‹æ ã‚’æ¢ã™
                for bg_hosp in hospital_cols:
                    bg_idx = shift_df.columns.get_loc(bg_hosp)
                    if not (B_COL_INDEX <= bg_idx <= B_K_END_INDEX):
                        continue

                    val = df.at[ridx, bg_hosp]
                    # ç©ºãæ ã‹ã©ã†ã‹
                    if not is_slot_value(shift_df.at[ridx, bg_hosp]):
                        continue
                    if isinstance(val, str) and val in doctor_names:
                        continue  # æ—¢ã«å‰²å½“æ¸ˆã¿

                    # ã“ã®æ—¥ã«zero_docãŒæ—¢ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
                    already_assigned = False
                    for h in hospital_cols:
                        v = df.at[ridx, h]
                        if isinstance(v, str) and normalize_name(v) == zero_doc and h != hosp:
                            already_assigned = True
                            break

                    if already_assigned:
                        continue

                    # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
                    if can_assign_doc_to_slot(zero_doc, date, bg_hosp):
                        # å¤–ç—…é™¢ã‹ã‚‰å‰Šé™¤ã€å¤§å­¦ç³»ã«è¿½åŠ 
                        df.at[ridx, hosp] = None  # å¤–ç—…é™¢ã‚’è§£é™¤
                        df.at[ridx, bg_hosp] = zero_doc  # å¤§å­¦ç³»ã«å‰²å½“
                        fixed_in_this_iteration += 1
                        total_fixed += 1
                        break  # æ¬¡ã®zero_docã¸

                if fixed_in_this_iteration > 0:
                    break  # æ¬¡ã®zero_docã¸

        # ä¿®æ­£ãŒé€²ã¾ãªãã¦ã‚‚max_attemptsã¾ã§è©¦è¡Œã‚’ç¶šã‘ã‚‹
        # if fixed_in_this_iteration == 0:
        #     break

    # æœ€çµ‚ç¢ºèª
    counts, bg_counts, *_ = recompute_stats(df)
    remaining_violations = sum(1 for doc in UNIVERSITY_MINIMUM_REQUIRED_DOCTORS if bg_counts.get(doc, 0) == 0)

    if verbose:
        if remaining_violations == 0:
            print(f"   âœ… å…¨ã¦ã®å¤§å­¦ç³»æœ€ä½1å›å¿…é ˆé•åã‚’ä¿®æ­£ã—ã¾ã—ãŸï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")
        else:
            print(f"   âš ï¸ {remaining_violations}ä»¶ã®å¤§å­¦ç³»æœ€ä½1å›å¿…é ˆé•åãŒæ®‹ã£ã¦ã„ã¾ã™ï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")

    return df, remaining_violations == 0, total_fixed

# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€æ—§é–¢æ•°åã‚’æ®‹ã™
def fix_code_1_2_violations(pattern_df, max_attempts=100, verbose=True):
    """å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°ï¼ˆfix_university_minimum_requirementã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆï¼‰"""
    return fix_university_minimum_requirement(pattern_df, max_attempts, verbose)

def fix_ch_kate_violations(pattern_df, max_attempts=100, verbose=True):
    """
    C-Håˆ—ï¼ˆä¼‘æ—¥å¤§å­¦ç³»ï¼‰ã®ã‚«ãƒ†å½“ç•ªé•åã‚’ä¿®æ­£ã™ã‚‹

    æ¡ä»¶ï¼šC-Håˆ—ã¯ã‚«ãƒ†å½“ç•ªã‚ã‚Šã®æ—¥ OR ã‚«ãƒ†å½“ç•ªãªã—åŒ»å¸«ã®ã¿
    ã‚«ãƒ†å½“ç•ªä¿æœ‰åŒ»å¸«ãŒãã®æ—¥ã«ã‚«ãƒ†å½“ç•ªãªã—ã§C-Håˆ—ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã€
    é©æ ¼ãªåŒ»å¸«ã¨äº¤æ›ã™ã‚‹

    Args:
        pattern_df: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«DataFrame
        max_attempts: æœ€å¤§è©¦è¡Œå›æ•°
        verbose: ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã‹

    Returns:
        (ä¿®æ­£å¾Œã®DataFrame, æˆåŠŸãƒ•ãƒ©ã‚°, ä¿®æ­£æ•°)
    """
    df = pattern_df.copy()
    total_fixed = 0

    for attempt in range(max_attempts):
        # C-Håˆ—ã®é•åã‚’æ¤œå‡º
        violations = []
        for ridx in df.index:
            date = df.at[ridx, date_col_shift]
            if pd.isna(date):
                continue
            date = pd.to_datetime(date).normalize().tz_localize(None)
            for hosp in hospital_cols:
                idx = shift_df.columns.get_loc(hosp)
                if not is_ch_slot(idx):
                    continue
                val = df.at[ridx, hosp]
                if not isinstance(val, str):
                    continue
                doc = normalize_name(val)
                if doc not in doctor_names:
                    continue
                if not is_eligible_for_ch_slot(doc, date):
                    violations.append({
                        "ridx": ridx,
                        "hosp": hosp,
                        "date": date,
                        "doc": doc,
                        "idx": idx
                    })

        if not violations:
            break

        # æœ€åˆã®é•åã‚’ä¿®æ­£
        viol = violations[0]
        ridx, hosp, date, bad_doc, col_idx = viol["ridx"], viol["hosp"], viol["date"], viol["doc"], viol["idx"]

        # 1. C-Håˆ—ã«é©æ ¼ãªåŒ»å¸«ã‚’æ¢ã™
        # é©æ ¼æ¡ä»¶: is_eligible_for_ch_slot(doc, date) = True
        # å€™è£œï¼šç¾åœ¨é•åãŒãªã„ã‚¹ãƒ­ãƒƒãƒˆã«ã„ã‚‹é©æ ¼åŒ»å¸«
        swap_done = False

        # åŒã˜æ—¥ã®ä»–ã®ã‚¹ãƒ­ãƒƒãƒˆï¼ˆC-Hä»¥å¤–ï¼‰ã§é©æ ¼ãªåŒ»å¸«ã‚’æ¢ã—ã¦äº¤æ›
        for other_hosp in hospital_cols:
            if swap_done:
                break
            other_idx = shift_df.columns.get_loc(other_hosp)
            # C-Håˆ—ä»¥å¤–ã®ã‚¹ãƒ­ãƒƒãƒˆã‚’æ¢ã™ï¼ˆL-Yåˆ—ãªã©ï¼‰
            if is_ch_slot(other_idx):
                continue
            other_val = df.at[ridx, other_hosp]
            if not isinstance(other_val, str):
                continue
            other_doc = normalize_name(other_val)
            if other_doc not in doctor_names:
                continue
            # other_docãŒC-Håˆ—ã«é©æ ¼ã‹ãƒã‚§ãƒƒã‚¯
            if not is_eligible_for_ch_slot(other_doc, date):
                continue
            # other_docãŒhospï¼ˆC-Håˆ—ï¼‰ã«å‰²ã‚Šå½“ã¦å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆABS-001å«ã‚€ï¼‰
            if not can_assign_doc_to_slot(other_doc, date, hosp):
                continue
            # bad_docãŒother_hospã«å‰²ã‚Šå½“ã¦å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
            if not can_assign_doc_to_slot(bad_doc, date, other_hosp):
                continue
            # äº¤æ›
            df.at[ridx, hosp] = other_doc
            df.at[ridx, other_hosp] = bad_doc
            total_fixed += 1
            swap_done = True
            if verbose:
                print(f"   [C-Hã‚«ãƒ†å½“ç•ªä¿®æ­£] {date.strftime('%Y-%m-%d')} {hosp}åˆ—: {bad_doc} â‡” {other_doc}")

        if swap_done:
            continue

        # 2. åˆ¥ã®æ—¥ã®é©æ ¼åŒ»å¸«ã¨äº¤æ›ã‚’è©¦ã¿ã‚‹
        for other_ridx in df.index:
            if swap_done:
                break
            other_date = df.at[other_ridx, date_col_shift]
            if pd.isna(other_date):
                continue
            other_date = pd.to_datetime(other_date).normalize().tz_localize(None)
            if other_date == date:
                continue

            for other_hosp in hospital_cols:
                if swap_done:
                    break
                other_idx = shift_df.columns.get_loc(other_hosp)
                # C-Håˆ—ä»¥å¤–ã®ã‚¹ãƒ­ãƒƒãƒˆ
                if is_ch_slot(other_idx):
                    continue
                other_val = df.at[other_ridx, other_hosp]
                if not isinstance(other_val, str):
                    continue
                other_doc = normalize_name(other_val)
                if other_doc not in doctor_names:
                    continue
                # other_docãŒC-Håˆ—ã«é©æ ¼ã‹ãƒã‚§ãƒƒã‚¯
                if not is_eligible_for_ch_slot(other_doc, date):
                    continue
                # bad_docãŒother_hospã«å‰²ã‚Šå½“ã¦å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                if not can_assign_doc_to_slot(bad_doc, other_date, other_hosp):
                    continue
                # other_docãŒdate, hospã«å‰²ã‚Šå½“ã¦å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                if not can_assign_doc_to_slot(other_doc, date, hosp):
                    continue
                # äº¤æ›
                df.at[ridx, hosp] = other_doc
                df.at[other_ridx, other_hosp] = bad_doc
                total_fixed += 1
                swap_done = True
                if verbose:
                    print(f"   [C-Hã‚«ãƒ†å½“ç•ªä¿®æ­£] {date.strftime('%Y-%m-%d')} {hosp}åˆ—: {bad_doc} â†’ {other_doc}")

        if not swap_done:
            # äº¤æ›ã§ããªã‹ã£ãŸå ´åˆã€æ¬¡ã®é•åã‚’è©¦ã™
            if verbose and attempt == 0:
                print(f"   âš ï¸ C-Håˆ—ã‚«ãƒ†å½“ç•ªé•åã‚’ä¿®æ­£ã§ãã¾ã›ã‚“: {date.strftime('%Y-%m-%d')} {hosp}åˆ— {bad_doc}")
            break

    # æ®‹ã‚Šé•åã‚’å†è¨ˆç®—
    remaining_violations = 0
    for ridx in df.index:
        date = df.at[ridx, date_col_shift]
        if pd.isna(date):
            continue
        date = pd.to_datetime(date).normalize().tz_localize(None)
        for hosp in hospital_cols:
            idx = shift_df.columns.get_loc(hosp)
            if not is_ch_slot(idx):
                continue
            val = df.at[ridx, hosp]
            if not isinstance(val, str):
                continue
            doc = normalize_name(val)
            if doc not in doctor_names:
                continue
            if not is_eligible_for_ch_slot(doc, date):
                remaining_violations += 1

    if verbose:
        if remaining_violations == 0:
            print(f"   âœ… å…¨ã¦ã®C-Håˆ—ã‚«ãƒ†å½“ç•ªé•åã‚’ä¿®æ­£ã—ã¾ã—ãŸï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")
        else:
            print(f"   âš ï¸ {remaining_violations}ä»¶ã®C-Håˆ—ã‚«ãƒ†å½“ç•ªé•åãŒæ®‹ã£ã¦ã„ã¾ã™ï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")

    return df, remaining_violations == 0, total_fixed

def fix_bg_ht_imbalance_violations(pattern_df, max_attempts=100, verbose=True):
    """
    å¤§å­¦ç³»ã¨å¤–ç—…é™¢ã®å·®ãŒ3ä»¥ä¸Šã®é•åã‚’ä¿®æ­£ã™ã‚‹

    Args:
        pattern_df: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«DataFrame
        max_attempts: æœ€å¤§è©¦è¡Œå›æ•°
        verbose: ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã‹

    Returns:
        (ä¿®æ­£å¾Œã®DataFrame, æˆåŠŸãƒ•ãƒ©ã‚°, ä¿®æ­£æ•°)
    """
    df = pattern_df.copy()
    total_fixed = 0

    for attempt in range(max_attempts):
        # ç¾åœ¨ã®å‰²å½“å›æ•°ã‚’å†è¨ˆç®—
        counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, cc_counts, cc_bg_counts, cc_ht_counts = recompute_stats(df)

        # å¤§å­¦ç³»ã¨å¤–ç—…é™¢ã®å·®ãŒ3ä»¥ä¸Šã®åŒ»å¸«ã‚’ç‰¹å®šï¼ˆCCé™¤å¤–ï¼‰
        imbalance_docs = []
        for doc in active_doctors:
            # CCã¯å¤§å‹é€£ä¼‘ç‰¹åˆ¥ã‚·ãƒ•ãƒˆãªã®ã§ãƒãƒ©ãƒ³ã‚¹è¨ˆç®—ã‹ã‚‰é™¤å¤–
            bg = bg_counts.get(doc, 0) - cc_bg_counts.get(doc, 0)
            ht = ht_counts.get(doc, 0) - cc_ht_counts.get(doc, 0)
            diff = abs(bg - ht)
            if diff >= 3:
                imbalance_docs.append((doc, bg, ht, diff))

        if not imbalance_docs:
            if verbose and total_fixed > 0:
                print(f"   âœ… å¤§å­¦ç³»ã¨å¤–ç—…é™¢ã®å·®3ä»¥ä¸Šã®é•åã‚’{total_fixed}ä»¶ä¿®æ­£ã—ã¾ã—ãŸ")
            return df, True, total_fixed

        if attempt == 0 and verbose:
            print(f"   âš ï¸ å¤§å­¦ç³»ã¨å¤–ç—…é™¢ã®å·®3ä»¥ä¸Šã®é•åã‚’{len(imbalance_docs)}ä»¶æ¤œå‡º â†’ è‡ªå‹•ä¿®æ­£ã‚’é–‹å§‹...")

        # ä¿®æ­£è©¦è¡Œ
        fixed_in_this_iteration = 0

        for doc, bg, ht, diff in imbalance_docs:
            if diff < 3:
                continue

            # BGãŒå¤šã„å ´åˆ: BGâ†’HTã«ç§»å‹•
            # HTãŒå¤šã„å ´åˆ: HTâ†’BGã«ç§»å‹•
            if bg > ht:
                # BGã®å‰²å½“ã‚’1ã¤HTã«å¤‰æ›´
                source_range = (B_COL_INDEX, B_K_END_INDEX)
                target_range = (L_COL_INDEX, L_Y_END_INDEX)
            else:
                # HTã®å‰²å½“ã‚’1ã¤BGã«å¤‰æ›´
                source_range = (L_COL_INDEX, L_Y_END_INDEX)
                target_range = (B_COL_INDEX, B_K_END_INDEX)

            # sourceç¯„å›²ã®å‰²å½“ã‚’æ¢ã™
            source_positions = []
            for ridx in df.index:
                date = df.at[ridx, date_col_shift]
                if pd.isna(date):
                    continue
                date = pd.to_datetime(date).normalize().tz_localize(None)

                for hosp in hospital_cols:
                    idx = shift_df.columns.get_loc(hosp)
                    if source_range[0] <= idx <= source_range[1]:
                        val = df.at[ridx, hosp]
                        if isinstance(val, str) and normalize_name(val) == doc:
                            source_positions.append((ridx, hosp, date))

            # 1ã¤ç§»å‹•ã‚’è©¦ã¿ã‚‹
            import random
            random.shuffle(source_positions)

            for ridx, hosp, date in source_positions[:1]:
                # targetç¯„å›²ã§ç©ºã„ã¦ã„ã‚‹æ ã‚’æ¢ã™
                for target_hosp in hospital_cols:
                    target_idx = shift_df.columns.get_loc(target_hosp)
                    if not (target_range[0] <= target_idx <= target_range[1]):
                        continue

                    val = df.at[ridx, target_hosp]
                    # ç©ºãæ ã‹ã©ã†ã‹
                    if not is_slot_value(shift_df.at[ridx, target_hosp]):
                        continue
                    if isinstance(val, str) and val in doctor_names:
                        continue  # æ—¢ã«å‰²å½“æ¸ˆã¿

                    # ã“ã®æ—¥ã«docãŒæ—¢ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
                    already_assigned = False
                    for h in hospital_cols:
                        v = df.at[ridx, h]
                        if isinstance(v, str) and normalize_name(v) == doc and h != hosp:
                            already_assigned = True
                            break

                    if already_assigned:
                        continue

                    # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
                    if can_assign_doc_to_slot(doc, date, target_hosp):
                        # sourceã‹ã‚‰å‰Šé™¤ã€targetã«è¿½åŠ 
                        df.at[ridx, hosp] = None
                        df.at[ridx, target_hosp] = doc
                        fixed_in_this_iteration += 1
                        total_fixed += 1
                        break  # æ¬¡ã®docã¸

                if fixed_in_this_iteration > 0:
                    break  # æ¬¡ã®docã¸

        # ä¿®æ­£ãŒé€²ã¾ãªãã¦ã‚‚max_attemptsã¾ã§è©¦è¡Œã‚’ç¶šã‘ã‚‹
        # if fixed_in_this_iteration == 0:
        #     break

    # æœ€çµ‚ç¢ºèª
    counts, bg_counts, ht_counts, *_ = recompute_stats(df)
    remaining_violations = sum(1 for doc in active_doctors if abs(bg_counts.get(doc, 0) - ht_counts.get(doc, 0)) >= 3)

    if verbose:
        if remaining_violations == 0:
            print(f"   âœ… å…¨ã¦ã®å¤§å­¦ç³»ã¨å¤–ç—…é™¢ã®å·®3ä»¥ä¸Šã®é•åã‚’ä¿®æ­£ã—ã¾ã—ãŸï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")
        else:
            print(f"   âš ï¸ {remaining_violations}ä»¶ã®å¤§å­¦ç³»ã¨å¤–ç—…é™¢ã®å·®3ä»¥ä¸Šã®é•åãŒæ®‹ã£ã¦ã„ã¾ã™ï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")

    return df, remaining_violations == 0, total_fixed

def fix_gap_violations(pattern_df, max_attempts=200, verbose=True):
    """
    gapé•åï¼ˆ3æ—¥æœªæº€ã®é–“éš”ã§ã®å‰²å½“ï¼‰ã‚’ä¿®æ­£ã™ã‚‹

    Args:
        pattern_df: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«DataFrame
        max_attempts: æœ€å¤§è©¦è¡Œå›æ•°
        verbose: ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã‹

    Returns:
        (ä¿®æ­£å¾Œã®DataFrame, æˆåŠŸãƒ•ãƒ©ã‚°, ä¿®æ­£æ•°)
    """
    df = pattern_df.copy()
    total_fixed = 0
    consecutive_failures = 0

    for attempt in range(max_attempts):
        # ç¾åœ¨ã®å‰²å½“çŠ¶æ…‹ã‚’å†è¨ˆç®—
        counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, *_ = recompute_stats(df)

        # gapé•åã‚’æ¤œå‡º
        gap_violation_list = []
        for doc, date_hosp_list in doc_assignments.items():
            dates = sorted([d for d, h in date_hosp_list])
            for i in range(1, len(dates)):
                gap = (dates[i] - dates[i-1]).days
                if gap < 3:
                    gap_violation_list.append((doc, dates[i-1], dates[i], gap))

        if not gap_violation_list:
            if verbose and total_fixed > 0:
                print(f"   âœ… gapé•åï¼ˆ3æ—¥æœªæº€ã®é–“éš”ï¼‰ã‚’{total_fixed}ä»¶ä¿®æ­£ã—ã¾ã—ãŸ")
            return df, True, total_fixed

        if attempt == 0 and verbose:
            print(f"   âš ï¸ gapé•åã‚’{len(gap_violation_list)}ä»¶æ¤œå‡º â†’ è‡ªå‹•ä¿®æ­£ã‚’é–‹å§‹...")

        # ä¿®æ­£è©¦è¡Œï¼ˆ1ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§è¤‡æ•°ã®é•åã‚’ä¿®æ­£ï¼‰
        fixed_in_this_iteration = 0

        for doc, date1, date2, gap in gap_violation_list:
            if gap >= 3:
                continue

            # date2ã®å‰²å½“ã‚’æ¢ã™
            positions_at_date2 = []
            for ridx in df.index:
                date = df.at[ridx, date_col_shift]
                if pd.isna(date):
                    continue
                date = pd.to_datetime(date).normalize().tz_localize(None)
                if date != date2:
                    continue

                for hosp in hospital_cols:
                    val = df.at[ridx, hosp]
                    if isinstance(val, str) and normalize_name(val) == doc:
                        positions_at_date2.append((ridx, hosp, date))

            # å„positionã«å¯¾ã—ã¦ä¿®æ­£ã‚’è©¦ã¿ã‚‹
            for ridx_src, hosp_src, date_src in positions_at_date2:
                moved = False

                # ç§»å‹•å…ˆå€™è£œã‚’æ¢ã™
                for ridx_tgt in df.index:
                    date_tgt = df.at[ridx_tgt, date_col_shift]
                    if pd.isna(date_tgt):
                        continue
                    date_tgt = pd.to_datetime(date_tgt).normalize().tz_localize(None)

                    # date1ã¨date_tgtã®é–“éš”ã‚’ãƒã‚§ãƒƒã‚¯
                    gap_from_date1 = abs((date_tgt - date1).days)
                    if gap_from_date1 < 4:
                        continue

                    # docã®ä»–ã®å‰²å½“ã¨date_tgtã®é–“éš”ã‚’ãƒã‚§ãƒƒã‚¯
                    doc_dates = sorted([d for d, h in doc_assignments[doc]])
                    doc_dates_without_date2 = [d for d in doc_dates if d != date2]

                    valid_gap = True
                    for existing_date in doc_dates_without_date2:
                        if abs((date_tgt - existing_date).days) < 4:
                            valid_gap = False
                            break

                    if not valid_gap:
                        continue

                    # ãã®æ—¥ã«docãŒæ—¢ã«å‰²å½“ã‚‰ã‚Œã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
                    already_assigned = False
                    for hosp_check in hospital_cols:
                        val = df.at[ridx_tgt, hosp_check]
                        if isinstance(val, str) and normalize_name(val) == doc:
                            already_assigned = True
                            break

                    if already_assigned:
                        continue

                    # å…¨ã¦ã®ç—…é™¢ã§ç©ºãæ ã‚’æ¢ã™
                    hospitals_to_try = [hosp_src] + [h for h in hospital_cols if h != hosp_src]
                    for hosp_tgt in hospitals_to_try:
                        if pd.isna(df.at[ridx_tgt, hosp_tgt]):
                            # ãƒãƒ¼ãƒ‰åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
                            if not can_assign_doc_to_slot(doc, date_tgt, hosp_tgt):
                                continue

                            # ç§»å‹•å®Ÿè¡Œ
                            df.at[ridx_src, hosp_src] = None
                            df.at[ridx_tgt, hosp_tgt] = doc
                            fixed_in_this_iteration += 1
                            total_fixed += 1
                            moved = True
                            break

                    if moved:
                        break

                # ç§»å‹•å…ˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å‰Šé™¤ï¼ˆç©æ¥µçš„ã«å®Ÿè¡Œï¼‰
                if not moved and attempt >= 5:  # 5å›ç›®ä»¥é™ã¯å‰Šé™¤ã‚‚æ¤œè¨
                    df.at[ridx_src, hosp_src] = None
                    fixed_in_this_iteration += 1
                    total_fixed += 1
                    if verbose and attempt < 10:
                        print(f"      ç§»å‹•å…ˆãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€{doc}ã®{date_src.strftime('%m/%d')}ã®å‰²å½“ã‚’å‰Šé™¤ã—ã¾ã™")
                    break  # ã“ã®é•åã®ä»–ã®positionã¯è©¦ã•ãªã„

            # ã“ã®é•åã‚’ä¿®æ­£ã—ãŸã‚‰ã€doc_assignmentsã‚’æ›´æ–°
            if fixed_in_this_iteration > 0:
                counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, *_ = recompute_stats(df)

        # é€²æ—ãƒã‚§ãƒƒã‚¯
        if fixed_in_this_iteration == 0:
            consecutive_failures += 1
        else:
            consecutive_failures = 0

        # é€£ç¶šã§20å›ä¿®æ­£ã§ããªã‘ã‚Œã°è«¦ã‚ã‚‹
        if consecutive_failures >= 20:
            break

    # æœ€çµ‚ç¢ºèª
    counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, *_ = recompute_stats(df)
    remaining_violations = 0
    for doc, date_hosp_list in doc_assignments.items():
        dates = sorted([d for d, h in date_hosp_list])
        for i in range(1, len(dates)):
            if (dates[i] - dates[i-1]).days < 3:
                remaining_violations += 1

    if verbose:
        if remaining_violations == 0:
            print(f"   âœ… å…¨ã¦ã®gapé•åã‚’ä¿®æ­£ã—ã¾ã—ãŸï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")
        else:
            print(f"   âš ï¸ {remaining_violations}ä»¶ã®gapé•åãŒæ®‹ã£ã¦ã„ã¾ã™ï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")

    return df, remaining_violations == 0, total_fixed

def fix_external_hospital_dup_violations(pattern_df, max_attempts=150, verbose=True):
    """
    å¤–ç—…é™¢ï¼ˆLï½Yåˆ—ï¼‰ã®é‡è¤‡ã‚’ä¿®æ­£ã™ã‚‹ï¼ˆå¤§å­¦ç—…é™¢ã®é‡è¤‡ã¯è¨±å®¹ï¼‰

    Args:
        pattern_df: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«DataFrame
        max_attempts: æœ€å¤§è©¦è¡Œå›æ•°
        verbose: ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã‹

    Returns:
        (ä¿®æ­£å¾Œã®DataFrame, æˆåŠŸãƒ•ãƒ©ã‚°, ä¿®æ­£æ•°)
    """
    df = pattern_df.copy()
    total_fixed = 0
    consecutive_failures = 0

    for attempt in range(max_attempts):
        # ç¾åœ¨ã®å‰²å½“çŠ¶æ…‹ã‚’å†è¨ˆç®—
        counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, cc_counts, cc_bg_counts, cc_ht_counts = recompute_stats(df)

        # CCåˆ†ã®ç—…é™¢åˆ¥ã‚«ã‚¦ãƒ³ãƒˆã‚’è¨ˆç®—ï¼ˆé‡è¤‡æ¤œå‡ºã‹ã‚‰é™¤å¤–ç”¨ï¼‰
        cc_hosp_counts = {d: defaultdict(int) for d in doctor_names}
        for ridx in df.index:
            date = df.at[ridx, date_col_shift]
            if pd.isna(date):
                continue
            date = pd.to_datetime(date).normalize().tz_localize(None)
            for hosp in hospital_cols:
                val = df.at[ridx, hosp]
                if isinstance(val, str):
                    doc = normalize_name(val)
                    if doc in doctor_names and is_cc_assignment(date, doc):
                        cc_hosp_counts[doc][hosp] += 1

        # å¤–ç—…é™¢é‡è¤‡ã‚’æ¤œå‡ºï¼ˆCCé™¤å¤–ï¼‰
        external_dup_list = []
        for doc, hosp_dict in assigned_hosp_count.items():
            for hosp, count in hosp_dict.items():
                # CCåˆ†ã‚’é™¤å¤–
                count_no_cc = count - cc_hosp_counts.get(doc, {}).get(hosp, 0)
                if count_no_cc > 1:
                    # å¤–ç—…é™¢ã‹ã©ã†ã‹ã‚’åˆ¤å®š
                    hidx = shift_df.columns.get_loc(hosp)
                    if L_COL_INDEX <= hidx <= L_Y_END_INDEX:
                        external_dup_list.append((doc, hosp, count_no_cc))

        if not external_dup_list:
            if verbose and total_fixed > 0:
                print(f"   âœ… å¤–ç—…é™¢é‡è¤‡ã‚’{total_fixed}ä»¶ä¿®æ­£ã—ã¾ã—ãŸ")
            return df, True, total_fixed

        if attempt == 0 and verbose:
            print(f"   âš ï¸ å¤–ç—…é™¢é‡è¤‡ã‚’{len(external_dup_list)}ä»¶æ¤œå‡º â†’ è‡ªå‹•ä¿®æ­£ã‚’é–‹å§‹...")

        # ä¿®æ­£è©¦è¡Œ
        fixed_in_this_iteration = 0

        for doc, dup_hosp, count in external_dup_list:
            if count <= 1:
                continue

            # ã“ã®åŒ»å¸«ã®ã“ã®ç—…é™¢ã¸ã®å‰²å½“ã‚’æ¢ã™
            dup_positions = []
            for ridx in df.index:
                date = df.at[ridx, date_col_shift]
                if pd.isna(date):
                    continue
                date = pd.to_datetime(date).normalize().tz_localize(None)

                val = df.at[ridx, dup_hosp]
                if isinstance(val, str) and normalize_name(val) == doc:
                    dup_positions.append((ridx, dup_hosp, date))

            # é‡è¤‡ã®ã†ã¡1ã¤ã‚’æ®‹ã—ã¦ã€æ®‹ã‚Šã‚’åˆ¥ã®ç—…é™¢ã«ç§»å‹•ã¾ãŸã¯å‰Šé™¤
            import random
            random.shuffle(dup_positions)

            for ridx, hosp, date in dup_positions[1:]:  # æœ€åˆã®1ã¤ã¯æ®‹ã™
                moved = False

                # åŒã˜æ—¥ã®ä»–ã®å¤–ç—…é™¢ï¼ˆLï½Yåˆ—ï¼‰ã®ç©ºãæ ã‚’æ¢ã™
                for other_hosp in hospital_cols:
                    other_hidx = shift_df.columns.get_loc(other_hosp)
                    # å¤–ç—…é™¢ã‹ã¤é‡è¤‡ç—…é™¢ã§ãªã„
                    if not (L_COL_INDEX <= other_hidx <= L_Y_END_INDEX):
                        continue
                    if other_hosp == dup_hosp:
                        continue

                    # ã“ã®ç—…é™¢ã«ã“ã®åŒ»å¸«ãŒæ—¢ã«å‰²å½“ã‚‰ã‚Œã¦ã„ãªã„ã‹
                    if assigned_hosp_count[doc].get(other_hosp, 0) >= 1:
                        continue

                    # ç©ºãæ ãŒã‚ã‚‹ã‹
                    if pd.isna(df.at[ridx, other_hosp]):
                        # ãƒãƒ¼ãƒ‰åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
                        if not can_assign_doc_to_slot(doc, date, other_hosp):
                            continue

                        # ç§»å‹•å®Ÿè¡Œ
                        df.at[ridx, dup_hosp] = None
                        df.at[ridx, other_hosp] = doc
                        fixed_in_this_iteration += 1
                        total_fixed += 1
                        moved = True
                        break

                # ç§»å‹•å…ˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å‰Šé™¤
                if not moved and attempt >= 5:
                    df.at[ridx, dup_hosp] = None
                    fixed_in_this_iteration += 1
                    total_fixed += 1
                    if verbose and attempt < 10:
                        print(f"      ç§»å‹•å…ˆãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€{doc}ã®{date.strftime('%m/%d')}ã®{dup_hosp}å‰²å½“ã‚’å‰Šé™¤ã—ã¾ã™")
                    break  # ã“ã®é‡è¤‡ã®ä»–ã®positionã¯æ¬¡å›

            if fixed_in_this_iteration > 0:
                counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, *_ = recompute_stats(df)

        # é€²æ—ãƒã‚§ãƒƒã‚¯
        if fixed_in_this_iteration == 0:
            consecutive_failures += 1
        else:
            consecutive_failures = 0

        # é€£ç¶šã§20å›ä¿®æ­£ã§ããªã‘ã‚Œã°è«¦ã‚ã‚‹
        if consecutive_failures >= 20:
            break

    # æœ€çµ‚ç¢ºèª
    counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, *_ = recompute_stats(df)
    remaining_violations = 0
    for doc, hosp_dict in assigned_hosp_count.items():
        for hosp, count in hosp_dict.items():
            if count > 1:
                hidx = shift_df.columns.get_loc(hosp)
                if L_COL_INDEX <= hidx <= L_Y_END_INDEX:
                    remaining_violations += (count - 1)

    if verbose:
        if remaining_violations == 0:
            print(f"   âœ… å…¨ã¦ã®å¤–ç—…é™¢é‡è¤‡ã‚’ä¿®æ­£ã—ã¾ã—ãŸï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")
        else:
            print(f"   âš ï¸ {remaining_violations}ä»¶ã®å¤–ç—…é™¢é‡è¤‡ãŒæ®‹ã£ã¦ã„ã¾ã™ï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")

    return df, remaining_violations == 0, total_fixed

def fix_university_over_2_violations(pattern_df, max_attempts=150, verbose=True):
    """
    å¤§å­¦ç—…é™¢ï¼ˆBï½Kåˆ—ï¼‰ãŒ3å›ä»¥ä¸Šã®åŒ»å¸«ã®é•åã‚’ä¿®æ­£ã™ã‚‹
    ã¾ãŸã€å¤–ç—…é™¢0å›ã®åŒ»å¸«ãŒã„ã‚‹å ´åˆã‚‚å¤§å­¦â†’å¤–ç—…é™¢ã¸ã®ç§»å‹•ã‚’è©¦ã¿ã‚‹ï¼ˆãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼‰

    Args:
        pattern_df: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«DataFrame
        max_attempts: æœ€å¤§è©¦è¡Œå›æ•°
        verbose: ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã‹

    Returns:
        (ä¿®æ­£å¾Œã®DataFrame, æˆåŠŸãƒ•ãƒ©ã‚°, ä¿®æ­£æ•°)
    """
    df = pattern_df.copy()
    total_fixed = 0
    consecutive_failures = 0

    for attempt in range(max_attempts):
        # ç¾åœ¨ã®å‰²å½“çŠ¶æ…‹ã‚’å†è¨ˆç®—
        counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, cc_counts, cc_bg_counts, cc_ht_counts = recompute_stats(df)

        # å¤§å­¦3å›ä»¥ä¸Šã®åŒ»å¸«ã‚’æ¤œå‡ºï¼ˆCCé™¤å¤–ï¼‰
        over_2_list = []
        for doc in active_doctors:
            if doc in RATIO_EXEMPT_DOCTORS:  # ã‚³ãƒ¼ãƒ‰3ã¯å¤–ç—…é™¢å°‚é–€ãªã®ã§é™¤å¤–
                continue
            # CCã¯å¤§å‹é€£ä¼‘ç‰¹åˆ¥ã‚·ãƒ•ãƒˆãªã®ã§é™¤å¤–
            bg_count_no_cc = bg_counts.get(doc, 0) - cc_bg_counts.get(doc, 0)
            if bg_count_no_cc >= 3:
                over_2_list.append((doc, bg_count_no_cc, "å¤§å­¦3å›ä»¥ä¸Š"))

        # å¤–ç—…é™¢0å›ã®åŒ»å¸«ã‚’æ¤œå‡ºï¼ˆå¤§å­¦ã‚’å¤–ç—…é™¢ã«ç§»å‹•ã™ã‚‹å¿…è¦ã‚ã‚Šï¼‰
        # æ³¨ï¼šã“ã‚Œã¯ãƒãƒ¼ãƒ‰åˆ¶ç´„ãªã®ã§CCã¯é™¤å¤–ã—ãªã„
        for doc in active_doctors:
            if doc in RATIO_EXEMPT_DOCTORS:  # ã‚³ãƒ¼ãƒ‰3ã¯å¤–ç—…é™¢å°‚é–€ãªã®ã§å¯¾è±¡å¤–
                continue
            ht_count = ht_counts.get(doc, 0)
            bg_count = bg_counts.get(doc, 0)
            # å¤–ç—…é™¢0å›ã‹ã¤å¤§å­¦1å›ä»¥ä¸Šãªã‚‰ã€å¤§å­¦â†’å¤–ç—…é™¢ã¸ã®ç§»å‹•ãŒå¿…è¦
            if ht_count == 0 and bg_count >= 1:
                # æ—¢ã«over_2_listã«å«ã¾ã‚Œã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
                if not any(d == doc for d, _, _ in over_2_list):
                    over_2_list.append((doc, bg_count, "å¤–ç—…é™¢0å›"))

        if not over_2_list:
            if verbose and total_fixed > 0:
                print(f"   âœ… å¤§å­¦3å›ä»¥ä¸Š/å¤–ç—…é™¢0å›é•åã‚’{total_fixed}ä»¶ä¿®æ­£ã—ã¾ã—ãŸ")
            return df, True, total_fixed

        if attempt == 0 and verbose:
            over_3_count = sum(1 for _, _, reason in over_2_list if reason == "å¤§å­¦3å›ä»¥ä¸Š")
            ext_0_count = sum(1 for _, _, reason in over_2_list if reason == "å¤–ç—…é™¢0å›")
            if over_3_count > 0:
                print(f"   âš ï¸ å¤§å­¦3å›ä»¥ä¸Šé•åã‚’{over_3_count}ä»¶æ¤œå‡º")
            if ext_0_count > 0:
                print(f"   âš ï¸ å¤–ç—…é™¢0å›é•åã‚’{ext_0_count}ä»¶æ¤œå‡º")

        # ä¿®æ­£è©¦è¡Œ
        fixed_in_this_iteration = 0

        for doc, bg_count, reason in over_2_list:
            # å¤§å­¦3å›ä»¥ä¸Šã®å ´åˆã¯2å›ã«æ¸›ã‚‰ã™ã€å¤–ç—…é™¢0å›ã®å ´åˆã¯1å›ç§»å‹•
            if reason == "å¤§å­¦3å›ä»¥ä¸Š" and bg_count < 3:
                continue
            if reason == "å¤–ç—…é™¢0å›" and bg_count < 1:
                continue

            # ã“ã®åŒ»å¸«ã®å¤§å­¦ç—…é™¢ã¸ã®å‰²å½“ã‚’æ¢ã™
            bg_positions = []
            for ridx in df.index:
                date = df.at[ridx, date_col_shift]
                if pd.isna(date):
                    continue
                date = pd.to_datetime(date).normalize().tz_localize(None)

                for hosp in hospital_cols:
                    hidx = shift_df.columns.get_loc(hosp)
                    # å¤§å­¦ç—…é™¢ï¼ˆBï½Kåˆ—ï¼‰ã‹
                    if not (B_COL_INDEX <= hidx <= B_K_END_INDEX):
                        continue

                    val = df.at[ridx, hosp]
                    if isinstance(val, str) and normalize_name(val) == doc:
                        bg_positions.append((ridx, hosp, date))

            # ç§»å‹•æ•°ã‚’æ±ºå®š
            if reason == "å¤§å­¦3å›ä»¥ä¸Š":
                excess = bg_count - 2  # 2å›ã¾ã§æ¸›ã‚‰ã™
            else:  # å¤–ç—…é™¢0å›
                excess = 1  # 1å›ã ã‘ç§»å‹•

            import random
            random.shuffle(bg_positions)

            for ridx, hosp, date in bg_positions[:excess]:
                moved = False

                # åŒã˜æ—¥ã®å¤–ç—…é™¢ï¼ˆLï½Yåˆ—ï¼‰ã®ç©ºãæ ã«ç§»å‹•ã‚’è©¦ã¿ã‚‹
                for other_hosp in hospital_cols:
                    other_hidx = shift_df.columns.get_loc(other_hosp)
                    # å¤–ç—…é™¢ã‹
                    if not (L_COL_INDEX <= other_hidx <= L_Y_END_INDEX):
                        continue

                    # ã“ã®ç—…é™¢ã«ã“ã®åŒ»å¸«ãŒæ—¢ã«å‰²å½“ã‚‰ã‚Œã¦ã„ãªã„ã‹
                    if assigned_hosp_count[doc].get(other_hosp, 0) >= 1:
                        continue

                    # ç©ºãæ ãŒã‚ã‚‹ã‹
                    if pd.isna(df.at[ridx, other_hosp]):
                        # ãƒãƒ¼ãƒ‰åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
                        if not can_assign_doc_to_slot(doc, date, other_hosp):
                            continue

                        # ç§»å‹•å®Ÿè¡Œ
                        df.at[ridx, hosp] = None
                        df.at[ridx, other_hosp] = doc
                        fixed_in_this_iteration += 1
                        total_fixed += 1
                        moved = True
                        break

                # ç§»å‹•å…ˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ä»£æ›¿åŒ»å¸«ã‚’æ¢ã—ã¦å‰²ã‚Šå½“ã¦ï¼ˆæœªå‰²å½“é˜²æ­¢ï¼‰
                if not moved and attempt >= 5:
                    # ã“ã®æ—¥ã«æ—¢ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹åŒ»å¸«ã‚’å–å¾—
                    already_on_date = set()
                    for h in hospital_cols:
                        v = df.at[ridx, h]
                        if isinstance(v, str):
                            already_on_date.add(normalize_name(v))
                    # ä»£æ›¿å€™è£œ: åŒæ—¥é‡è¤‡ãªã— & å¤§å­¦ç³»2å›æœªæº€ã®åŒ»å¸«
                    replacement_candidates = [
                        d for d in doctor_names
                        if d not in already_on_date
                        and d != doc
                        and bg_counts.get(d, 0) < 2
                        and can_assign_doc_to_slot(d, date, hosp)
                    ]
                    if replacement_candidates:
                        replacement_candidates.sort(key=lambda d: bg_counts.get(d, 0))
                        new_doc = replacement_candidates[0]
                        df.at[ridx, hosp] = new_doc
                        if verbose and attempt < 10:
                            print(f"      {doc}â†’{new_doc}: {date.strftime('%m/%d')}ã®å¤§å­¦ç—…é™¢å‰²å½“ã‚’äº¤ä»£")
                    else:
                        # ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: çµ¶å¯¾ç¦å¿Œã‚’ã™ã¹ã¦å›é¿
                        hosp_idx = shift_df.columns.get_loc(hosp)
                        is_external_hosp = L_COL_INDEX <= hosp_idx <= L_Y_END_INDEX

                        def is_valid_bg_emergency(d):
                            # åŒæ—¥é‡è¤‡ç¦æ­¢
                            if d in already_on_date or d == doc:
                                return False
                            # ABS-001: ã‚³ãƒ¼ãƒ‰0ç¦æ­¢
                            if get_avail_code(date, d) == 0:
                                return False
                            # gap1ç¦æ­¢
                            d_dates = sorted([dt for dt, _ in doc_assignments.get(d, [])])
                            if d_dates:
                                min_gap = min(abs((date - dt).days) for dt in d_dates)
                                if min_gap < 2:
                                    return False
                            # å¤–ç—…é™¢é‡è¤‡ç¦æ­¢
                            if is_external_hosp and assigned_hosp_count.get(d, {}).get(hosp, 0) >= 1:
                                return False
                            return True

                        emergency = [d for d in doctor_names if is_valid_bg_emergency(d)]
                        if emergency:
                            emergency.sort(key=lambda d: bg_counts.get(d, 0))
                            new_doc = emergency[0]
                            df.at[ridx, hosp] = new_doc
                            if verbose and attempt < 10:
                                print(f"      {doc}â†’{new_doc}(ç·Šæ€¥): {date.strftime('%m/%d')}ã®å¤§å­¦ç—…é™¢å‰²å½“ã‚’äº¤ä»£")
                        else:
                            # æœ€çµ‚æ‰‹æ®µ: å…ƒã®åŒ»å¸«ã‚’ç¶­æŒï¼ˆå‰Šé™¤ã—ãªã„ï¼‰
                            df.at[ridx, hosp] = doc
                            if verbose and attempt < 10:
                                print(f"      {doc}: {date.strftime('%m/%d')}ã®å‰²å½“ç¶­æŒï¼ˆçµ¶å¯¾ç¦å¿Œå›é¿ä¸å¯ï¼‰")
                    fixed_in_this_iteration += 1
                    total_fixed += 1

            if fixed_in_this_iteration > 0:
                counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, *_ = recompute_stats(df)

        # é€²æ—ãƒã‚§ãƒƒã‚¯
        if fixed_in_this_iteration == 0:
            consecutive_failures += 1
        else:
            consecutive_failures = 0

        # é€£ç¶šã§20å›ä¿®æ­£ã§ããªã‘ã‚Œã°è«¦ã‚ã‚‹
        if consecutive_failures >= 20:
            break

    # æœ€çµ‚ç¢ºèª
    counts, bg_counts, ht_counts, *_ = recompute_stats(df)
    remaining_over_2 = sum(1 for doc in active_doctors if doc not in RATIO_EXEMPT_DOCTORS and bg_counts.get(doc, 0) >= 3)
    remaining_ext_0 = sum(1 for doc in active_doctors if doc not in RATIO_EXEMPT_DOCTORS and ht_counts.get(doc, 0) == 0 and bg_counts.get(doc, 0) >= 1)
    remaining_violations = remaining_over_2 + remaining_ext_0

    if verbose:
        if remaining_violations == 0:
            if total_fixed > 0:
                print(f"   âœ… å…¨ã¦ã®å¤§å­¦3å›ä»¥ä¸Š/å¤–ç—…é™¢0å›é•åã‚’ä¿®æ­£ã—ã¾ã—ãŸï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")
        else:
            if remaining_over_2 > 0:
                print(f"   âš ï¸ {remaining_over_2}ä»¶ã®å¤§å­¦3å›ä»¥ä¸Šé•åãŒæ®‹ã£ã¦ã„ã¾ã™")
            if remaining_ext_0 > 0:
                print(f"   âš ï¸ {remaining_ext_0}ä»¶ã®å¤–ç—…é™¢0å›é•åãŒæ®‹ã£ã¦ã„ã¾ã™")

    return df, remaining_violations == 0, total_fixed

def fix_university_weekday_balance_violations(pattern_df, max_attempts=150, verbose=True):
    """
    å¤§å­¦ç—…é™¢ã®å¹³æ—¥åã‚Šï¼ˆå¹³æ—¥2å›ä»¥ä¸Šï¼‰ã®é•åã‚’ä¿®æ­£ã™ã‚‹

    Args:
        pattern_df: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«DataFrame
        max_attempts: æœ€å¤§è©¦è¡Œå›æ•°
        verbose: ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã‹

    Returns:
        (ä¿®æ­£å¾Œã®DataFrame, æˆåŠŸãƒ•ãƒ©ã‚°, ä¿®æ­£æ•°)
    """
    df = pattern_df.copy()
    total_fixed = 0
    consecutive_failures = 0

    for attempt in range(max_attempts):
        # ç¾åœ¨ã®å‰²å½“çŠ¶æ…‹ã‚’å†è¨ˆç®—
        counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, cc_counts, cc_bg_counts, cc_ht_counts = recompute_stats(df)

        # å¤§å­¦ã®å¹³æ—¥2å›ä»¥ä¸Šã®åŒ»å¸«ã‚’æ¤œå‡º
        # æ³¨ï¼šweekday_countã‹ã‚‰CCã‚’é™¤å¤–ã™ã‚‹ã«ã¯è¿½åŠ ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãŒå¿…è¦
        # ç¾æ™‚ç‚¹ã§ã¯weekday_countã¯ãã®ã¾ã¾ä½¿ç”¨ï¼ˆå¤§å‹é€£ä¼‘ã¯å¹³æ—¥ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã«ãã„ï¼‰
        weekday_over_list = []
        for doc in active_doctors:
            weekday_count = bg_cat[doc].get("å¹³æ—¥", 0)
            if weekday_count >= 2:
                weekday_over_list.append((doc, weekday_count, bg_counts.get(doc, 0)))

        if not weekday_over_list:
            if verbose and total_fixed > 0:
                print(f"   âœ… å¤§å­¦å¹³æ—¥åã‚Šé•åã‚’{total_fixed}ä»¶ä¿®æ­£ã—ã¾ã—ãŸ")
            return df, True, total_fixed

        if attempt == 0 and verbose:
            print(f"   âš ï¸ å¤§å­¦å¹³æ—¥åã‚Šé•åã‚’{len(weekday_over_list)}ä»¶æ¤œå‡º â†’ è‡ªå‹•ä¿®æ­£ã‚’é–‹å§‹...")

        # ä¿®æ­£è©¦è¡Œ
        fixed_in_this_iteration = 0

        for doc, weekday_count, bg_total in weekday_over_list:
            if weekday_count < 2:
                continue

            # ã“ã®åŒ»å¸«ã®å¤§å­¦ç—…é™¢å¹³æ—¥ã®å‰²å½“ã‚’æ¢ã™
            bg_weekday_positions = []
            for ridx in df.index:
                date = df.at[ridx, date_col_shift]
                if pd.isna(date):
                    continue
                date = pd.to_datetime(date).normalize().tz_localize(None)

                for hosp in hospital_cols:
                    hidx = shift_df.columns.get_loc(hosp)
                    # å¤§å­¦ç—…é™¢ï¼ˆBï½Kåˆ—ï¼‰ã‹
                    if not (B_COL_INDEX <= hidx <= B_K_END_INDEX):
                        continue

                    val = df.at[ridx, hosp]
                    if isinstance(val, str) and normalize_name(val) == doc:
                        # å¹³æ—¥ã‹
                        category = classify_bg_category(date, hosp)
                        if category == "å¹³æ—¥":
                            bg_weekday_positions.append((ridx, hosp, date))

            # å¹³æ—¥ã®ã†ã¡1ã¤ã‚’å¤–ç—…é™¢ã«ç§»å‹•ã¾ãŸã¯å‰Šé™¤
            import random
            random.shuffle(bg_weekday_positions)

            for ridx, hosp, date in bg_weekday_positions[:1]:  # 1ã¤ã ã‘è©¦è¡Œ
                moved = False

                # åŒã˜æ—¥ã®å¤–ç—…é™¢ï¼ˆLï½Yåˆ—ï¼‰ã®ç©ºãæ ã«ç§»å‹•ã‚’è©¦ã¿ã‚‹
                for other_hosp in hospital_cols:
                    other_hidx = shift_df.columns.get_loc(other_hosp)
                    # å¤–ç—…é™¢ã‹
                    if not (L_COL_INDEX <= other_hidx <= L_Y_END_INDEX):
                        continue

                    # ã“ã®ç—…é™¢ã«ã“ã®åŒ»å¸«ãŒæ—¢ã«å‰²å½“ã‚‰ã‚Œã¦ã„ãªã„ã‹
                    if assigned_hosp_count[doc].get(other_hosp, 0) >= 1:
                        continue

                    # ç©ºãæ ãŒã‚ã‚‹ã‹
                    if pd.isna(df.at[ridx, other_hosp]):
                        # ãƒãƒ¼ãƒ‰åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
                        if not can_assign_doc_to_slot(doc, date, other_hosp):
                            continue

                        # ç§»å‹•å®Ÿè¡Œ
                        df.at[ridx, hosp] = None
                        df.at[ridx, other_hosp] = doc
                        fixed_in_this_iteration += 1
                        total_fixed += 1
                        moved = True
                        break

                # ç§»å‹•å…ˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ä»£æ›¿åŒ»å¸«ã‚’æ¢ã—ã¦å‰²ã‚Šå½“ã¦ï¼ˆæœªå‰²å½“é˜²æ­¢ï¼‰
                if not moved and attempt >= 5:
                    # ã“ã®æ—¥ã«æ—¢ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹åŒ»å¸«ã‚’å–å¾—
                    already_on_date = set()
                    for h in hospital_cols:
                        v = df.at[ridx, h]
                        if isinstance(v, str):
                            already_on_date.add(normalize_name(v))
                    # ä»£æ›¿å€™è£œ: åŒæ—¥é‡è¤‡ãªã— & å¤§å­¦å¹³æ—¥æœªå‰²å½“ã®åŒ»å¸«
                    replacement_candidates = [
                        d for d in doctor_names
                        if d not in already_on_date
                        and d != doc
                        and wd_counts.get(d, 0) < we_counts.get(d, 0)  # å¹³æ—¥<ä¼‘æ—¥ã®åŒ»å¸«ã‚’å„ªå…ˆ
                        and can_assign_doc_to_slot(d, date, hosp)
                    ]
                    if replacement_candidates:
                        replacement_candidates.sort(key=lambda d: wd_counts.get(d, 0))
                        new_doc = replacement_candidates[0]
                        df.at[ridx, hosp] = new_doc
                        if verbose and attempt < 10:
                            print(f"      {doc}â†’{new_doc}: {date.strftime('%m/%d')}ã®å¤§å­¦å¹³æ—¥å‰²å½“ã‚’äº¤ä»£")
                    else:
                        # ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: çµ¶å¯¾ç¦å¿Œã‚’ã™ã¹ã¦å›é¿
                        hosp_idx = shift_df.columns.get_loc(hosp)
                        is_external_hosp = L_COL_INDEX <= hosp_idx <= L_Y_END_INDEX

                        def is_valid_weekday_emergency(d):
                            # åŒæ—¥é‡è¤‡ç¦æ­¢
                            if d in already_on_date or d == doc:
                                return False
                            # ABS-001: ã‚³ãƒ¼ãƒ‰0ç¦æ­¢
                            if get_avail_code(date, d) == 0:
                                return False
                            # gap1ç¦æ­¢
                            d_dates = sorted([dt for dt, _ in doc_assignments.get(d, [])])
                            if d_dates:
                                min_gap = min(abs((date - dt).days) for dt in d_dates)
                                if min_gap < 2:
                                    return False
                            # å¤–ç—…é™¢é‡è¤‡ç¦æ­¢
                            if is_external_hosp and assigned_hosp_count.get(d, {}).get(hosp, 0) >= 1:
                                return False
                            return True

                        emergency = [d for d in doctor_names if is_valid_weekday_emergency(d)]
                        if emergency:
                            emergency.sort(key=lambda d: counts.get(d, 0))
                            new_doc = emergency[0]
                            df.at[ridx, hosp] = new_doc
                            if verbose and attempt < 10:
                                print(f"      {doc}â†’{new_doc}(ç·Šæ€¥): {date.strftime('%m/%d')}ã®å¤§å­¦å¹³æ—¥å‰²å½“ã‚’äº¤ä»£")
                        else:
                            # æœ€çµ‚æ‰‹æ®µ: å…ƒã®åŒ»å¸«ã‚’ç¶­æŒ
                            df.at[ridx, hosp] = doc
                            if verbose and attempt < 10:
                                print(f"      {doc}: {date.strftime('%m/%d')}ã®å‰²å½“ç¶­æŒï¼ˆçµ¶å¯¾ç¦å¿Œå›é¿ä¸å¯ï¼‰")
                    fixed_in_this_iteration += 1
                    total_fixed += 1
                    break

            if fixed_in_this_iteration > 0:
                counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, *_ = recompute_stats(df)

        # é€²æ—ãƒã‚§ãƒƒã‚¯
        if fixed_in_this_iteration == 0:
            consecutive_failures += 1
        else:
            consecutive_failures = 0

        # é€£ç¶šã§20å›ä¿®æ­£ã§ããªã‘ã‚Œã°è«¦ã‚ã‚‹
        if consecutive_failures >= 20:
            break

    # æœ€çµ‚ç¢ºèª
    counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, *_ = recompute_stats(df)
    remaining_violations = sum(1 for doc in active_doctors if bg_cat[doc].get("å¹³æ—¥", 0) >= 2)

    if verbose:
        if remaining_violations == 0:
            print(f"   âœ… å…¨ã¦ã®å¤§å­¦å¹³æ—¥åã‚Šé•åã‚’ä¿®æ­£ã—ã¾ã—ãŸï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")
        else:
            print(f"   âš ï¸ {remaining_violations}ä»¶ã®å¤§å­¦å¹³æ—¥åã‚Šé•åãŒæ®‹ã£ã¦ã„ã¾ã™ï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")

    return df, remaining_violations == 0, total_fixed

def fix_fairness_imbalance(pattern_df, max_attempts=200, verbose=True):
    """
    activeåŒ»å¸«é–“ã®å‰²å½“å›æ•°ã®å…¬å¹³æ€§ã‚’å¼·åŒ–ã™ã‚‹ï¼ˆæœ€å¤§ã¨æœ€å°ã®å·®ã‚’ç¸®ã‚ã‚‹ï¼‰

    Args:
        pattern_df: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«DataFrame
        max_attempts: æœ€å¤§è©¦è¡Œå›æ•°
        verbose: ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã‹

    Returns:
        (ä¿®æ­£å¾Œã®DataFrame, æˆåŠŸãƒ•ãƒ©ã‚°, ä¿®æ­£æ•°)
    """
    df = pattern_df.copy()
    total_fixed = 0
    consecutive_failures = 0

    for attempt in range(max_attempts):
        counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, cc_counts, cc_bg_counts, cc_ht_counts = recompute_stats(df)

        # activeåŒ»å¸«ã®å‰²å½“å›æ•°ã‚’ç¢ºèªï¼ˆCCé™¤å¤–ï¼‰
        # CCã¯å¤§å‹é€£ä¼‘ç‰¹åˆ¥ã‚·ãƒ•ãƒˆãªã®ã§å…¬å¹³æ€§è¨ˆç®—ã‹ã‚‰é™¤å¤–
        active_counts = [(doc, counts.get(doc, 0) - cc_counts.get(doc, 0)) for doc in active_doctors]
        if not active_counts:
            return df, True, total_fixed

        # æœ€å¤§ã¨æœ€å°ã‚’å–å¾—
        max_count = max(c for _, c in active_counts)
        min_count = min(c for _, c in active_counts)
        diff = max_count - min_count

        # å·®ãŒ1ä»¥ä¸‹ãªã‚‰å…¬å¹³æ€§é”æˆ
        if diff <= 1:
            if verbose and total_fixed > 0:
                print(f"   âœ… å…¬å¹³æ€§é•åã‚’{total_fixed}ä»¶ä¿®æ­£ã—ã¾ã—ãŸï¼ˆmax={max_count}, min={min_count}, diff={diff}ï¼‰")
            return df, True, total_fixed

        if attempt == 0 and verbose:
            max_docs = [doc for doc, c in active_counts if c == max_count]
            min_docs = [doc for doc, c in active_counts if c == min_count]
            print(f"   âš ï¸ å…¬å¹³æ€§é•åã‚’æ¤œå‡ºï¼ˆmax={max_count}, min={min_count}, diff={diff}ï¼‰ â†’ è‡ªå‹•ä¿®æ­£ã‚’é–‹å§‹...")

        fixed_in_this_iteration = 0

        # æœ€å¤§å›æ•°ã®åŒ»å¸«ã‹ã‚‰æœ€å°å›æ•°ã®åŒ»å¸«ã«ã‚·ãƒ•ãƒˆã‚’ç§»å‹•
        max_docs = [doc for doc, c in active_counts if c == max_count]
        min_docs = [doc for doc, c in active_counts if c == min_count]

        import random
        random.shuffle(max_docs)
        random.shuffle(min_docs)

        # æœ€å¤§å›æ•°ã®åŒ»å¸«ã®ã‚·ãƒ•ãƒˆã‚’æ¢ã™
        for max_doc in max_docs[:3]:  # æœ€å¤§3äººã¾ã§è©¦è¡Œ
            # max_docã®å‰²å½“ä½ç½®ã‚’å–å¾—
            max_doc_positions = []
            for ridx in df.index:
                date = df.at[ridx, date_col_shift]
                if pd.isna(date):
                    continue
                date = pd.to_datetime(date).normalize().tz_localize(None)

                for hosp in hospital_cols:
                    val = df.at[ridx, hosp]
                    if isinstance(val, str) and normalize_name(val) == max_doc:
                        max_doc_positions.append((ridx, hosp, date))

            random.shuffle(max_doc_positions)

            # å„ä½ç½®ã«ã¤ã„ã¦ã€æœ€å°å›æ•°ã®åŒ»å¸«ã¨å…¥ã‚Œæ›¿ãˆå¯èƒ½ã‹è©¦ã™
            for ridx, hosp, date in max_doc_positions[:5]:  # æœ€å¤§5å€‹ã¾ã§è©¦è¡Œ
                # ã“ã®æ—¥ã«æ—¢ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹åŒ»å¸«ã‚’é™¤å¤–
                already_assigned_on_date = set()
                for h in hospital_cols:
                    v = df.at[ridx, h]
                    if isinstance(v, str):
                        already_assigned_on_date.add(normalize_name(v))

                # æœ€å°å›æ•°ã®åŒ»å¸«ã®ä¸­ã‹ã‚‰ä»£æ›¿ã‚’æ¢ã™
                for min_doc in min_docs:
                    if min_doc in already_assigned_on_date:
                        continue
                    if not can_assign_doc_to_slot(min_doc, date, hosp):
                        continue

                    # gapåˆ¶ç´„ãƒã‚§ãƒƒã‚¯ï¼ˆç§»å‹•å¾Œã«gapé•åãŒç™ºç”Ÿã—ãªã„ã‹ï¼‰
                    # min_docã«å‰²ã‚Šå½“ã¦ãŸå ´åˆã®gapé•åãƒã‚§ãƒƒã‚¯
                    # doc_assignments ã¯ (date, hosp) ã®ã‚¿ãƒ—ãƒ«ã®ãƒªã‚¹ãƒˆ
                    min_doc_dates = sorted([d for d, h in doc_assignments.get(min_doc, []) if h != hosp or d != date])
                    new_dates = sorted(min_doc_dates + [date])

                    gap_ok = True
                    for j in range(len(new_dates) - 1):
                        gap = (new_dates[j + 1] - new_dates[j]).days
                        if gap < 3:
                            gap_ok = False
                            break

                    if not gap_ok:
                        continue

                    # å¤–ç—…é™¢é‡è¤‡ãƒã‚§ãƒƒã‚¯
                    hosp_idx = shift_df.columns.get_loc(hosp)
                    is_external = L_COL_INDEX <= hosp_idx <= L_Y_END_INDEX
                    if is_external:
                        # min_docãŒã“ã®å¤–ç—…é™¢ã«æ—¢ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã¯æ‹’å¦
                        if assigned_hosp_count.get(min_doc, {}).get(hosp, 0) >= 1:
                            continue

                    # max_docã‹ã‚‰å‰Šé™¤ã—ãŸå ´åˆã®gapé•åãƒã‚§ãƒƒã‚¯
                    max_doc_dates = sorted([d for d, h in doc_assignments.get(max_doc, []) if h != hosp or d != date])
                    if len(max_doc_dates) >= 2:
                        for j in range(len(max_doc_dates) - 1):
                            gap = (max_doc_dates[j + 1] - max_doc_dates[j]).days
                            # å‰Šé™¤ã«ã‚ˆã£ã¦gapé•åãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã¯ãªã„ï¼ˆå‰Šé™¤ã¯é–“éš”ã‚’åºƒã’ã‚‹ã ã‘ï¼‰

                    # å…¥ã‚Œæ›¿ãˆ
                    df.at[ridx, hosp] = min_doc
                    fixed_in_this_iteration += 1
                    total_fixed += 1

                    if verbose and attempt < 3:
                        print(f"      {date.strftime('%m/%d')} {hosp}: {max_doc}({max_count}å›) â†’ {min_doc}({min_count}å›)")

                    # doc_assignmentsã‚’æ›´æ–°ï¼ˆæ¬¡ã®åå¾©ã®ãŸã‚ï¼‰
                    if max_doc in doc_assignments:
                        doc_assignments[max_doc] = [(d, h) for d, h in doc_assignments[max_doc] if h != hosp or d != date]
                    if min_doc not in doc_assignments:
                        doc_assignments[min_doc] = []
                    doc_assignments[min_doc].append((date, hosp))

                    break  # min_docs loop

                if fixed_in_this_iteration > 0:
                    break  # max_doc_positions loop

            if fixed_in_this_iteration > 0:
                break  # max_docs loop

        # é€²æ—ãƒã‚§ãƒƒã‚¯
        if fixed_in_this_iteration == 0:
            consecutive_failures += 1
        else:
            consecutive_failures = 0

        # é€£ç¶šã§20å›ä¿®æ­£ã§ããªã‘ã‚Œã°è«¦ã‚ã‚‹
        if consecutive_failures >= 20:
            break

    # æœ€çµ‚ç¢ºèª
    counts, *_ = recompute_stats(df)
    active_counts = [(doc, counts.get(doc, 0)) for doc in active_doctors]
    max_count = max(c for _, c in active_counts)
    min_count = min(c for _, c in active_counts)
    diff = max_count - min_count

    if verbose:
        if diff <= 1:
            print(f"   âœ… å…¬å¹³æ€§ã‚’é”æˆã—ã¾ã—ãŸï¼ˆmax={max_count}, min={min_count}, diff={diff}ï¼‰ï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")
        else:
            print(f"   âš ï¸ å…¬å¹³æ€§é•åãŒæ®‹ã£ã¦ã„ã¾ã™ï¼ˆmax={max_count}, min={min_count}, diff={diff}ï¼‰ï¼ˆä¿®æ­£æ•°: {total_fixed}ï¼‰")

    return df, diff <= 1, total_fixed

def fix_unassigned_slots(pattern_df, verbose=True):
    """
    slot_metaã«ç™»éŒ²ã•ã‚ŒãŸã‚¹ãƒ­ãƒƒãƒˆã§åŒ»å¸«ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ãªã„ã‚‚ã®ã‚’åŸ‹ã‚ã‚‹
    ã“ã‚Œã¯æœ€çµ‚ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒãƒƒãƒˆã¨ã—ã¦ã€å…¨ã¦ã®ã‚¹ãƒ­ãƒƒãƒˆã«åŒ»å¸«ã‚’é…ç½®ã™ã‚‹ã“ã¨ã‚’ä¿è¨¼ã™ã‚‹
    """
    df = pattern_df.copy()
    total_fixed = 0

    counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, *_ = recompute_stats(df)

    for (ridx, hosp), (date, fixed) in slot_meta.items():
        val = df.at[ridx, hosp]

        # æ—¢ã«åŒ»å¸«ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if isinstance(val, str):
            v_norm = normalize_name(val)
            if v_norm in doctor_names:
                continue

        # æœªå‰²ã‚Šå½“ã¦ã‚¹ãƒ­ãƒƒãƒˆã‚’ç™ºè¦‹
        # ã“ã®æ—¥ã«æ—¢ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹åŒ»å¸«ã‚’å–å¾—
        already_assigned_on_date = set()
        for h in hospital_cols:
            v = df.at[ridx, h]
            if isinstance(v, str):
                already_assigned_on_date.add(normalize_name(v))

        # å€™è£œåŒ»å¸«ã‚’æ¢ã™ï¼ˆåˆ¶ç´„ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
        candidates = [
            d for d in doctor_names
            if d not in already_assigned_on_date
            and can_assign_doc_to_slot(d, date, hosp)
        ]

        if candidates:
            # å‰²å½“å›æ•°ãŒå°‘ãªã„åŒ»å¸«ã‚’å„ªå…ˆ
            candidates.sort(key=lambda d: counts.get(d, 0))
            new_doc = candidates[0]
        else:
            # ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: çµ¶å¯¾ç¦å¿Œã‚’ã™ã¹ã¦å›é¿
            col_idx = shift_df.columns.get_loc(hosp)
            is_external = L_COL_INDEX <= col_idx <= L_Y_END_INDEX

            def is_valid_unassigned_fallback(d):
                # åŒæ—¥é‡è¤‡ç¦æ­¢
                if d in already_assigned_on_date:
                    return False
                # ABS-001: ã‚³ãƒ¼ãƒ‰0ç¦æ­¢
                if get_avail_code(date, d) == 0:
                    return False
                # gap1ç¦æ­¢
                d_dates = sorted([dt for dt, _ in doc_assignments.get(d, [])])
                if d_dates:
                    min_gap = min(abs((date - dt).days) for dt in d_dates)
                    if min_gap < 2:
                        return False
                # å¤–ç—…é™¢é‡è¤‡ç¦æ­¢
                if is_external and assigned_hosp_count.get(d, {}).get(hosp, 0) >= 1:
                    return False
                return True

            emergency = [d for d in doctor_names if is_valid_unassigned_fallback(d)]
            if emergency:
                emergency.sort(key=lambda d: counts.get(d, 0))
                new_doc = emergency[0]
            else:
                # çµ¶å¯¾ç¦å¿Œã‚’æº€ãŸã™å€™è£œãŒã„ãªã„å ´åˆã¯æœªå‰²å½“ã®ã¾ã¾
                if verbose:
                    print(f"   âŒ æœªå‰²å½“: {date.strftime('%Y-%m-%d')} {hosp}ï¼ˆçµ¶å¯¾ç¦å¿Œå›é¿ä¸å¯ï¼‰")
                continue

        df.at[ridx, hosp] = new_doc
        counts[new_doc] = counts.get(new_doc, 0) + 1
        total_fixed += 1

        if verbose:
            print(f"   ğŸ”§ æœªå‰²ã‚Šå½“ã¦ä¿®æ­£: {date.strftime('%Y-%m-%d')} {hosp} â†’ {new_doc}")

    if verbose:
        if total_fixed == 0:
            print("   âœ… æœªå‰²ã‚Šå½“ã¦ã‚¹ãƒ­ãƒƒãƒˆãªã—")
        else:
            print(f"   âœ… {total_fixed}ä»¶ã®æœªå‰²ã‚Šå½“ã¦ã‚¹ãƒ­ãƒƒãƒˆã‚’ä¿®æ­£ã—ã¾ã—ãŸ")

    return df, (total_fixed == 0 or total_fixed > 0), total_fixed

def validate_absolute_constraints(pattern_df, verbose=True):
    """
    çµ¶å¯¾ç¦å¿Œã®æœ€çµ‚æ¤œè¨¼ï¼ˆv6.0.0ï¼‰

    ãƒã‚§ãƒƒã‚¯é …ç›®:
    - ABS-001: ã‚³ãƒ¼ãƒ‰0å‰²å½“ç¦æ­¢
    - ABS-002: ã‚³ãƒ¼ãƒ‰2åˆ—åˆ¶é™ï¼ˆBã€œQåˆ—ã®ã¿ï¼‰
    - ABS-003: ã‚³ãƒ¼ãƒ‰3åˆ—åˆ¶é™ï¼ˆLã€œYåˆ—ã®ã¿ï¼‰
    - ABS-006: åŒæ—¥é‡è¤‡ç¦æ­¢
    - ABS-007: gap >= 3æ—¥å¿…é ˆ
    - ABS-008: åŒä¸€ç—…é™¢é‡è¤‡ç¦æ­¢ï¼ˆå…¨åˆ—ï¼‰
    - ABS-009: æœªå‰²å½“ç¦æ­¢
    - ABS-010: TARGET_CAPéµå®ˆ
    - ABS-011: å¤§å­¦ç³»2å›ã¾ã§

    Returns:
        (violations_list, is_valid)
    """
    violations = []

    counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, *_ = recompute_stats(pattern_df)

    # ABS-001, ABS-002, ABS-003: ã‚³ãƒ¼ãƒ‰åˆ¶é™ãƒã‚§ãƒƒã‚¯
    for (ridx, hosp), (date, fixed) in slot_meta.items():
        val = pattern_df.at[ridx, hosp]
        if isinstance(val, str):
            doc = normalize_name(val)
            if doc in doctor_names:
                code = get_avail_code(date, doc)
                hidx = shift_df.columns.get_loc(hosp)
                # ABS-001: ã‚³ãƒ¼ãƒ‰0ç¦æ­¢
                if code == 0:
                    violations.append({
                        "type": "ABS-001",
                        "desc": f"ã‚³ãƒ¼ãƒ‰0å‰²å½“: {doc} â†’ {date.strftime('%Y-%m-%d')} {hosp}"
                    })
                # ABS-002: ã‚³ãƒ¼ãƒ‰2ã¯Bã€œQåˆ—ã®ã¿
                if code == 2 and not (B_COL_INDEX <= hidx <= Q_COL_INDEX):
                    violations.append({
                        "type": "ABS-002",
                        "desc": f"ã‚³ãƒ¼ãƒ‰2åˆ—é•å: {doc} â†’ {date.strftime('%Y-%m-%d')} {hosp}"
                    })
                # ABS-003: ã‚³ãƒ¼ãƒ‰3ã¯Lã€œYåˆ—ã®ã¿
                if code == 3 and not (L_COL_INDEX <= hidx <= L_Y_END_INDEX):
                    violations.append({
                        "type": "ABS-003",
                        "desc": f"ã‚³ãƒ¼ãƒ‰3åˆ—é•å: {doc} â†’ {date.strftime('%Y-%m-%d')} {hosp}"
                    })

    # ABS-006: åŒæ—¥é‡è¤‡ãƒã‚§ãƒƒã‚¯
    for date, doc_count in build_date_doc_count(pattern_df).items():
        for doc, count in doc_count.items():
            if count > 1:
                violations.append({
                    "type": "ABS-006",
                    "desc": f"åŒæ—¥é‡è¤‡: {doc} â†’ {date.strftime('%Y-%m-%d')} ({count}å›)"
                })

    # ABS-007: gap >= 3æ—¥ãƒã‚§ãƒƒã‚¯
    for doc, assigns in doc_assignments.items():
        dates = sorted([d for d, _ in assigns])
        for i in range(1, len(dates)):
            gap = (dates[i] - dates[i-1]).days
            if gap < 3:
                violations.append({
                    "type": "ABS-007",
                    "desc": f"gapé•å: {doc} â†’ gap={gap}æ—¥ (å¿…é ˆ>=3)"
                })

    # ABS-008: åŒä¸€ç—…é™¢é‡è¤‡ãƒã‚§ãƒƒã‚¯
    for doc, hosp_dict in assigned_hosp_count.items():
        for hosp, count in hosp_dict.items():
            if count > 1:
                violations.append({
                    "type": "ABS-008",
                    "desc": f"ç—…é™¢é‡è¤‡: {doc} â†’ {hosp} ({count}å›)"
                })

    # ABS-009: æœªå‰²å½“æ ãƒã‚§ãƒƒã‚¯
    for (ridx, hosp), (date, fixed) in slot_meta.items():
        val = pattern_df.at[ridx, hosp]
        if not isinstance(val, str):
            violations.append({
                "type": "ABS-009",
                "desc": f"æœªå‰²å½“: {date.strftime('%Y-%m-%d')} {hosp}"
            })
        elif normalize_name(val) not in doctor_names:
            violations.append({
                "type": "ABS-009",
                "desc": f"ä¸æ˜åŒ»å¸«: {date.strftime('%Y-%m-%d')} {hosp} â†’ {val}"
            })

    # ABS-010: TARGET_CAPéµå®ˆãƒã‚§ãƒƒã‚¯
    for doc, count in counts.items():
        cap = TARGET_CAP.get(doc, 0)
        if count > cap:
            violations.append({
                "type": "ABS-010",
                "desc": f"TARGET_CAPè¶…é: {doc} â†’ {count}å› (ä¸Šé™{cap})"
            })

    # ABS-011: å¤§å­¦ç³»2å›ã¾ã§ãƒã‚§ãƒƒã‚¯
    for doc, bg_count in bg_counts.items():
        if bg_count > 2:
            violations.append({
                "type": "ABS-011",
                "desc": f"å¤§å­¦ç³»3å›ä»¥ä¸Š: {doc} â†’ {bg_count}å› (ä¸Šé™2)"
            })

    is_valid = len(violations) == 0

    if verbose:
        if is_valid:
            print("   âœ… çµ¶å¯¾ç¦å¿Œãƒã‚§ãƒƒã‚¯: å…¨ã¦ã‚¯ãƒªã‚¢")
        else:
            print(f"   âŒ çµ¶å¯¾ç¦å¿Œé•å: {len(violations)}ä»¶")
            for v in violations[:10]:  # æœ€å¤§10ä»¶è¡¨ç¤º
                print(f"      - [{v['type']}] {v['desc']}")
            if len(violations) > 10:
                print(f"      ... ä»– {len(violations) - 10}ä»¶")

    return violations, is_valid

def build_diagnostics(pattern_df):
    counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, assigned_hosp_count, doc_assignments, unassigned, *_ = recompute_stats(pattern_df)
    score, raw, metrics = evaluate_schedule_with_raw(
        pattern_df,
        counts,
        bg_counts,
        ht_counts,
        wd_counts,
        we_counts,
        bk_counts,
        ly_counts,
    )

    df_doctors = build_doctor_diag(counts, bg_counts, ht_counts, wd_counts, we_counts, doc_assignments, assigned_hosp_count)
    df_gap = build_gap_details(doc_assignments)
    df_same = build_same_day_duplicates(doc_assignments)
    df_hdup = build_hosp_dup_details(assigned_hosp_count)
    df_unass = build_unassigned_details(unassigned)
    df_metrics = build_metrics_df(score, raw, metrics)
    df_hard_violations = build_hard_constraint_violations(pattern_df)

    return df_doctors, df_gap, df_same, df_hdup, df_unass, df_metrics, df_hard_violations

# =========================
# ãƒ‘ã‚¿ãƒ¼ãƒ³æ¢ç´¢ï¼ˆgreedy â†’ topå€™è£œã«å±€æ‰€æ¢ç´¢ â†’ top3ï¼‰
# =========================
print("\n" + "="*60)
print("  ğŸš€ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç”Ÿæˆ")
print("="*60)

score_rows = []
candidates = []  # TOP_KEEPã ã‘ä¿æŒ

for i in tqdm(range(1, NUM_PATTERNS + 1), desc="   ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ", ncols=60, disable=not TQDM_AVAILABLE):

    (
        pattern_df,
        counts,
        bg_counts,
        ht_counts,
        wd_counts,
        we_counts,
        bk_counts,
        ly_counts,
        bg_cat,
    ) = build_schedule_pattern(seed=i)
    score, raw_score, metrics = evaluate_schedule_with_raw(
        pattern_df,
        counts,
        bg_counts,
        ht_counts,
        wd_counts,
        we_counts,
        bk_counts,
        ly_counts,
    )

    score_rows.append({"seed": i, "score": score, "raw_score": raw_score, **metrics})

    # gapé•åãŒ0å€‹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿æ¡ç”¨ï¼ˆå®Œå…¨ãªgapåˆ¶ç´„éµå®ˆï¼‰
    gap_violations = metrics.get("gap_violations", 0)
    if gap_violations == 0:
        candidates.append({
            "seed": i,
            "score": score,
            "raw_score": raw_score,
            "metrics": metrics,
            "pattern_df": pattern_df,
        })

# gapé•å0å€‹ã®å€™è£œã‚’ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
candidates = sorted(candidates, key=lambda e: e["raw_score"], reverse=True)[:TOP_KEEP]

if len(candidates) == 0:
    print("\nâš ï¸  gapé•å0å€‹ã®å€™è£œãªã— â†’ åˆ¶ç´„ç·©å’Œã—ã¦ç¶šè¡Œ")
    # gapé•åã®åˆ¶ç´„ã‚’ç·©å’Œã—ã¦å†é¸æŠ
    candidates = []
    for row in score_rows:
        candidates.append({
            "seed": row["seed"],
            "score": row["score"],
            "raw_score": row["raw_score"],
            "metrics": {k: v for k, v in row.items() if k not in ["seed", "score", "raw_score"]},
            "pattern_df": None,  # å†ç”ŸæˆãŒå¿…è¦
        })
    candidates = sorted(candidates, key=lambda e: e["raw_score"], reverse=True)[:TOP_KEEP]
    # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å†ç”Ÿæˆ
    for cand in candidates:
        if cand["pattern_df"] is None:
            pattern_df, *_ = build_schedule_pattern(seed=cand["seed"])
            cand["pattern_df"] = pattern_df

# ãƒ­ãƒ¼ã‚«ãƒ«æ¢ç´¢ã§å€™è£œã‚’æ”¹å–„
refined = []
refine_list = candidates[:REFINE_TOP]
for idx, cand in enumerate(tqdm(refine_list, desc="   å±€æ‰€æ¢ç´¢    ", ncols=60, disable=not TQDM_AVAILABLE), 1):
    if LOCAL_SEARCH_ENABLED:
        improved_df, sc2, raw2, met2 = local_search_swap(
            cand["pattern_df"],
            max_iters=LOCAL_MAX_ITERS,
            patience=LOCAL_PATIENCE,
            refresh_every=LOCAL_REFRESH_EVERY,
            seed=1000 + cand["seed"],
        )
    else:
        improved_df = cand["pattern_df"]
        sc2 = cand["score"]
        raw2 = cand["raw_score"]
        met2 = cand["metrics"]

    # v5.7.1: æœ€é©åŒ–å‡¦ç†ã®ON/OFFã‚¹ã‚¤ãƒƒãƒ
    if OPTIMIZATION_ENABLED:
        # 1. ãƒãƒ¼ãƒ‰åˆ¶ç´„é•åã®è‡ªå‹•ä¿®æ­£
        fixed_df, fix_success, fix_count, fail_count = fix_hard_constraint_violations(
            improved_df, max_attempts=50, verbose=False
        )

        # 2. å¯å¦ã‚³ãƒ¼ãƒ‰2åŒ»å¸«ã®n+1å›é•åã‚’ä¿®æ­£ï¼ˆãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼‰
        code_2_fixed_df, code_2_success, code_2_fix_count = fix_code_2_extra_violations(
            fixed_df, max_attempts=100, verbose=False
        )

        # 3. TARGET_CAPé•åã®è‡ªå‹•ä¿®æ­£ï¼ˆå„ªå…ˆåº¦1ä½ï¼‰
        cap_fixed_df, cap_success, cap_fix_count = fix_target_cap_violations(
            code_2_fixed_df, max_attempts=100, verbose=False
        )

        # 4. å¤§å­¦ç³»æœ€ä½1å›å¿…é ˆé•åã‚’ä¿®æ­£ï¼ˆæº–ãƒãƒ¼ãƒ‰åˆ¶ç´„ã€å„ªå…ˆåº¦2ä½ï¼‰
        univ_min_fixed_df, univ_min_success, univ_min_fix_count = fix_university_minimum_requirement(
            cap_fixed_df, max_attempts=100, verbose=False
        )

        # 4.5. C-Håˆ—ï¼ˆä¼‘æ—¥å¤§å­¦ç³»ï¼‰ã‚«ãƒ†å½“ç•ªé•åã‚’ä¿®æ­£
        ch_kate_fixed_df, ch_kate_success, ch_kate_fix_count = fix_ch_kate_violations(
            univ_min_fixed_df, max_attempts=100, verbose=False
        )

        # 5. gapé•åï¼ˆ3æ—¥æœªæº€ã®é–“éš”ï¼‰ã‚’ä¿®æ­£ï¼ˆå„ªå…ˆåº¦3ä½ï¼‰
        gap_fixed_df, gap_success, gap_fix_count = fix_gap_violations(
            ch_kate_fixed_df, max_attempts=200, verbose=False
        )

        # 6. å¤§å­¦ç³»ã¨å¤–ç—…é™¢ã®å·®ãŒ3ä»¥ä¸Šã®é•åã‚’ä¿®æ­£
        bg_ht_fixed_df, bg_ht_success, bg_ht_fix_count = fix_bg_ht_imbalance_violations(
            gap_fixed_df, max_attempts=100, verbose=False
        )

        # 7. å¤–ç—…é™¢é‡è¤‡ã‚’ä¿®æ­£
        ext_dup_fixed_df, ext_dup_success, ext_dup_fix_count = fix_external_hospital_dup_violations(
            bg_ht_fixed_df, max_attempts=150, verbose=False
        )

        # 8. å¤§å­¦3å›ä»¥ä¸Šé•åã‚’ä¿®æ­£ï¼ˆå¤–ç—…é™¢æœ€ä½1å›ã‚‚å¼·åˆ¶ï¼‰
        univ_over_2_fixed_df, univ_over_2_success, univ_over_2_fix_count = fix_university_over_2_violations(
            ext_dup_fixed_df, max_attempts=150, verbose=False
        )

        # 9. å¤§å­¦å¹³æ—¥åã‚Šé•åã‚’ä¿®æ­£
        univ_weekday_fixed_df, univ_weekday_success, univ_weekday_fix_count = fix_university_weekday_balance_violations(
            univ_over_2_fixed_df, max_attempts=150, verbose=False
        )

        # 10. å…¬å¹³æ€§é•åã®ä¿®æ­£ï¼ˆæœ€å¤§ã¨æœ€å°ã®å·®ã‚’ç¸®ã‚ã‚‹ï¼‰
        fairness_fixed_df, fairness_success, fairness_fix_count = fix_fairness_imbalance(
            univ_weekday_fixed_df, max_attempts=200, verbose=False
        )

        # 11. æœ€çµ‚ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒãƒƒãƒˆ: æœªå‰²ã‚Šå½“ã¦ã‚¹ãƒ­ãƒƒãƒˆã‚’åŸ‹ã‚ã‚‹ï¼ˆãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼‰
        final_df, unassigned_success, unassigned_fix_count = fix_unassigned_slots(
            fairness_fixed_df, verbose=False
        )

        # ä¿®æ­£å¾Œã«å†è©•ä¾¡
        if fix_count > 0 or code_2_fix_count > 0 or cap_fix_count > 0 or univ_min_fix_count > 0 or ch_kate_fix_count > 0 or bg_ht_fix_count > 0 or gap_fix_count > 0 or ext_dup_fix_count > 0 or univ_over_2_fix_count > 0 or univ_weekday_fix_count > 0 or fairness_fix_count > 0 or unassigned_fix_count > 0:
            counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, *_ = recompute_stats(final_df)
            sc2, raw2, met2 = evaluate_schedule_with_raw(
                final_df, counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts
            )
            improved_df = final_df
        else:
            improved_df = final_df
    else:
        # v5.7.1: æœ€é©åŒ–ç„¡åŠ¹ - åˆæœŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãã®ã¾ã¾ä½¿ç”¨
        final_df = improved_df
        fix_count = fail_count = 0
        code_2_fix_count = cap_fix_count = univ_min_fix_count = 0
        ch_kate_fix_count = gap_fix_count = bg_ht_fix_count = 0
        ext_dup_fix_count = univ_over_2_fix_count = univ_weekday_fix_count = 0
        fairness_fix_count = unassigned_fix_count = 0

    # v5.7.1: çµ¶å¯¾ç¦å¿Œã®æœ€çµ‚æ¤œè¨¼
    violations, is_valid = validate_absolute_constraints(final_df, verbose=False)

    refined.append({
        "seed": cand["seed"],
        "score_before": cand["score"],
        "raw_before": cand["raw_score"],
        "score_after": sc2,
        "raw_after": raw2,
        "metrics_after": met2,
        "pattern_df": final_df,  # v5.7.1: æœ€çµ‚ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨
        "violations_fixed": fix_count,
        "violations_failed": fail_count,
        "code_2_violations_fixed": code_2_fix_count,
        "cap_violations_fixed": cap_fix_count,
        "univ_min_violations_fixed": univ_min_fix_count,
        "ch_kate_violations_fixed": ch_kate_fix_count,
        "bg_ht_imbalance_fixed": bg_ht_fix_count,
        "gap_violations_fixed": gap_fix_count,
        "external_dup_violations_fixed": ext_dup_fix_count,
        "univ_over_2_violations_fixed": univ_over_2_fix_count,
        "univ_weekday_violations_fixed": univ_weekday_fix_count,
        "fairness_violations_fixed": fairness_fix_count,
        "unassigned_slots_fixed": unassigned_fix_count,
        "absolute_constraints_valid": is_valid,  # v5.7.1: çµ¶å¯¾ç¦å¿Œãƒã‚§ãƒƒã‚¯çµæœ
        "absolute_violations": violations,  # v5.7.1: é•åè©³ç´°
    })

# =========================
# v5.7.1: çµ¶å¯¾ç¦å¿Œãƒã‚§ãƒƒã‚¯çµæœã®è¡¨ç¤º
# =========================
print("\n=== çµ¶å¯¾ç¦å¿Œãƒã‚§ãƒƒã‚¯ (v5.7.1) ===")
abs_valid_count = sum(1 for e in refined if e.get("absolute_constraints_valid", False))
abs_invalid_count = len(refined) - abs_valid_count
print(f"   çµ¶å¯¾ç¦å¿Œã‚¯ãƒªã‚¢: {abs_valid_count}/{len(refined)} ãƒ‘ã‚¿ãƒ¼ãƒ³")
if abs_invalid_count > 0:
    print(f"   âŒ çµ¶å¯¾ç¦å¿Œé•åã‚ã‚Š: {abs_invalid_count} ãƒ‘ã‚¿ãƒ¼ãƒ³")
    # é•åã®å†…è¨³ã‚’è¡¨ç¤º
    for e in refined:
        if not e.get("absolute_constraints_valid", False):
            viols = e.get("absolute_violations", [])
            if viols:
                print(f"      seed={e['seed']}: {len(viols)}ä»¶ã®é•å")
                for v in viols[:3]:
                    print(f"         - [{v['type']}] {v['desc']}")
                if len(viols) > 3:
                    print(f"         ... ä»– {len(viols) - 3}ä»¶")

# =========================
# ãƒãƒ¼ãƒ‰åˆ¶ç´„é•åã®ãªã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿é¸æŠï¼ˆTARGET_CAPã€gapã€æœªå‰²å½“ï¼‰
# =========================
print("\n=== ãƒãƒ¼ãƒ‰åˆ¶ç´„ãƒã‚§ãƒƒã‚¯ ===")
valid_patterns = []
excluded_count = 0
for e in refined:
    met = e["metrics_after"]
    cap_viol = met.get('cap_violations', 0)
    gap_viol = met.get('gap_violations', 0)
    unassigned = met.get('unassigned_slots', 0)
    code_2_viol = met.get('code_2_extra_violations', 0)
    bg_over_2_viol = met.get('bg_over_2_violations', 0)
    ht_0_viol = met.get('ht_0_violations', 0)
    abs_valid = e.get("absolute_constraints_valid", False)  # v5.7.1: çµ¶å¯¾ç¦å¿Œãƒã‚§ãƒƒã‚¯
    # ch_kate_violationsã¯ã‚½ãƒ•ãƒˆåˆ¶ç´„ï¼ˆãƒšãƒŠãƒ«ãƒ†ã‚£ã®ã¿ã€ãƒãƒ¼ãƒ‰åˆ¶ç´„ã‹ã‚‰é™¤å¤–ï¼‰

    # v5.7.1: çµ¶å¯¾ç¦å¿Œé•åãŒã‚ã‚Œã°é™¤å¤–
    if not abs_valid:
        excluded_count += 1
    elif cap_viol > 0 or gap_viol > 0 or unassigned > 0 or code_2_viol > 0 or bg_over_2_viol > 0 or ht_0_viol > 0:
        excluded_count += 1
    else:
        valid_patterns.append(e)

if not valid_patterns:
    print("\nâš ï¸  ãƒãƒ¼ãƒ‰åˆ¶ç´„ã‚’æº€ãŸã™ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã— â†’ å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰é¸æŠ")
    valid_patterns = refined
else:
    print(f"\nâœ… {len(valid_patterns)}/{len(refined)} ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒãƒãƒ¼ãƒ‰åˆ¶ç´„OKï¼ˆçµ¶å¯¾ç¦å¿Œã‚¯ãƒªã‚¢å«ã‚€ï¼‰")

# è©•ä¾¡è»¸1: å…¬å¹³æ€§é‡è¦–ï¼ˆTARGET_CAPã€å…¬å¹³æ€§ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’é‡è¦–ï¼‰
fairness_patterns = sorted(
    valid_patterns,
    key=lambda e: (
        -e["metrics_after"].get('cap_violations', 0) * 1000,  # TARGET_CAPé•åã‚’æœ€å„ªå…ˆã§å›é¿
        -e["metrics_after"].get('max_minus_min_total_active', 0) * 100,  # å…¬å¹³æ€§
        -e["metrics_after"].get('bg_ht_imbalance_violations', 0) * 50,
        e["raw_after"]
    ),
    reverse=True
)

# è©•ä¾¡è»¸2: gapé•åå›é¿é‡è¦–ï¼ˆé€£ç¶šå½“ç›´ã®é–“éš”ã‚’é‡è¦–ï¼‰
gap_patterns = sorted(
    valid_patterns,
    key=lambda e: (
        -e["metrics_after"].get('gap_violations', 0) * 1000,
        -e["metrics_after"].get('external_hosp_dup_violations', 0) * 100,
        -e["metrics_after"].get('hospital_dup_violations', 0) * 50,
        e["raw_after"]
    ),
    reverse=True
)

# è©•ä¾¡è»¸3: ãƒãƒ©ãƒ³ã‚¹é‡è¦–ï¼ˆå¤§å­¦/å¤–ç—…é™¢ã€å¹³æ—¥/ä¼‘æ—¥ã®ãƒãƒ©ãƒ³ã‚¹ã‚’é‡è¦–ï¼‰
balance_patterns = sorted(
    valid_patterns,
    key=lambda e: (
        -e["metrics_after"].get('bg_ht_imbalance_violations', 0) * 1000,
        -e["metrics_after"].get('bg_weekday_weekend_imbalance', 0) * 100,
        -e["metrics_after"].get('bg_over_2_violations', 0) * 100,
        -e["metrics_after"].get('bg_weekday_over_violations', 0) * 100,
        e["raw_after"]
    ),
    reverse=True
)

# v6.0.0: çµ¶å¯¾ç¦å¿Œã‚¯ãƒªã‚¢ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ã‚’é¸æŠã—ã€ã‚¹ã‚³ã‚¢ä¸Šä½3ã¤ã‚’å‡ºåŠ›
# çµ¶å¯¾ç¦å¿Œé•åã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯æ¡ç”¨ã—ãªã„
abs_valid_patterns = [e for e in valid_patterns if e.get("absolute_constraints_valid", False)]

if abs_valid_patterns:
    # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆï¼ˆraw_afteré™é †ï¼‰
    abs_valid_patterns.sort(key=lambda e: e["raw_after"], reverse=True)
    # ä¸Šä½3ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠ
    top_patterns = abs_valid_patterns[:3]
    for i, p in enumerate(top_patterns):
        p["axis_label"] = f"ã‚¹ã‚³ã‚¢{i+1}ä½"
    print(f"\nâœ… çµ¶å¯¾ç¦å¿Œã‚¯ãƒªã‚¢: {len(abs_valid_patterns)}/{len(valid_patterns)} ãƒ‘ã‚¿ãƒ¼ãƒ³")
    print(f"   â†’ ä¸Šä½3ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‡ºåŠ›")
else:
    # çµ¶å¯¾ç¦å¿Œã‚¯ãƒªã‚¢ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒãªã„å ´åˆã¯è­¦å‘Š
    print(f"\nâš ï¸  çµ¶å¯¾ç¦å¿Œã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“")
    print(f"   å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ä¸Šä½3ã‚’é¸æŠï¼ˆå‚è€ƒç”¨ï¼‰")
    valid_patterns.sort(key=lambda e: e["raw_after"], reverse=True)
    top_patterns = valid_patterns[:3]
    for i, p in enumerate(top_patterns):
        p["axis_label"] = f"å‚è€ƒ{i+1}ä½ï¼ˆé•åã‚ã‚Šï¼‰"

# ã‚½ãƒ¼ãƒˆæ¸ˆã¿ãƒªã‚¹ãƒˆã‚‚ä½œæˆï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
refined_sorted = sorted(valid_patterns, key=lambda e: e["raw_after"], reverse=True)
TOP_OUTPUT_PATTERNS = len(top_patterns)  # v6.0.0: æœ€å¤§3ãƒ‘ã‚¿ãƒ¼ãƒ³å‡ºåŠ›

scores_df = pd.DataFrame(score_rows).sort_values(["raw_score", "seed"], ascending=[False, True]).reset_index(drop=True)

refined_df = pd.DataFrame([
    {
        "seed": e["seed"],
        "score_before": e["score_before"],
        "raw_before": e["raw_before"],
        "score_after": e["score_after"],
        "raw_after": e["raw_after"],
        **{f"after_{k}": v for k, v in e["metrics_after"].items() if k not in ("raw_score", "penalty_total")},
    }
    for e in refined_sorted
]).sort_values(["raw_after", "seed"], ascending=[False, True]).reset_index(drop=True)

# =========================
# v6.0.0: ä¸Šä½3ãƒ‘ã‚¿ãƒ¼ãƒ³è©•ä¾¡
# =========================
print("\n" + "="*60)
print("  ğŸ“Š ä¸Šä½ãƒ‘ã‚¿ãƒ¼ãƒ³è©•ä¾¡ (v6.0.0)")
print("="*60)

if top_patterns:
    print(f"\n{'é †ä½':<6}{'ã‚¹ã‚³ã‚¢':>10}{'å…¬å¹³æ€§':>8}{'ABSé•å':>8}{'seed':>8}")
    print("-"*44)
    for i, pattern in enumerate(top_patterns, 1):
        raw_score = pattern.get('raw_after', 0)
        fairness = pattern['metrics_after'].get('max_minus_min_total_active', 0)
        abs_valid = pattern.get('absolute_constraints_valid', False)
        abs_viols = len(pattern.get('absolute_violations', []))
        seed = pattern.get('seed', 0)
        status = "âœ…" if abs_valid else f"âŒ{abs_viols}"
        print(f"{i}ä½{'':<4}{raw_score:>10.0f}{fairness:>8}{status:>8}{seed:>8}")
else:
    print("\n  âš ï¸ æœ‰åŠ¹ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

# =========================
# å‡ºåŠ›ï¼ˆpattern + summary + diagnosticsï¼‰
# =========================
base_name = uploaded_filename.rsplit(".", 1)[0]
output_filename = f"{base_name}_v{VERSION}.xlsx"
output_path = output_filename

def write_diagnostics_sheet(writer, sheet_name, diagnostics):
    startrow = 0
    for title, df in diagnostics:
        df.to_excel(writer, sheet_name=sheet_name, startrow=startrow + 1, index=False)
        ws = writer.sheets[sheet_name]
        ws.cell(row=startrow + 1, column=1, value=title)
        startrow += len(df.index) + 3


with pd.ExcelWriter(output_path, engine="openpyxl") as writer:
    # å…ƒã‚·ãƒ¼ãƒˆ
    shift_df.to_excel(writer, sheet_name="sheet1", index=False)
    availability_raw.to_excel(writer, sheet_name="sheet2", index=False)
    schedule_raw.to_excel(writer, sheet_name="sheet3", index=False)
    sheet4_raw_out.to_excel(writer, sheet_name="sheet4", index=False)

    # TOPãƒ‘ã‚¿ãƒ¼ãƒ³å‡ºåŠ›
    for rank, entry in enumerate(top_patterns, start=1):
        axis_label = entry.get('axis_label', 'ç·åˆã‚¹ã‚³ã‚¢')
        sheet_label = f"pattern_{rank:02d}"

        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚·ãƒ¼ãƒˆã®ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã«è»¸ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
        pattern_df_with_label = entry["pattern_df"].copy()
        entry["pattern_df"].to_excel(writer, sheet_name=sheet_label, index=False)

        # ã‚·ãƒ¼ãƒˆåã«è»¸ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ ï¼ˆExcelã®åˆ¶é™ã«ã‚ˆã‚Šç°¡ç•¥åŒ–ï¼‰
        ws = writer.sheets[sheet_label]
        axis_short = {"å…¬å¹³æ€§é‡è¦–": "å…¬å¹³æ€§", "é€£ç¶šå½“ç›´å›é¿é‡è¦–": "gapå›é¿", "ãƒãƒ©ãƒ³ã‚¹é‡è¦–": "ãƒãƒ©ãƒ³ã‚¹", "ç·åˆã‚¹ã‚³ã‚¢": "ç·åˆ"}.get(axis_label, axis_label)
        ws.cell(row=1, column=len(entry["pattern_df"].columns) + 2, value=f"ã€{axis_short}ã€‘")

        # summaryï¼ˆä»Šæœˆ/ç´¯è¨ˆï¼‰
        counts, bg_counts, ht_counts, wd_counts, we_counts, bk_counts, ly_counts, bg_cat, *_ = recompute_stats(entry["pattern_df"])
        df_month, df_total = build_summaries(entry["pattern_df"], counts, bg_counts, ht_counts, wd_counts, we_counts, bg_cat)
        df_month.to_excel(writer, sheet_name=f"{sheet_label}_ä»Šæœˆ", index=False)
        df_total.to_excel(writer, sheet_name=f"{sheet_label}_ç´¯è¨ˆ", index=False)

        # diagnostics
        df_doctors, df_gap, df_same, df_hdup, df_unass, df_metrics, df_hard_violations = build_diagnostics(entry["pattern_df"])
        write_diagnostics_sheet(
            writer,
            sheet_name=f"{sheet_label}_diag",
            diagnostics=[
                ("ğŸš¨ ãƒãƒ¼ãƒ‰åˆ¶ç´„é•å", df_hard_violations),
                ("åŒ»å¸«ã”ã¨ã®åã‚Š", df_doctors),
                ("gapé•å", df_gap),
                ("åŒæ—¥é‡è¤‡", df_same),
                ("åŒä¸€ç—…é™¢é‡è¤‡", df_hdup),
                ("æœªå‰²å½“æ ", df_unass),
                ("ãƒ¡ãƒˆãƒªã‚¯ã‚¹", df_metrics),
            ],
        )

print("\n" + "="*60)
print("  ğŸ‰ å®Œäº†")
print("="*60)
print(f"\nğŸ“¥ å‡ºåŠ›: {output_path}")
print("\nã€å†…å®¹ã€‘")
print("  â”œâ”€ sheet1ã€œ4: å…ƒãƒ‡ãƒ¼ã‚¿")
print("  â”œâ”€ pattern_01: æœ€è‰¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆçµ¶å¯¾ç¦å¿Œã‚¯ãƒªã‚¢ï¼‰")
print("  â”œâ”€ pattern_01_ä»Šæœˆ/ç´¯è¨ˆ: ã‚µãƒãƒªãƒ¼")
print("  â””â”€ pattern_01_diag: è¨ºæ–­ã‚·ãƒ¼ãƒˆ")
print("\nã€v6.0.0 åˆ¶ç´„ãƒã‚§ãƒƒã‚¯é …ç›®ã€‘")
print("  çµ¶å¯¾ç¦å¿Œ(ABS): 11é …ç›®")
print("  â”œâ”€ ABS-001: ã‚³ãƒ¼ãƒ‰0å‰²å½“ç¦æ­¢")
print("  â”œâ”€ ABS-002: ã‚³ãƒ¼ãƒ‰2åˆ—åˆ¶é™ï¼ˆBã€œQåˆ—ã®ã¿ï¼‰")
print("  â”œâ”€ ABS-003: ã‚³ãƒ¼ãƒ‰3åˆ—åˆ¶é™ï¼ˆLã€œYåˆ—ã®ã¿ï¼‰")
print("  â”œâ”€ ABS-006: åŒæ—¥é‡è¤‡ç¦æ­¢")
print("  â”œâ”€ ABS-007: gap >= 3æ—¥å¿…é ˆ")
print("  â”œâ”€ ABS-008: åŒä¸€ç—…é™¢é‡è¤‡ç¦æ­¢ï¼ˆå…¨åˆ—ï¼‰")
print("  â”œâ”€ ABS-009: æœªå‰²å½“ç¦æ­¢")
print("  â”œâ”€ ABS-010: TARGET_CAPéµå®ˆ")
print("  â””â”€ ABS-011: å¤§å­¦ç³»2å›ã¾ã§")
print("  ãƒãƒ¼ãƒ‰åˆ¶ç´„(HARD): 3é …ç›®")
print("  â”œâ”€ HARD-001: B/Iåˆ—1å›ã¾ã§")
print("  â”œâ”€ HARD-002: C-H/J-Kåˆ—1å›ã¾ã§")
print("  â””â”€ HARD-003: å¤–ç—…é™¢1å›ä»¥ä¸Š")
print("="*60)

if COLAB_AVAILABLE:
    files.download(output_path)
